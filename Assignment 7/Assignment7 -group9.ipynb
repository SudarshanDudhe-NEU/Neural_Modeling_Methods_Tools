{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa70c0f",
   "metadata": {},
   "source": [
    "## 1. Train Language Embeddings\n",
    "\n",
    "In this section, we will train language embeddings for a language other than English. The goal is to train embeddings on a language corpus and understand how they can be used for downstream tasks like chatbot development.\n",
    "\n",
    "### Steps:\n",
    "- **Load Data**: Load a corpus of text in your native language.\n",
    "- **Train Word2Vec Embeddings**: Use the gensim Word2Vec model to train embeddings on the corpus.\n",
    "- **Save the Model**: Save the embeddings in a file format that can be reused for evaluation and other tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba314782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/sudarshan/anaconda3/lib/python3.11/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/sudarshan/anaconda3/lib/python3.11/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/sudarshan/anaconda3/lib/python3.11/site-packages (from gensim) (5.2.1)\n",
      "Downloading gensim-4.3.3-cp311-cp311-macosx_11_0_arm64.whl (24.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: gensim\n",
      "Successfully installed gensim-4.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "# !pip install indic-nlp-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4688effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a7f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import re\n",
    "import string\n",
    "from indicnlp.tokenize import sentence_tokenize, indic_tokenize  # Part of Indic NLP Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21b7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"sourabh219/oscarmarathicorpus\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158f7e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function kagglehub.datasets.dataset_download(handle: str, path: Optional[str] = None, *, force_download: Optional[bool] = False) -> str>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kagglehub.dataset_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daaf0b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q aiobotocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f807d13",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# import re\n",
    "# import string\n",
    "\n",
    "# def load_and_clean_text_from_dataset(file_path):\n",
    "#     # Load the dataset\n",
    "#     dataset = load_dataset('oscar', 'unshuffled_deduplicated_mr', data_files=file_path, split='train')\n",
    "\n",
    "#     # Extract text and clean it\n",
    "#     marathi_text = []\n",
    "#     for record in dataset:\n",
    "#         text = record['text']\n",
    "#         # Remove punctuation and numbers\n",
    "#         text = re.sub(r'[{}]'.format(string.punctuation), ' ', text)\n",
    "#         text = re.sub(r'\\d+', '', text)\n",
    "#         marathi_text.append(text)\n",
    "    \n",
    "#     return marathi_text\n",
    "\n",
    "# # Load and clean text\n",
    "# file_path = f'{path}/dataset.arrow'\n",
    "# marathi_text = load_and_clean_text_from_dataset(file_path)\n",
    "\n",
    "# # You can then save or further process `marathi_text`\n",
    "# print(marathi_text[:5])  # Display the first 5 cleaned texts for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af1cba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_text(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[{}]'.format(string.punctuation), ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text\n",
    "file_path = \"/Users/sudarshan/courses/Neural_Modeling_Methods_&_Tool/W9L1/mar-in_web_2015_300K/mar-in_web_2015_300K-sentences.txt\"\n",
    "\n",
    "marathi_text = load_and_clean_text(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "603cdbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t     द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t टक्के इतके अल्प असते \n",
      "\t    द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t  किंवा त्याहूनही कमी करण्यात येते \n",
      "\t  असल्याचे अनुमान काढण्यात आले आहे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t   पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य क  वार्षिक उत्पन्नाचा दाखला तलाठी तहसिलदार यांचा आवश्यक ड  लाभार्थी चे वय  वर्षे पेक्षा कमी व त्यांचेकडे सक्षम संस्थेचे शिवणकाम प्रशिक्षण घेतलेचे प्रमाणपत्र आवश्यक \n",
      "\t   प्रत्येक आयएसडीएन पीआरआय साठी मासिक कनेक्टिव्हिटी फ़्रैंचाइजीना पूल बिलींगची सुविधा दिली जाते व जेवढया पीआरआय लाईनसाठी जेवढे लाख कॉल पूर्ण केले असतील तेवढी कनेक्टिव्हिटी मूल्यात सूट दिली जाईल \n",
      "\t वर्षापासून आहे \n",
      "\t\n",
      " द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t     द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t टक्के इतके अल्प असते \n",
      "\t    द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t  किंवा त्याहूनही कमी करण्यात येते \n",
      "\t  असल्याचे अनुमान काढण्यात आले आहे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t   पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य क  वार्षिक उत्पन्नाचा दाखला तलाठी तहसिलदार यांचा आवश्यक ड  लाभार्थी चे वय  वर्षे पेक्षा कमी व त्यांचेकडे सक्षम संस्थेचे शिवणकाम प्रशिक्षण घेतलेचे प्रमाणपत्र आवश्यक \n",
      "\t   प्रत्येक आयएसडीएन पीआरआय साठी मासिक कनेक्टिव्हिटी फ़्रैंचाइजीना पूल बिलींगची सुविधा दिली जाते व जेवढया पीआरआय लाईनसाठी जेवढे लाख कॉल पूर्ण केले असतील तेवढी कनेक्टिव्हिटी मूल्यात सूट दिली जाईल \n",
      "\t वर्षापासून आहे \n",
      "\t \n",
      "द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t     द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t टक्के इतके अल्प असते \n",
      "\t    द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t  किंवा त्याहूनही कमी करण्यात येते \n",
      "\t  असल्याचे अनुमान काढण्यात आले आहे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t   पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य क  वार्षिक उत्पन्नाचा दाखला तलाठी तहसिलदार यांचा आवश्यक ड  लाभार्थी चे वय  वर्षे पेक्षा कमी व त्यांचेकडे सक्षम संस्थेचे शिवणकाम प्रशिक्षण घेतलेचे प्रमाणपत्र आवश्यक \n",
      "\t   प्रत्येक आयएसडीएन पीआरआय साठी मासिक कनेक्टिव्हिटी फ़्रैंचाइजीना पूल बिलींगची सुविधा दिली जाते व जेवढया पीआरआय लाईनसाठी जेवढे लाख कॉल पूर्ण केले असतील तेवढी कनेक्टिव्हिटी मूल्यात सूट दिली जाईल \n",
      "\t वर्षापासून आहे \n",
      "\t य\n",
      "्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t     द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t टक्के इतके अल्प असते \n",
      "\t    द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t  किंवा त्याहूनही कमी करण्यात येते \n",
      "\t  असल्याचे अनुमान काढण्यात आले आहे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t   पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य क  वार्षिक उत्पन्नाचा दाखला तलाठी तहसिलदार यांचा आवश्यक ड  लाभार्थी चे वय  वर्षे पेक्षा कमी व त्यांचेकडे सक्षम संस्थेचे शिवणकाम प्रशिक्षण घेतलेचे प्रमाणपत्र आवश्यक \n",
      "\t   प्रत्येक आयएसडीएन पीआरआय साठी मासिक कनेक्टिव्हिटी फ़्रैंचाइजीना पूल बिलींगची सुविधा दिली जाते व जेवढया पीआरआय लाईनसाठी जेवढे लाख कॉल पूर्ण केले असतील तेवढी कनेक्टिव्हिटी मूल्यात सूट दिली जाईल \n",
      "\t वर्षापासून आहे \n",
      "\t या\n",
      "वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t     द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t टक्के इतके अल्प असते \n",
      "\t    द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t  किंवा त्याहूनही कमी करण्यात येते \n",
      "\t  असल्याचे अनुमान काढण्यात आले आहे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t   पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य क  वार्षिक उत्पन्नाचा दाखला तलाठी तहसिलदार यांचा आवश्यक ड  लाभार्थी चे वय  वर्षे पेक्षा कमी व त्यांचेकडे सक्षम संस्थेचे शिवणकाम प्रशिक्षण घेतलेचे प्रमाणपत्र आवश्यक \n",
      "\t   प्रत्येक आयएसडीएन पीआरआय साठी मासिक कनेक्टिव्हिटी फ़्रैंचाइजीना पूल बिलींगची सुविधा दिली जाते व जेवढया पीआरआय लाईनसाठी जेवढे लाख कॉल पूर्ण केले असतील तेवढी कनेक्टिव्हिटी मूल्यात सूट दिली जाईल \n",
      "\t वर्षापासून आहे \n",
      "\t या \n",
      "ारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t     द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t टक्के इतके अल्प असते \n",
      "\t    द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t  किंवा त्याहूनही कमी करण्यात येते \n",
      "\t  असल्याचे अनुमान काढण्यात आले आहे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t   पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य क  वार्षिक उत्पन्नाचा दाखला तलाठी तहसिलदार यांचा आवश्यक ड  लाभार्थी चे वय  वर्षे पेक्षा कमी व त्यांचेकडे सक्षम संस्थेचे शिवणकाम प्रशिक्षण घेतलेचे प्रमाणपत्र आवश्यक \n",
      "\t   प्रत्येक आयएसडीएन पीआरआय साठी मासिक कनेक्टिव्हिटी फ़्रैंचाइजीना पूल बिलींगची सुविधा दिली जाते व जेवढया पीआरआय लाईनसाठी जेवढे लाख कॉल पूर्ण केले असतील तेवढी कनेक्टिव्हिटी मूल्यात सूट दिली जाईल \n",
      "\t वर्षापासून आहे \n",
      "\t या स\n",
      "रा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t     द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t टक्के इतके अल्प असते \n",
      "\t    द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t  किंवा त्याहूनही कमी करण्यात येते \n",
      "\t  असल्याचे अनुमान काढण्यात आले आहे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t   पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य क  वार्षिक उत्पन्नाचा दाखला तलाठी तहसिलदार यांचा आवश्यक ड  लाभार्थी चे वय  वर्षे पेक्षा कमी व त्यांचेकडे सक्षम संस्थेचे शिवणकाम प्रशिक्षण घेतलेचे प्रमाणपत्र आवश्यक \n",
      "\t   प्रत्येक आयएसडीएन पीआरआय साठी मासिक कनेक्टिव्हिटी फ़्रैंचाइजीना पूल बिलींगची सुविधा दिली जाते व जेवढया पीआरआय लाईनसाठी जेवढे लाख कॉल पूर्ण केले असतील तेवढी कनेक्टिव्हिटी मूल्यात सूट दिली जाईल \n",
      "\t वर्षापासून आहे \n",
      "\t या सम\n",
      "ा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t     द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t टक्के इतके अल्प असते \n",
      "\t    द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t  किंवा त्याहूनही कमी करण्यात येते \n",
      "\t  असल्याचे अनुमान काढण्यात आले आहे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t   पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य क  वार्षिक उत्पन्नाचा दाखला तलाठी तहसिलदार यांचा आवश्यक ड  लाभार्थी चे वय  वर्षे पेक्षा कमी व त्यांचेकडे सक्षम संस्थेचे शिवणकाम प्रशिक्षण घेतलेचे प्रमाणपत्र आवश्यक \n",
      "\t   प्रत्येक आयएसडीएन पीआरआय साठी मासिक कनेक्टिव्हिटी फ़्रैंचाइजीना पूल बिलींगची सुविधा दिली जाते व जेवढया पीआरआय लाईनसाठी जेवढे लाख कॉल पूर्ण केले असतील तेवढी कनेक्टिव्हिटी मूल्यात सूट दिली जाईल \n",
      "\t वर्षापासून आहे \n",
      "\t या समा\n",
      " पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t     द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t टक्के इतके अल्प असते \n",
      "\t    द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t  किंवा त्याहूनही कमी करण्यात येते \n",
      "\t  असल्याचे अनुमान काढण्यात आले आहे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t   पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य क  वार्षिक उत्पन्नाचा दाखला तलाठी तहसिलदार यांचा आवश्यक ड  लाभार्थी चे वय  वर्षे पेक्षा कमी व त्यांचेकडे सक्षम संस्थेचे शिवणकाम प्रशिक्षण घेतलेचे प्रमाणपत्र आवश्यक \n",
      "\t   प्रत्येक आयएसडीएन पीआरआय साठी मासिक कनेक्टिव्हिटी फ़्रैंचाइजीना पूल बिलींगची सुविधा दिली जाते व जेवढया पीआरआय लाईनसाठी जेवढे लाख कॉल पूर्ण केले असतील तेवढी कनेक्टिव्हिटी मूल्यात सूट दिली जाईल \n",
      "\t वर्षापासून आहे \n",
      "\t या समान\n",
      "पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t     द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t टक्के इतके अल्प असते \n",
      "\t    द्वारा पोस्ट केलेले सतीश लळीत  महाराष्ट्र शासनात वरिष्ठ अधिकारी \n",
      "\t  किंवा त्याहूनही कमी करण्यात येते \n",
      "\t  असल्याचे अनुमान काढण्यात आले आहे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t   पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य   महिलांना विविध साहित्य पुरविणे \n",
      "\t  पर्यत अथवा कुंटूंब दारिद्रय रेषेखालील असल्यास प्राधान्य क  वार्षिक उत्पन्नाचा दाखला तलाठी तहसिलदार यांचा आवश्यक ड  लाभार्थी चे वय  वर्षे पेक्षा कमी व त्यांचेकडे सक्षम संस्थेचे शिवणकाम प्रशिक्षण घेतलेचे प्रमाणपत्र आवश्यक \n",
      "\t   प्रत्येक आयएसडीएन पीआरआय साठी मासिक कनेक्टिव्हिटी फ़्रैंचाइजीना पूल बिलींगची सुविधा दिली जाते व जेवढया पीआरआय लाईनसाठी जेवढे लाख कॉल पूर्ण केले असतील तेवढी कनेक्टिव्हिटी मूल्यात सूट दिली जाईल \n",
      "\t वर्षापासून आहे \n",
      "\t या समान \n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(marathi_text[i:i+1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "960d928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into sentences\n",
    "sentences = sentence_tokenize.sentence_split(marathi_text, lang='mr')\n",
    "\n",
    "# Tokenize each sentence into words\n",
    "tokenized_sentences = [indic_tokenize.trivial_tokenize(sentence) for sentence in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2282d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['द्वारा',\n",
       " 'पोस्ट',\n",
       " 'केलेले',\n",
       " 'सतीश',\n",
       " 'लळीत',\n",
       " 'महाराष्ट्र',\n",
       " 'शासनात',\n",
       " 'वरिष्ठ',\n",
       " 'अधिकारी',\n",
       " '\\n',\n",
       " 'द्वारा',\n",
       " 'पोस्ट',\n",
       " 'केलेले',\n",
       " 'सतीश',\n",
       " 'लळीत',\n",
       " 'महाराष्ट्र',\n",
       " 'शासनात',\n",
       " 'वरिष्ठ',\n",
       " 'अधिकारी',\n",
       " '\\n',\n",
       " 'द्वारा',\n",
       " 'पोस्ट',\n",
       " 'केलेले',\n",
       " 'सतीश',\n",
       " 'लळीत',\n",
       " 'महाराष्ट्र',\n",
       " 'शासनात',\n",
       " 'वरिष्ठ',\n",
       " 'अधिकारी',\n",
       " '\\n',\n",
       " 'टक्के',\n",
       " 'इतके',\n",
       " 'अल्प',\n",
       " 'असते',\n",
       " '\\n',\n",
       " 'द्वारा',\n",
       " 'पोस्ट',\n",
       " 'केलेले',\n",
       " 'सतीश',\n",
       " 'लळीत',\n",
       " 'महाराष्ट्र',\n",
       " 'शासनात',\n",
       " 'वरिष्ठ',\n",
       " 'अधिकारी',\n",
       " '\\n',\n",
       " 'किंवा',\n",
       " 'त्याहूनही',\n",
       " 'कमी',\n",
       " 'करण्यात',\n",
       " 'येते',\n",
       " '\\n',\n",
       " 'असल्याचे',\n",
       " 'अनुमान',\n",
       " 'काढण्यात',\n",
       " 'आले',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'पर्यत',\n",
       " 'अथवा',\n",
       " 'कुंटूंब',\n",
       " 'दारिद्रय',\n",
       " 'रेषेखालील',\n",
       " 'असल्यास',\n",
       " 'प्राधान्य',\n",
       " 'महिलांना',\n",
       " 'विविध',\n",
       " 'साहित्य',\n",
       " 'पुरविणे',\n",
       " '\\n',\n",
       " 'पर्यत',\n",
       " 'अथवा',\n",
       " 'कुंटूंब',\n",
       " 'दारिद्रय',\n",
       " 'रेषेखालील',\n",
       " 'असल्यास',\n",
       " 'प्राधान्य',\n",
       " 'महिलांना',\n",
       " 'विविध',\n",
       " 'साहित्य',\n",
       " 'पुरविणे',\n",
       " '\\n',\n",
       " 'पर्यत',\n",
       " 'अथवा',\n",
       " 'कुंटूंब',\n",
       " 'दारिद्रय',\n",
       " 'रेषेखालील',\n",
       " 'असल्यास',\n",
       " 'प्राधान्य',\n",
       " 'क',\n",
       " 'वार्षिक',\n",
       " 'उत्पन्नाचा',\n",
       " 'दाखला',\n",
       " 'तलाठी',\n",
       " 'तहसिलदार',\n",
       " 'यांचा',\n",
       " 'आवश्यक',\n",
       " 'ड',\n",
       " 'लाभार्थी',\n",
       " 'चे',\n",
       " 'वय',\n",
       " 'वर्षे',\n",
       " 'पेक्षा',\n",
       " 'कमी',\n",
       " 'व',\n",
       " 'त्यांचेकडे',\n",
       " 'सक्षम',\n",
       " 'संस्थेचे',\n",
       " 'शिवणकाम',\n",
       " 'प्रशिक्षण',\n",
       " 'घेतलेचे',\n",
       " 'प्रमाणपत्र',\n",
       " 'आवश्यक',\n",
       " '\\n',\n",
       " 'प्रत्येक',\n",
       " 'आयएसडीएन',\n",
       " 'पीआरआय',\n",
       " 'साठी',\n",
       " 'मासिक',\n",
       " 'कनेक्टिव्हिटी',\n",
       " 'फ़्रैंचाइजीना',\n",
       " 'पूल',\n",
       " 'बिलींगची',\n",
       " 'सुविधा',\n",
       " 'दिली',\n",
       " 'जाते',\n",
       " 'व',\n",
       " 'जेवढया',\n",
       " 'पीआरआय',\n",
       " 'लाईनसाठी',\n",
       " 'जेवढे',\n",
       " 'लाख',\n",
       " 'कॉल',\n",
       " 'पूर्ण',\n",
       " 'केले',\n",
       " 'असतील',\n",
       " 'तेवढी',\n",
       " 'कनेक्टिव्हिटी',\n",
       " 'मूल्यात',\n",
       " 'सूट',\n",
       " 'दिली',\n",
       " 'जाईल',\n",
       " '\\n',\n",
       " 'वर्षापासून',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'या',\n",
       " 'समान',\n",
       " 'दराने',\n",
       " 'मुद्रांक',\n",
       " 'शुल्क',\n",
       " '•',\n",
       " 'मध्ये',\n",
       " 'महसुली',\n",
       " 'जमा',\n",
       " 'रुपये',\n",
       " 'हजार',\n",
       " 'कोटी',\n",
       " '•',\n",
       " 'मध्ये',\n",
       " 'महसुली',\n",
       " 'जमा',\n",
       " 'रुपये',\n",
       " 'लक्ष',\n",
       " 'हजार',\n",
       " 'कोटी',\n",
       " 'एकूण',\n",
       " 'वाढ',\n",
       " '\\n',\n",
       " 'अशी',\n",
       " 'करण्यात',\n",
       " 'येते़',\n",
       " 'प्रवासी',\n",
       " 'विंत्र्वा',\n",
       " 'दिवसाचा',\n",
       " 'पास',\n",
       " 'घेऊन',\n",
       " 'ज्यावेळी',\n",
       " 'प्रवास',\n",
       " 'करीत',\n",
       " 'असतो',\n",
       " 'व',\n",
       " 'त्या',\n",
       " 'पासाच्या',\n",
       " 'प्रवासाच्या',\n",
       " 'शेवटच्या',\n",
       " 'दिवाशी',\n",
       " 'रात्री',\n",
       " '\\n',\n",
       " 'अंबाझरी',\n",
       " 'तलाव',\n",
       " 'परिसरातील',\n",
       " 'प्लास्टिक',\n",
       " 'व',\n",
       " 'टाकाऊ',\n",
       " 'साहित्य',\n",
       " 'उचलणे',\n",
       " 'तसेच',\n",
       " 'सकाळी',\n",
       " '\\n',\n",
       " 'एकशेपस्तीस',\n",
       " 'माजी',\n",
       " 'सैनिक',\n",
       " '–',\n",
       " 'रू',\n",
       " '\\n',\n",
       " 'एमटीएनएल',\n",
       " 'नेटवर्कमघ्ये',\n",
       " 'एकदा',\n",
       " 'संदेशा',\n",
       " 'एसएमएस',\n",
       " 'सहीत',\n",
       " 'मोफत',\n",
       " 'टॉक',\n",
       " 'टाईम',\n",
       " 'दिला',\n",
       " 'जाईल',\n",
       " 'व',\n",
       " 'एका',\n",
       " 'वर्षात',\n",
       " 'त्याचा',\n",
       " 'उपयोग',\n",
       " 'करावा',\n",
       " 'लागेल',\n",
       " '\\n',\n",
       " 'किलो',\n",
       " 'संतुलित',\n",
       " 'आहार',\n",
       " 'ते',\n",
       " 'ग्रॅम',\n",
       " 'प्रतिशेळी',\n",
       " 'प्रतिदिन',\n",
       " '\\n',\n",
       " 'कोटी',\n",
       " 'देण्याचा',\n",
       " 'महत्वपूर्ण',\n",
       " 'निर्णय',\n",
       " 'घेण्यात',\n",
       " 'आला',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'झोप',\n",
       " 'म्हटलेले',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'झोप',\n",
       " 'विद्यार्थ्यांची',\n",
       " 'असा',\n",
       " 'शिक्षकांचा',\n",
       " 'विद्यार्थ्यांसाठी',\n",
       " 'दिनक्रम',\n",
       " 'ठरवून',\n",
       " 'दिलेला',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'ट्राफिक',\n",
       " 'चिल्ड्रेन',\n",
       " 'पार्क',\n",
       " 'येथील',\n",
       " 'प्लास्टिक',\n",
       " 'व',\n",
       " 'टाकाऊ',\n",
       " 'साहित्य',\n",
       " 'उचलणे',\n",
       " '\\n',\n",
       " 'डॉलर',\n",
       " 'प्रति',\n",
       " 'बॅरलवर',\n",
       " 'आले',\n",
       " '\\n',\n",
       " 'तास',\n",
       " 'धरुन',\n",
       " 'आकारणी',\n",
       " 'करण्यात',\n",
       " 'येईल',\n",
       " '\\n',\n",
       " 'तासांचे',\n",
       " 'म्हणजेच',\n",
       " 'किमान',\n",
       " 'विंत्र्वा',\n",
       " 'प्रत्यक्ष',\n",
       " 'यापैकी',\n",
       " 'जे',\n",
       " 'जास्त',\n",
       " 'असतील',\n",
       " 'ते',\n",
       " 'कि़',\n",
       " '\\n',\n",
       " 'तासांच्या',\n",
       " 'आत',\n",
       " 'परंतु',\n",
       " 'पेक्षा',\n",
       " 'जास्त',\n",
       " 'कि़',\n",
       " '\\n',\n",
       " 'ते',\n",
       " 'सायंकाळी',\n",
       " '\\n',\n",
       " 'ते',\n",
       " 'सांयकाळी',\n",
       " '\\n',\n",
       " 'पासुन',\n",
       " 'सुरू',\n",
       " 'होईल',\n",
       " 'बालभारती',\n",
       " 'पुणे',\n",
       " 'सरळसेवा',\n",
       " 'भरतीसाठीची',\n",
       " 'नोंदणी',\n",
       " 'दिनांक',\n",
       " '\\n',\n",
       " 'पेक्षा',\n",
       " 'कमी',\n",
       " 'असल्याचे',\n",
       " 'जन्म',\n",
       " 'प्रमाण',\n",
       " 'कायम',\n",
       " 'ठेवण्यासाठी',\n",
       " '\\n',\n",
       " 'प्रति',\n",
       " 'किलो',\n",
       " 'या',\n",
       " 'दराने',\n",
       " 'देण्यात',\n",
       " 'येतो',\n",
       " '\\n',\n",
       " 'मिमी',\n",
       " 'पाऊस',\n",
       " 'पडला',\n",
       " '\\n',\n",
       " 'या',\n",
       " 'तासांत',\n",
       " 'वार्षिक',\n",
       " 'उत्पन्नाइतके',\n",
       " 'वाढते',\n",
       " 'असे',\n",
       " 'म्हटल्यास',\n",
       " 'वावगे',\n",
       " 'ठरणार',\n",
       " 'नाही',\n",
       " '\\n',\n",
       " 'या',\n",
       " 'कालावधीत',\n",
       " 'पाणी',\n",
       " 'पुरवठा',\n",
       " 'बंद',\n",
       " 'राहणार',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'या',\n",
       " 'दराने',\n",
       " 'करण्यात',\n",
       " 'येते',\n",
       " '\\n',\n",
       " 'याने',\n",
       " 'दुसरा',\n",
       " 'श्रुती',\n",
       " 'सोसे',\n",
       " 'व',\n",
       " 'निरज',\n",
       " 'प्रजापती',\n",
       " 'अनुक्रमे',\n",
       " '\\n',\n",
       " 'राउत',\n",
       " 'चौक',\n",
       " 'त',\n",
       " 'नाईक',\n",
       " 'परिसरातील',\n",
       " 'प्लास्टिक',\n",
       " 'व',\n",
       " 'टाकाऊ',\n",
       " 'पदार्थ',\n",
       " 'उचलणे',\n",
       " 'व',\n",
       " 'साफ',\n",
       " 'सफाई',\n",
       " 'स्वंयसेवी',\n",
       " 'संस्था',\n",
       " 'चे',\n",
       " 'सहकार्याने',\n",
       " 'राबिविणे',\n",
       " '\\n',\n",
       " 'लक्ष',\n",
       " 'अनुदान',\n",
       " 'केंद्र',\n",
       " 'व',\n",
       " 'राज्य',\n",
       " 'मिळून',\n",
       " 'देण्यात',\n",
       " 'येते',\n",
       " '\\n',\n",
       " 'लक्ष',\n",
       " 'अनुदानातून',\n",
       " 'टक्के',\n",
       " 'अदानावर',\n",
       " 'बैरण',\n",
       " 'विकासासाठी',\n",
       " 'मका',\n",
       " 'बियाने',\n",
       " 'वाटप',\n",
       " 'करण्यात',\n",
       " 'येत',\n",
       " 'आहेत',\n",
       " 'एकात्मीक',\n",
       " 'कुक्कुट',\n",
       " 'विकास',\n",
       " 'कार्यक्रमा',\n",
       " 'अंतर्गत',\n",
       " 'लाभधारकांना',\n",
       " 'सुधारीत',\n",
       " 'जातीच्या',\n",
       " 'कुक्कुटपिल्लाचे',\n",
       " 'गट',\n",
       " 'व',\n",
       " 'खादय',\n",
       " 'देण्यात',\n",
       " 'येत',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'लक्ष',\n",
       " 'निधी',\n",
       " 'उपलब्ध',\n",
       " 'झाला',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'लक्ष',\n",
       " 'नियतव्यय',\n",
       " 'मंजूर',\n",
       " 'असून',\n",
       " 'लाभधारकांना',\n",
       " 'लाभ',\n",
       " 'देणार',\n",
       " '\\n',\n",
       " 'लक्ष',\n",
       " 'नियतव्यय',\n",
       " 'मंजूर',\n",
       " 'असून',\n",
       " 'लाभधारकांना',\n",
       " 'लाभ',\n",
       " 'देणार',\n",
       " '\\n',\n",
       " 'लक्ष',\n",
       " 'पर्यंतचे',\n",
       " 'देता',\n",
       " 'येईल',\n",
       " 'त्यासाठी',\n",
       " 'ग्रामपंचायत',\n",
       " 'आर्थिक',\n",
       " 'दृष्ट्या',\n",
       " 'सक्षम',\n",
       " 'असल्याचे',\n",
       " 'प्रमाणपत्र',\n",
       " 'गटविकास',\n",
       " 'अधिकारी',\n",
       " 'पंचायत',\n",
       " 'समिती',\n",
       " 'यांचेकडून',\n",
       " 'उपलब्ध',\n",
       " 'करुन',\n",
       " 'घ्यावे',\n",
       " '\\n',\n",
       " 'लक्ष',\n",
       " 'रुपयांचे',\n",
       " 'अनुदान',\n",
       " 'मंजूर',\n",
       " 'करण्यात',\n",
       " 'आले',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'लक्ष्य',\n",
       " 'तरतूद',\n",
       " 'उपलब्ध',\n",
       " 'झाली',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'लक्ष्य',\n",
       " 'तरतूदप्राप्त',\n",
       " 'होती',\n",
       " '\\n',\n",
       " 'लाख',\n",
       " 'लाख',\n",
       " 'व',\n",
       " '\\n',\n",
       " 'लाख',\n",
       " 'प्रति',\n",
       " 'अंगणवाडी',\n",
       " 'याप्रमाणे',\n",
       " 'करण्यात',\n",
       " 'आलेली',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'लाख',\n",
       " 'प्रती',\n",
       " 'संस्था',\n",
       " 'मंजुर',\n",
       " 'व',\n",
       " 'उपलब्ध',\n",
       " 'करुन',\n",
       " 'दिलेले',\n",
       " 'आहेत',\n",
       " '\\n',\n",
       " 'लाख',\n",
       " 'व',\n",
       " 'अभ्यास',\n",
       " 'केंद्रासाठी',\n",
       " 'रु',\n",
       " 'लाख',\n",
       " 'राहील',\n",
       " '\\n',\n",
       " 'लाख',\n",
       " 'व',\n",
       " 'सुवर्णपदक',\n",
       " 'देण्यात',\n",
       " 'येते',\n",
       " '\\n',\n",
       " 'लाखाचा',\n",
       " 'निधी',\n",
       " 'मंजूर',\n",
       " 'केलेला',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'लाखापर्यंतचा',\n",
       " 'निधी',\n",
       " 'पणन',\n",
       " 'व्यवस्थापन',\n",
       " 'बाजारपेठ',\n",
       " 'निमीर्ती',\n",
       " 'उत्पादित',\n",
       " 'वस्तुंचा',\n",
       " 'दर्जा',\n",
       " 'सूधारणा',\n",
       " 'इ',\n",
       " 'सारख्या',\n",
       " 'बाबीवर',\n",
       " 'करावयाचा',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'वाजता',\n",
       " 'कार्यपत्रिका',\n",
       " 'काढणेचा',\n",
       " 'अंतिम',\n",
       " 'दिवस',\n",
       " 'शुक्रवार',\n",
       " '\\n',\n",
       " 'वाजता',\n",
       " 'कार्यपत्रिका',\n",
       " 'काढणेचा',\n",
       " 'अंतिम',\n",
       " 'दिवस',\n",
       " 'सोमवार',\n",
       " '\\n',\n",
       " 'वाजता',\n",
       " 'गोवा',\n",
       " 'मेडिकल',\n",
       " 'कॉलेजमध्ये',\n",
       " 'दाखल',\n",
       " 'करण्यात',\n",
       " 'आले',\n",
       " '\\n',\n",
       " 'वाजता',\n",
       " 'तिच्या',\n",
       " 'घरी',\n",
       " 'आली',\n",
       " 'होती',\n",
       " '\\n',\n",
       " 'वाजता',\n",
       " 'परिषदेच्या',\n",
       " 'संकेत',\n",
       " 'स्थळावर',\n",
       " 'घोषित',\n",
       " 'करण्यात',\n",
       " 'येत',\n",
       " 'आहेत',\n",
       " '\\n',\n",
       " 'वाजता',\n",
       " 'पोहचेल',\n",
       " 'आणि',\n",
       " 'परतीच्या',\n",
       " 'प्रवासात',\n",
       " 'ही',\n",
       " 'गडी',\n",
       " 'पंढरपुरयेथुन',\n",
       " 'दुसऱ्या',\n",
       " 'दिवशी',\n",
       " 'म्हणजेच',\n",
       " 'दि',\n",
       " '\\n',\n",
       " 'वाजता',\n",
       " 'मी',\n",
       " 'तसा',\n",
       " 'प्रयत्न',\n",
       " 'चालू',\n",
       " 'केला',\n",
       " '\\n',\n",
       " 'वाजता',\n",
       " 'स्वातंत्र्य',\n",
       " 'सैनिकांच्या',\n",
       " 'हस्ते',\n",
       " 'ध्वजवंदन',\n",
       " 'करून',\n",
       " 'राष्ट्रप्रेमाची',\n",
       " 'पावती',\n",
       " 'दिली',\n",
       " '\\n',\n",
       " 'वाजता',\n",
       " 'ही',\n",
       " 'गाडी',\n",
       " 'ह',\n",
       " 'निमाजुद्दीनवरू',\n",
       " 'निघाली',\n",
       " '\\n',\n",
       " '–',\n",
       " 'सरकारी',\n",
       " 'सुट्टीच्या',\n",
       " 'दिवशी',\n",
       " 'बंद',\n",
       " '\\n',\n",
       " 'कॅफिन',\n",
       " 'व',\n",
       " 'काही',\n",
       " 'भाग',\n",
       " 'तंतू',\n",
       " 'आणि',\n",
       " 'पाणी',\n",
       " 'असते',\n",
       " '\\n',\n",
       " 'टक्का',\n",
       " 'लोक',\n",
       " 'हेच',\n",
       " 'चांगले',\n",
       " 'काम',\n",
       " 'करतात',\n",
       " '\\n',\n",
       " 'टक्के',\n",
       " 'हा',\n",
       " 'उच्चांकी',\n",
       " 'स्तर',\n",
       " 'गाठला',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'पेक्षा',\n",
       " 'जास्त',\n",
       " 'नसते',\n",
       " 'व',\n",
       " 'त्यातील',\n",
       " 'बहुतेक',\n",
       " 'भाग',\n",
       " 'शिजविण्याच्या',\n",
       " 'क्रियेत',\n",
       " 'नष्ट',\n",
       " 'होतो',\n",
       " '\\n',\n",
       " 'पेक्षा',\n",
       " 'जास्त',\n",
       " 'प्रमाणात',\n",
       " 'सोलॅनीन',\n",
       " 'असलेले',\n",
       " 'बटाटे',\n",
       " 'खाणे',\n",
       " 'प्रकृतीला',\n",
       " 'हानिकारक',\n",
       " 'असते',\n",
       " '\\n',\n",
       " 'शेती',\n",
       " 'क्षेत्रात',\n",
       " 'उल्लेखनिय',\n",
       " 'काम',\n",
       " 'केलेल्या',\n",
       " 'शेतक',\n",
       " 'यांने',\n",
       " 'सदर',\n",
       " 'पुरस्कारासाठी',\n",
       " 'आपला',\n",
       " 'प्रस्ताव',\n",
       " 'विहीत',\n",
       " 'प्रपत्रात',\n",
       " 'पंचायत',\n",
       " 'समिती',\n",
       " 'कृषि',\n",
       " 'विभागाकडे',\n",
       " 'सादर',\n",
       " 'करावा',\n",
       " '\\n',\n",
       " 'प्रक्षेत्र',\n",
       " 'व्यवस्थापक',\n",
       " 'पुण्यश्लोक',\n",
       " 'अहिल्यादेवी',\n",
       " 'मेंढी',\n",
       " 'व',\n",
       " 'शेळी',\n",
       " 'विकास',\n",
       " 'प्रक्षेत्र',\n",
       " 'बिलाखेड',\n",
       " 'ता',\n",
       " '\\n',\n",
       " 'से',\n",
       " 'वरील',\n",
       " 'भौतिक',\n",
       " 'स्थिरांकांच्या',\n",
       " 'स्पष्टीकरणाकरिता',\n",
       " 'अ\\u200dॅमिनो',\n",
       " 'अम्ले',\n",
       " 'या',\n",
       " 'नोंदीतील',\n",
       " '‘भौतिक',\n",
       " 'गुणधर्म’',\n",
       " 'हा',\n",
       " 'परिच्छेद',\n",
       " 'पहावा',\n",
       " '\\n',\n",
       " 'vyasapith',\n",
       " 'gmail',\n",
       " 'com',\n",
       " 'वर',\n",
       " 'तसेच',\n",
       " '‘प्रहार’च्या',\n",
       " 'संकेतस्थळावर',\n",
       " 'किंवा',\n",
       " 'प्रहारच्या',\n",
       " 'फेसबुक',\n",
       " 'पेजवरही',\n",
       " 'मत',\n",
       " 'नोंदवू',\n",
       " 'शकता',\n",
       " '\\n',\n",
       " 'प्रक्षेत्र',\n",
       " 'व्यवस्थापक',\n",
       " 'पुण्यश्लोक',\n",
       " 'अहिल्यादेवी',\n",
       " 'मेंढी',\n",
       " 'व',\n",
       " 'शेळी',\n",
       " 'विकास',\n",
       " 'प्रक्षेत्र',\n",
       " 'महूद',\n",
       " 'पो',\n",
       " '\\n',\n",
       " 'जुलै',\n",
       " 'टंकलेखन',\n",
       " 'लघुलेखन',\n",
       " 'संस्थाना',\n",
       " 'मान्यता',\n",
       " 'देनेबाबत',\n",
       " 'शिक्षणाधिकारी',\n",
       " 'माध्यमिक',\n",
       " 'व',\n",
       " 'शिक्षण',\n",
       " 'उपसंचालक',\n",
       " 'यांचेसाठी',\n",
       " 'संगणक',\n",
       " 'टायपिंग',\n",
       " 'अभ्यासक्रम',\n",
       " 'सुरु',\n",
       " 'करण्यासाठी',\n",
       " 'शासनमान्य',\n",
       " 'टंकलेखन',\n",
       " 'लघुलेखन',\n",
       " 'संस्थाना',\n",
       " 'शासनमान्यता',\n",
       " 'देणेबाबत',\n",
       " 'दि',\n",
       " '\\n',\n",
       " 'सदर',\n",
       " 'योजनेअंतर्गत',\n",
       " 'देय्य',\n",
       " 'अनुदान',\n",
       " 'हे',\n",
       " 'प्रतिवर्षी',\n",
       " 'शासनाकडुन',\n",
       " 'प्राप्त',\n",
       " 'मार्गदर्शक',\n",
       " 'सुचनानुसार',\n",
       " 'बदलते',\n",
       " 'असते',\n",
       " 'सदर',\n",
       " 'अनुदान',\n",
       " 'कमीत',\n",
       " 'कमी',\n",
       " 'ते',\n",
       " 'टक्के',\n",
       " 'किंवा',\n",
       " 'विशिष्ट',\n",
       " 'रक्कमेच्या',\n",
       " 'मर्यादेत',\n",
       " 'देय्य',\n",
       " 'असते',\n",
       " '\\n',\n",
       " 'कोटी',\n",
       " 'प्रवर्तकांचा',\n",
       " 'हिस्सा',\n",
       " 'दर्शनी',\n",
       " 'मूल्य',\n",
       " 'रु',\n",
       " '\\n',\n",
       " 'कोटी',\n",
       " 'रुपयांचा',\n",
       " 'निव्वळ',\n",
       " 'नफा',\n",
       " 'झाला',\n",
       " 'होता',\n",
       " '\\n',\n",
       " 'कोटी',\n",
       " 'रुपयांचे',\n",
       " 'प्रत्यक्ष',\n",
       " 'हप्ते',\n",
       " 'गोळा',\n",
       " 'केले',\n",
       " '\\n',\n",
       " 'दशलक्ष',\n",
       " 'टन',\n",
       " 'होते',\n",
       " '\\n',\n",
       " 'प्रतिशत',\n",
       " 'लागला',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'मार्च',\n",
       " 'रोजी',\n",
       " 'स्व',\n",
       " '\\n',\n",
       " 'या',\n",
       " 'महिनाभरातील',\n",
       " 'नीचांकी',\n",
       " 'पातळीवर',\n",
       " 'बंद',\n",
       " 'झाला',\n",
       " '\\n',\n",
       " 'अंकांवर',\n",
       " 'बंद',\n",
       " 'झाला',\n",
       " '\\n',\n",
       " 'कोटी',\n",
       " 'मतदार',\n",
       " 'आहेत',\n",
       " '\\n',\n",
       " 'जास्त',\n",
       " 'असते',\n",
       " '\\n',\n",
       " 'ला',\n",
       " 'अकरावीच्या',\n",
       " 'वर्गात',\n",
       " 'कॉम्पुटर',\n",
       " 'चा',\n",
       " 'दुसरा',\n",
       " 'तास',\n",
       " 'होता',\n",
       " '\\n',\n",
       " 'लाख',\n",
       " 'चक्रवाढ',\n",
       " 'रक्कम',\n",
       " 'अशी',\n",
       " 'असेल',\n",
       " 'व',\n",
       " '\\n',\n",
       " 'सर्वसाधारणत',\n",
       " 'गोल',\n",
       " 'व',\n",
       " 'घट्ट',\n",
       " 'पानांच्या',\n",
       " 'कोबीच्या',\n",
       " 'गड्ड्याला',\n",
       " 'बाजारात',\n",
       " 'जास्त',\n",
       " 'मागणी',\n",
       " 'असते',\n",
       " '\\n',\n",
       " 'दुसरी',\n",
       " 'लोकसभा',\n",
       " '\\n',\n",
       " 'ऑक्टोंबर',\n",
       " 'अन्वये',\n",
       " 'गठित',\n",
       " 'करण्यात',\n",
       " 'आलेल्या',\n",
       " 'हज',\n",
       " 'समितीवरील',\n",
       " 'सदस्यांचा',\n",
       " 'वर्षाचा',\n",
       " 'कालावधी',\n",
       " 'दि',\n",
       " '\\n',\n",
       " 'कोटी',\n",
       " 'इतकी',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'टक्के',\n",
       " 'मुंबई',\n",
       " 'उत्तर',\n",
       " 'पूर्व',\n",
       " 'म्हणजेच',\n",
       " 'ईशान्य',\n",
       " 'मुंबई',\n",
       " 'लोकसभा',\n",
       " 'मतदारसंघात',\n",
       " '\\n',\n",
       " 'लाख',\n",
       " 'कोटी',\n",
       " 'डॉलर्सपर्यंत',\n",
       " 'वाढेल',\n",
       " 'असा',\n",
       " 'अंदाजही',\n",
       " 'या',\n",
       " 'अहवालात',\n",
       " 'व्यक्त',\n",
       " 'करण्यात',\n",
       " 'आला',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'वर्ष',\n",
       " 'वयोगटातील',\n",
       " 'मुलांमधील',\n",
       " 'बाल',\n",
       " 'लिंग',\n",
       " 'गुणोत्तरातील',\n",
       " 'घट',\n",
       " 'लक्षात',\n",
       " 'घेऊन',\n",
       " 'महिला',\n",
       " 'आणि',\n",
       " 'बाल',\n",
       " 'विकास',\n",
       " 'मंत्रालयाने',\n",
       " 'बेटी',\n",
       " 'बचाओ',\n",
       " 'बेटी',\n",
       " 'पढाओ',\n",
       " 'कार्यक्रम',\n",
       " 'सुरू',\n",
       " 'केला',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'ऑक्टोबर',\n",
       " 'मंगळवार',\n",
       " 'औरंगाबाद',\n",
       " 'जालना',\n",
       " 'आवृत्ती',\n",
       " 'डॉ',\n",
       " '\\n',\n",
       " 'ऑक्टोबर',\n",
       " 'मध्य',\n",
       " 'रेल्वेच्या',\n",
       " 'डोंबिवली',\n",
       " 'रेल्वे',\n",
       " 'स्थानकातील',\n",
       " 'सरकत्या',\n",
       " 'जिन्याचं',\n",
       " 'उदघाटन',\n",
       " 'ठाणे',\n",
       " 'जिल्ह्याचे',\n",
       " 'पालकमंत्री',\n",
       " 'पालकमंत्री',\n",
       " 'गणेश',\n",
       " 'नाईक',\n",
       " 'यांच्या',\n",
       " 'हस्ते',\n",
       " 'आज',\n",
       " 'करण्यात',\n",
       " 'आले',\n",
       " '\\n',\n",
       " 'कोटी',\n",
       " 'मंजूर',\n",
       " 'झाले',\n",
       " '\\n',\n",
       " 'जुलै',\n",
       " 'पर्यंत',\n",
       " 'भरावी',\n",
       " 'त्यानंतर',\n",
       " 'सदर',\n",
       " 'माहिती',\n",
       " 'भरता',\n",
       " 'येणार',\n",
       " 'नाही',\n",
       " 'संगणक',\n",
       " 'टायपिंग',\n",
       " 'अभ्यासक्रम',\n",
       " 'पुस्तिका',\n",
       " 'Your',\n",
       " 'username',\n",
       " 'and',\n",
       " 'or',\n",
       " 'password',\n",
       " 'are',\n",
       " 'invalid',\n",
       " '\\n',\n",
       " 'पासून',\n",
       " 'बंद',\n",
       " 'आहे',\n",
       " '\\n',\n",
       " 'येथील',\n",
       " 'खडक',\n",
       " 'पाडा',\n",
       " 'चौकातून',\n",
       " 'गोदरेज',\n",
       " 'हिलकडे',\n",
       " 'जाणाऱ्या',\n",
       " 'रस्त्यावरील',\n",
       " 'खड्ड्यात',\n",
       " 'एक',\n",
       " 'मालवाहू',\n",
       " 'ट्रक',\n",
       " 'फसल्याची',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c3d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    sentences=tokenized_sentences,\n",
    "    vector_size=100,   # Dimensionality of the word vectors\n",
    "    window=5,          # Context window size\n",
    "    min_count=2,       # Ignores words with total frequency lower than this\n",
    "    workers=4,         # Number of CPU threads\n",
    "    sg=1               # 1 for skip-gram; 0 for CBOW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81b62cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"marathi_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dd13eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('माध्यमाच्या', 0.78094083070755), ('माध्यमिक', 0.7644445896148682), ('शाळांमध्ये', 0.7604185938835144), ('शाळेत', 0.7596253752708435), ('शाळांना', 0.7335298657417297), ('दवाखाना', 0.7293843030929565), ('खाजगी', 0.726482093334198), ('मुलींसाठी', 0.721418023109436), ('महाविद्यालये', 0.7198560833930969), ('शाळांत', 0.7174965739250183)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2310 (\\N{DEVANAGARI LETTER AA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2361 (\\N{DEVANAGARI LETTER HA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2375 (\\N{DEVANAGARI VOWEL SIGN E}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2339 (\\N{DEVANAGARI LETTER NNA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2351 (\\N{DEVANAGARI LETTER YA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2357 (\\N{DEVANAGARI LETTER VA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2360 (\\N{DEVANAGARI LETTER SA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2319 (\\N{DEVANAGARI LETTER E}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2346 (\\N{DEVANAGARI LETTER PA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2381 (\\N{DEVANAGARI SIGN VIRAMA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2350 (\\N{DEVANAGARI LETTER MA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2354 (\\N{DEVANAGARI LETTER LA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2370 (\\N{DEVANAGARI VOWEL SIGN UU}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2332 (\\N{DEVANAGARI LETTER JA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2358 (\\N{DEVANAGARI LETTER SHA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2355 (\\N{DEVANAGARI LETTER LLA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2333 (\\N{DEVANAGARI LETTER JHA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2330 (\\N{DEVANAGARI LETTER CA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2342 (\\N{DEVANAGARI LETTER DA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2341 (\\N{DEVANAGARI LETTER THA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2343 (\\N{DEVANAGARI LETTER DHA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2338 (\\N{DEVANAGARI LETTER DDHA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find similar words\n",
    "print(model.wv.most_similar(\"शाळा\"))  # Replace \"शाळा\" with any Marathi word in your corpus\n",
    "\n",
    "# Visualize embeddings using t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a subset of words\n",
    "words = list(model.wv.index_to_key)[:100]\n",
    "word_vectors = model.wv[words]\n",
    "\n",
    "# Reduce dimensionality\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "word_vectors_2d = tsne.fit_transform(word_vectors)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, word in enumerate(words):\n",
    "    plt.scatter(word_vectors_2d[i, 0], word_vectors_2d[i, 1])\n",
    "    plt.annotate(word, (word_vectors_2d[i, 0], word_vectors_2d[i, 1]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af11cbd3",
   "metadata": {},
   "source": [
    "## 2. Develop RNN-based Embeddings\n",
    "\n",
    "Next, we'll implement an RNN-based approach to learn word embeddings. This will involve defining an RNN model that learns embeddings via backpropagation and comparing the results with the Word2Vec approach.\n",
    "\n",
    "### Steps:\n",
    "- **RNN Model**: Define an RNN to learn embeddings.\n",
    "- **Train the Model**: Use the same corpus for training the RNN.\n",
    "- **Extract Embeddings**: Extract the learned embeddings from the RNN and analyze their quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9917cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "823e6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, Lambda\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15e937f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(13)\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "# Define a function to preprocess and extract sentences from a file\n",
    "def extract_sentences_from_file(file_path):\n",
    "    sentences = []\n",
    "    \n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Process each line\n",
    "    for line in lines:\n",
    "        # Remove leading numbers and spaces\n",
    "        line = re.sub(r'^\\d+\\s+', '', line)\n",
    "        # Remove numbers and symbols\n",
    "        sentence = re.sub(r'[०१२३४५६७८९0-9%]+', '', line)\n",
    "        # Add cleaned sentence to list if not empty\n",
    "        cleaned_sentence = sentence.strip()\n",
    "        if cleaned_sentence:\n",
    "            sentences.append(cleaned_sentence)\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# Usage example:\n",
    "file_path = \"/Users/sudarshan/courses/Neural_Modeling_Methods_&_Tool/W9L1/mar-in_web_2015_300K/mar-in_web_2015_300K-sentences.txt\"\n",
    "# file_path = 'path_to_your_file.txt'\n",
    "marathi_sentences = extract_sentences_from_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5dd03b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "print(len(marathi_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e28df227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Select 10,000 random sentences\n",
    "random_sentences = random.sample(marathi_sentences, 100)\n",
    "print(len(random_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "356479f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">901</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">91,001</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │        \u001b[38;5;34m90,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m901\u001b[0m)            │        \u001b[38;5;34m91,001\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">181,101</span> (707.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m181,101\u001b[0m (707.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">181,101</span> (707.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m181,101\u001b[0m (707.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(random_sentences)\n",
    "corpus = tokenizer.texts_to_sequences(random_sentences)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Function to generate training data\n",
    "def generate_data(corpus, window_size, V):\n",
    "    maxlen = window_size * 2\n",
    "    for words in corpus:\n",
    "        L = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            contexts = []\n",
    "            labels = []\n",
    "            s = index - window_size\n",
    "            e = index + window_size + 1\n",
    "\n",
    "            contexts.append([words[i] for i in range(s, e) if 0 <= i < L and i != index])\n",
    "            labels.append(word)\n",
    "\n",
    "            x = pad_sequences(contexts, maxlen=maxlen, padding='post')\n",
    "#             y = to_categorical(labels, V)\n",
    "            y = tf.keras.utils.to_categorical(labels, V)\n",
    "            yield (x, y)\n",
    "\n",
    "# Parameters for the embedding\n",
    "dim = 100\n",
    "window_size = 2\n",
    "V = vocab_size\n",
    "\n",
    "# Define the RNN-based embedding model (CBOW-style with mean aggregation)\n",
    "cbow = Sequential()\n",
    "cbow.add(Embedding(input_dim=V, output_dim=dim,input_shape=(window_size * 2,)))\n",
    "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(dim,)))\n",
    "cbow.add(Dense(V, activation='softmax'))\n",
    "\n",
    "cbow.summary()\n",
    "\n",
    "# Compile the model\n",
    "cbow.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777ada2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f36485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.77661657333374\n",
      "13.553037643432617\n",
      "20.32926368713379\n",
      "27.1052508354187\n",
      "33.88090419769287\n",
      "40.65572690963745\n",
      "47.43035364151001\n",
      "54.204795360565186\n",
      "60.97905731201172\n",
      "67.75274229049683\n",
      "74.52625465393066\n",
      "81.29957675933838\n",
      "88.07251596450806\n",
      "94.84495162963867\n",
      "101.61718559265137\n",
      "108.38922691345215\n",
      "115.16069269180298\n",
      "121.93119812011719\n",
      "128.70154190063477\n",
      "135.4717035293579\n",
      "142.24166345596313\n",
      "149.01142072677612\n",
      "155.7809977531433\n",
      "162.5503830909729\n",
      "169.31909370422363\n",
      "176.08617496490479\n",
      "182.85299921035767\n",
      "189.61889839172363\n",
      "196.38443517684937\n",
      "203.14979314804077\n",
      "209.91485738754272\n",
      "216.6797389984131\n",
      "223.44442415237427\n",
      "230.2088646888733\n",
      "236.97296285629272\n",
      "243.73634672164917\n",
      "250.49940156936646\n",
      "257.26228046417236\n",
      "264.0249843597412\n",
      "270.78716230392456\n",
      "277.54902696609497\n",
      "284.31053829193115\n",
      "291.0717911720276\n",
      "297.8328785896301\n",
      "304.5937695503235\n",
      "311.35447549819946\n",
      "318.1147360801697\n",
      "324.8748068809509\n",
      "331.634681224823\n",
      "338.39410638809204\n",
      "345.15335416793823\n",
      "351.9124011993408\n",
      "358.67106008529663\n",
      "365.4291000366211\n",
      "372.18687534332275\n",
      "378.9444770812988\n",
      "385.7017855644226\n",
      "392.45891857147217\n",
      "399.21579790115356\n",
      "405.9722399711609\n",
      "412.7278480529785\n",
      "419.48292112350464\n",
      "426.23783111572266\n",
      "432.99257707595825\n",
      "439.7471055984497\n",
      "446.50134563446045\n",
      "453.2551317214966\n",
      "460.0082936286926\n",
      "466.7612977027893\n",
      "473.513897895813\n",
      "480.2663288116455\n",
      "487.01860427856445\n",
      "493.77058506011963\n",
      "500.5223846435547\n",
      "507.27391624450684\n",
      "514.0241389274597\n",
      "520.773859500885\n",
      "527.5233502388\n",
      "534.2726879119873\n",
      "541.0218329429626\n",
      "547.7706379890442\n",
      "554.5192914009094\n",
      "561.2677898406982\n",
      "568.0161299705505\n",
      "574.7643275260925\n",
      "581.5123691558838\n",
      "588.2602362632751\n",
      "595.0076603889465\n",
      "601.7548003196716\n",
      "608.5005393028259\n",
      "615.2458863258362\n",
      "621.9909768104553\n",
      "628.7359204292297\n",
      "635.4807043075562\n",
      "642.2253112792969\n",
      "648.9697785377502\n",
      "655.7139430046082\n",
      "662.4579696655273\n",
      "669.2017517089844\n",
      "675.9446930885315\n",
      "682.687237739563\n",
      "689.429521560669\n",
      "696.1715197563171\n",
      "702.9130940437317\n",
      "709.6542921066284\n",
      "716.3952293395996\n",
      "723.1360168457031\n",
      "729.8766589164734\n",
      "736.6170797348022\n",
      "743.3573575019836\n",
      "750.0974855422974\n",
      "756.8374614715576\n",
      "763.5771794319153\n",
      "770.3167147636414\n",
      "777.0553607940674\n",
      "783.7935523986816\n",
      "790.5313582420349\n",
      "797.2687363624573\n",
      "804.0051374435425\n",
      "810.7412900924683\n",
      "817.4772987365723\n",
      "824.2131581306458\n",
      "830.9488716125488\n",
      "837.6844711303711\n",
      "844.4197268486023\n",
      "851.1548461914062\n",
      "857.8898258209229\n",
      "864.6245603561401\n",
      "871.3578033447266\n",
      "878.0906028747559\n",
      "884.8231272697449\n",
      "891.555504322052\n",
      "898.2877616882324\n",
      "905.0198874473572\n",
      "911.751829624176\n",
      "918.4836492538452\n",
      "925.2153191566467\n",
      "931.9468522071838\n",
      "938.6782579421997\n",
      "945.4094095230103\n",
      "952.1403503417969\n",
      "958.8709855079651\n",
      "965.6009373664856\n",
      "972.3305816650391\n",
      "979.0599384307861\n",
      "985.7890577316284\n",
      "992.5180139541626\n",
      "999.2468304634094\n",
      "1005.97536277771\n",
      "1012.7036695480347\n",
      "1019.4317965507507\n",
      "1026.1597833633423\n",
      "1032.8874716758728\n",
      "1039.6148991584778\n",
      "1046.3407292366028\n",
      "1053.066219329834\n",
      "1059.7912583351135\n",
      "1066.5161666870117\n",
      "1073.2406787872314\n",
      "1079.9650354385376\n",
      "1086.6890802383423\n",
      "1093.4129815101624\n",
      "1100.1366653442383\n",
      "1106.8601899147034\n",
      "1113.58358335495\n",
      "1120.3068165779114\n",
      "1127.0296421051025\n",
      "1133.7522659301758\n",
      "1140.4747514724731\n",
      "1147.197108745575\n",
      "1153.9192633628845\n",
      "1160.64110994339\n",
      "1167.3624262809753\n",
      "1174.08349943161\n",
      "1180.8041815757751\n",
      "1187.5245661735535\n",
      "1194.2446103096008\n",
      "1200.9643635749817\n",
      "1207.6838426589966\n",
      "1214.4031710624695\n",
      "1221.1222863197327\n",
      "1227.8409366607666\n",
      "1234.559310913086\n",
      "1241.2774691581726\n",
      "1247.9953436851501\n",
      "1254.7131266593933\n",
      "1261.430790424347\n",
      "1268.1483249664307\n",
      "1274.8657417297363\n",
      "1281.58305311203\n",
      "1288.3002462387085\n",
      "1295.017292022705\n",
      "1301.7342004776\n",
      "1308.4509949684143\n",
      "1315.167649269104\n",
      "1321.8841533660889\n",
      "1328.6005358695984\n",
      "1335.316785812378\n",
      "1342.0328335762024\n",
      "1348.7479634284973\n",
      "1355.4627661705017\n",
      "1362.176923751831\n",
      "1368.8908729553223\n",
      "1375.6045484542847\n",
      "1382.3177609443665\n",
      "1389.0308647155762\n",
      "1395.743787765503\n",
      "1402.4563837051392\n",
      "1409.1685528755188\n",
      "1415.8805141448975\n",
      "1422.5922546386719\n",
      "1429.303849697113\n",
      "1436.0153393745422\n",
      "1442.7267384529114\n",
      "1449.4379982948303\n",
      "1456.1490731239319\n",
      "1462.8598647117615\n",
      "1469.5703854560852\n",
      "1476.2807426452637\n",
      "1482.9909992218018\n",
      "1489.701141834259\n",
      "1496.4111614227295\n",
      "1503.1210713386536\n",
      "1509.8307428359985\n",
      "1516.5402998924255\n",
      "1523.2497291564941\n",
      "1529.9590396881104\n",
      "1536.6682085990906\n",
      "1543.377260684967\n",
      "1550.0861687660217\n",
      "1556.7948937416077\n",
      "1563.503026008606\n",
      "1570.2108807563782\n",
      "1576.9185619354248\n",
      "1583.626121520996\n",
      "1590.3335313796997\n",
      "1597.0408191680908\n",
      "1603.7479968070984\n",
      "1610.4550619125366\n",
      "1617.161572933197\n",
      "1623.8676776885986\n",
      "1630.573492050171\n",
      "1637.2791471481323\n",
      "1643.9846820831299\n",
      "1650.6900968551636\n",
      "1657.395369052887\n",
      "1664.099781513214\n",
      "1670.803195476532\n",
      "1677.5065026283264\n",
      "1684.2096915245056\n",
      "1690.9127645492554\n",
      "1697.6157150268555\n",
      "1704.318540096283\n",
      "1711.0212426185608\n",
      "1717.723503112793\n",
      "1724.4255414009094\n",
      "1731.1274423599243\n",
      "1737.8292078971863\n",
      "1744.530843257904\n",
      "1751.232343196869\n",
      "1757.9337048530579\n",
      "1764.6349186897278\n",
      "1771.3359951972961\n",
      "1778.0369205474854\n",
      "1784.7377066612244\n",
      "1791.4383430480957\n",
      "1798.1388516426086\n",
      "1804.8392181396484\n",
      "1811.539216518402\n",
      "1818.2390093803406\n",
      "1824.938663482666\n",
      "1831.6381859779358\n",
      "1838.3375716209412\n",
      "1845.0368008613586\n",
      "1851.735800743103\n",
      "1858.4346027374268\n",
      "1865.133282661438\n",
      "1871.8318400382996\n",
      "1878.5302777290344\n",
      "1885.2286086082458\n",
      "1891.9268345832825\n",
      "1898.624828338623\n",
      "1905.321283340454\n",
      "1912.0175385475159\n",
      "1918.7136616706848\n",
      "1925.4096689224243\n",
      "1932.105547428131\n",
      "1938.8011898994446\n",
      "1945.49666929245\n",
      "1952.1920409202576\n",
      "1958.8872799873352\n",
      "1965.582365989685\n",
      "1972.2772789001465\n",
      "1978.9720406532288\n",
      "1985.6666831970215\n",
      "1992.3612003326416\n",
      "1999.0555982589722\n",
      "2005.7498669624329\n",
      "2012.4440035820007\n",
      "2019.1380290985107\n",
      "2025.8319272994995\n",
      "2032.5257124900818\n",
      "2039.2193870544434\n",
      "2045.9129328727722\n",
      "2052.606334209442\n",
      "2059.2996406555176\n",
      "2065.9927768707275\n",
      "2072.6857738494873\n",
      "2079.3786578178406\n",
      "2086.0714530944824\n",
      "2092.7641110420227\n",
      "2099.45654296875\n",
      "2106.1487379074097\n",
      "2112.8407649993896\n",
      "2119.5326166152954\n",
      "2126.224380493164\n",
      "2132.9156455993652\n",
      "2139.606819629669\n",
      "2146.2978887557983\n",
      "2152.9888644218445\n",
      "2159.6797437667847\n",
      "2166.3705434799194\n",
      "2173.0610637664795\n",
      "2179.751474380493\n",
      "2186.4417762756348\n",
      "2193.131974220276\n",
      "2199.822075843811\n",
      "2206.512065410614\n",
      "2213.2019391059875\n",
      "2219.891703605652\n",
      "2226.5813217163086\n",
      "2233.270842075348\n",
      "2239.960256576538\n",
      "2246.649567127228\n",
      "2253.3387427330017\n",
      "2260.0277819633484\n",
      "2266.7167077064514\n",
      "2273.40554523468\n",
      "2280.0942521095276\n",
      "2286.782777786255\n",
      "2293.4712147712708\n",
      "2300.159547805786\n",
      "2306.8477730751038\n",
      "2313.5358724594116\n",
      "2320.2238731384277\n",
      "2326.911771297455\n",
      "2333.5995950698853\n",
      "2340.2873482704163\n",
      "2346.9745688438416\n",
      "2353.661509990692\n",
      "2360.34836101532\n",
      "2367.035096168518\n",
      "2373.7201676368713\n",
      "2380.404986858368\n",
      "2387.0897092819214\n",
      "2393.7743196487427\n",
      "2400.458830833435\n",
      "2407.1432461738586\n",
      "2413.8275632858276\n",
      "2420.511791706085\n",
      "2427.195887565613\n",
      "2433.879316806793\n",
      "2440.5626635551453\n",
      "2447.2459177970886\n",
      "2453.929085254669\n",
      "2460.612126350403\n",
      "2467.295051574707\n",
      "2473.9777750968933\n",
      "2480.6604137420654\n",
      "2487.342969894409\n",
      "2494.024874687195\n",
      "2500.7050909996033\n",
      "2507.3851795196533\n",
      "2514.0651631355286\n",
      "2520.745051383972\n",
      "2527.424409866333\n",
      "2534.1037015914917\n",
      "2540.7829279899597\n",
      "2547.462116241455\n",
      "2554.1412420272827\n",
      "2560.8201355934143\n",
      "2567.4980940818787\n",
      "2574.175910949707\n",
      "2580.8535737991333\n",
      "2587.531150341034\n",
      "2594.2086277008057\n",
      "2600.886006832123\n",
      "2607.5633029937744\n",
      "2614.24049949646\n",
      "2620.9176058769226\n",
      "2627.594570159912\n",
      "2634.2714262008667\n",
      "2640.9481654167175\n",
      "2647.6247935295105\n",
      "2654.3013195991516\n",
      "2660.977743625641\n",
      "2667.6540842056274\n",
      "2674.3303275108337\n",
      "2681.006504058838\n",
      "2687.682544708252\n",
      "2694.3579654693604\n",
      "2701.033317089081\n",
      "2707.7085723876953\n",
      "2714.3837389945984\n",
      "2721.0588364601135\n",
      "2727.7338576316833\n",
      "2734.4085125923157\n",
      "2741.0831174850464\n",
      "2747.7576627731323\n",
      "2754.4321188926697\n",
      "2761.1048855781555\n",
      "2767.777581691742\n",
      "2774.4502472877502\n",
      "2781.122820854187\n",
      "2787.7953391075134\n",
      "2794.4676027297974\n",
      "2801.1395859718323\n",
      "2807.811158180237\n",
      "2814.48264503479\n",
      "2821.154037475586\n",
      "2827.8253378868103\n",
      "2834.4965534210205\n",
      "2841.1676721572876\n",
      "2847.8386554718018\n",
      "2854.509537220001\n",
      "2861.180320739746\n",
      "2867.851044654846\n",
      "2874.5215191841125\n",
      "2881.1919078826904\n",
      "2887.8622393608093\n",
      "2894.5324959754944\n",
      "2901.2026810646057\n",
      "2907.872821331024\n",
      "2914.542606830597\n",
      "2921.2123608589172\n",
      "2927.8803453445435\n",
      "2934.548312664032\n",
      "2941.216245174408\n",
      "2947.8840980529785\n",
      "2954.5517859458923\n",
      "2961.2193970680237\n",
      "2967.886933326721\n",
      "2974.5540862083435\n",
      "2981.2212195396423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2987.8882489204407\n",
      "2994.5552320480347\n",
      "3001.222210407257\n",
      "3007.8887042999268\n",
      "3014.555127620697\n",
      "3021.2212147712708\n",
      "3027.887255191803\n",
      "3034.553099155426\n",
      "3041.2188873291016\n",
      "3047.8845958709717\n",
      "3054.5502219200134\n",
      "3061.2157850265503\n",
      "3067.8812527656555\n",
      "3074.546633720398\n",
      "3081.2119274139404\n",
      "3087.8771238327026\n",
      "3094.542236328125\n",
      "3101.207275390625\n",
      "3107.872220993042\n",
      "3114.5371828079224\n",
      "3121.2021021842957\n",
      "3127.8669991493225\n",
      "3134.531819820404\n",
      "3141.196539878845\n",
      "3147.8611931800842\n",
      "3154.525763988495\n",
      "3161.1902656555176\n",
      "3167.8546957969666\n",
      "3174.519070148468\n",
      "3181.1833806037903\n",
      "3187.847553253174\n",
      "3194.5101017951965\n",
      "3201.172686100006\n",
      "3207.8348054885864\n",
      "3214.4968643188477\n",
      "3221.158899307251\n",
      "3227.8197717666626\n",
      "3234.4806842803955\n",
      "3241.1414279937744\n",
      "3247.8021850585938\n",
      "3254.4626183509827\n",
      "3261.1230120658875\n",
      "3267.783067703247\n",
      "3274.4412908554077\n",
      "3281.0994625091553\n",
      "3287.7576265335083\n",
      "3294.4157209396362\n",
      "3301.0737957954407\n",
      "3307.7318387031555\n",
      "3314.3898587226868\n",
      "3321.0474395751953\n",
      "3327.7045192718506\n",
      "3334.361636161804\n",
      "3341.018753051758\n",
      "3347.675806045532\n",
      "3354.3327918052673\n",
      "3360.989649295807\n",
      "3367.646352291107\n",
      "3374.303003311157\n",
      "3380.9596076011658\n",
      "3387.6161646842957\n",
      "3394.2726740837097\n",
      "3400.929130077362\n",
      "3407.585500717163\n",
      "3414.241885662079\n",
      "3420.8982920646667\n",
      "3427.55464220047\n",
      "3434.210620880127\n",
      "3440.866563796997\n",
      "3447.5222058296204\n",
      "3454.1778078079224\n",
      "3460.833381652832\n",
      "3467.4889454841614\n",
      "3474.144495487213\n",
      "3480.799889087677\n",
      "3487.45499420166\n",
      "3494.1101093292236\n",
      "3500.7652344703674\n",
      "3507.420347213745\n",
      "3514.0741314888\n",
      "3520.727919101715\n",
      "3527.3817114830017\n",
      "3534.035436630249\n",
      "3540.6890988349915\n",
      "3547.3427205085754\n",
      "3553.996295928955\n",
      "3560.6498947143555\n",
      "3567.3028979301453\n",
      "3573.955952167511\n",
      "3580.609006881714\n",
      "3587.2619881629944\n",
      "3593.914774417877\n",
      "3600.567512512207\n",
      "3607.220248222351\n",
      "3613.8729763031006\n",
      "3620.5254426002502\n",
      "3627.17756319046\n",
      "3633.8296332359314\n",
      "3640.4816856384277\n",
      "3647.1337447166443\n",
      "3653.7857608795166\n",
      "3660.437728881836\n",
      "3667.089698791504\n",
      "3673.7400336265564\n",
      "3680.390009880066\n",
      "3687.0400066375732\n",
      "3693.689905166626\n",
      "3700.339735031128\n",
      "3706.989505290985\n",
      "3713.639211654663\n",
      "3720.28892993927\n",
      "3726.9387135505676\n",
      "3733.58855676651\n",
      "3740.23842048645\n",
      "3746.888223171234\n",
      "3753.5379724502563\n",
      "3760.187689304352\n",
      "3766.8373804092407\n",
      "3773.4870495796204\n",
      "3780.1363520622253\n",
      "3786.7848291397095\n",
      "3793.433382511139\n",
      "3800.0814294815063\n",
      "3806.7294921875\n",
      "3813.377510547638\n",
      "3820.0255069732666\n",
      "3826.673448562622\n",
      "3833.321322441101\n",
      "3839.969229221344\n",
      "3846.6171984672546\n",
      "3853.265190601349\n",
      "3859.913197994232\n",
      "3866.56116437912\n",
      "3873.209071159363\n",
      "3879.856964111328\n",
      "3886.5048451423645\n",
      "3893.1526985168457\n",
      "3899.800494670868\n",
      "3906.448036670685\n",
      "3913.0955805778503\n",
      "3919.743182659149\n",
      "3926.3909254074097\n",
      "3933.038727760315\n",
      "3939.68652677536\n",
      "3946.3342666625977\n",
      "3952.9819626808167\n",
      "3959.629596233368\n",
      "3966.2771735191345\n",
      "3972.9247093200684\n",
      "3979.5722818374634\n",
      "3986.219952106476\n",
      "3992.8677287101746\n",
      "3999.515564441681\n",
      "4006.1632118225098\n",
      "4012.810905456543\n",
      "4019.4587540626526\n",
      "4026.106695175171\n",
      "4032.754699230194\n",
      "4039.402656555176\n",
      "4046.050575733185\n",
      "4052.6982865333557\n",
      "4059.345977783203\n",
      "4065.9936175346375\n",
      "4072.6412224769592\n",
      "4079.2887444496155\n",
      "4085.9361958503723\n",
      "4092.583484172821\n",
      "4099.23069858551\n",
      "4105.877822875977\n",
      "4112.5248827934265\n",
      "4119.171875476837\n",
      "4125.818798065186\n",
      "4132.465658664703\n",
      "4139.1124567985535\n",
      "4145.759197235107\n",
      "4152.405879497528\n",
      "4159.05250453949\n",
      "4165.699074268341\n",
      "4172.3455810546875\n",
      "4178.991894245148\n",
      "4185.638157367706\n",
      "4192.284394264221\n",
      "4198.930629253387\n",
      "4205.576953411102\n",
      "4212.2225613594055\n",
      "4218.868267059326\n",
      "4225.514029979706\n",
      "4232.159841060638\n",
      "4238.805570602417\n",
      "4245.451401233673\n",
      "4252.09725856781\n",
      "4258.743057727814\n",
      "4265.388819694519\n",
      "4272.034530162811\n",
      "4278.68018913269\n",
      "4285.3258147239685\n",
      "4291.971432209015\n",
      "4298.617049217224\n",
      "4305.262660503387\n",
      "4311.908320903778\n",
      "4318.5538239479065\n",
      "4325.199420452118\n",
      "4331.843343257904\n",
      "4338.487359046936\n",
      "4345.131412029266\n",
      "4351.77534532547\n",
      "4358.41925239563\n",
      "4365.063157081604\n",
      "4371.707082271576\n",
      "4378.350910186768\n",
      "4384.994585037231\n",
      "4391.638247013092\n",
      "4398.281904697418\n",
      "4404.925535202026\n",
      "4411.569123268127\n",
      "4418.212682723999\n",
      "4424.856219291687\n",
      "4431.499767303467\n",
      "4438.143085479736\n",
      "4444.786386013031\n",
      "4451.429691791534\n",
      "4458.07297706604\n",
      "4464.716228961945\n",
      "4471.3594489097595\n",
      "4478.002640247345\n",
      "4484.645784378052\n",
      "4491.288894176483\n",
      "4497.932011127472\n",
      "4504.57515668869\n",
      "4511.218305110931\n",
      "4517.861523151398\n",
      "4524.503891944885\n",
      "4531.146347045898\n",
      "4537.788833618164\n",
      "4544.4313015937805\n",
      "4551.073792934418\n",
      "4557.716348171234\n",
      "4564.358626365662\n",
      "4571.000965118408\n",
      "4577.643333435059\n",
      "4584.285598278046\n",
      "4590.927759647369\n",
      "4597.569843292236\n",
      "4604.211687088013\n",
      "4610.853281021118\n",
      "4617.494864940643\n",
      "4624.136326313019\n",
      "4630.777747631073\n",
      "4637.419155597687\n",
      "4644.060629367828\n",
      "4650.702136516571\n",
      "4657.343683719635\n",
      "4663.985210895538\n",
      "4670.626805305481\n",
      "4677.268002986908\n",
      "4683.90929889679\n",
      "4690.550626754761\n",
      "4697.191940784454\n",
      "4703.833243370056\n",
      "4710.474510192871\n",
      "4717.115752696991\n",
      "4723.757061004639\n",
      "4730.398048400879\n",
      "4737.039077758789\n",
      "4743.680111885071\n",
      "4750.321162700653\n",
      "4756.962186336517\n",
      "4763.603176116943\n",
      "4770.244149208069\n",
      "4776.885122299194\n",
      "4783.5261697769165\n",
      "4790.166460514069\n",
      "4796.806238651276\n",
      "4803.446092605591\n",
      "4810.085934638977\n",
      "4816.725761413574\n",
      "4823.365636348724\n",
      "4830.005472660065\n",
      "4836.645285606384\n",
      "4843.2850794792175\n",
      "4849.924882411957\n",
      "4856.564702987671\n",
      "4863.20449590683\n",
      "4869.844207286835\n",
      "4876.483439922333\n",
      "4883.122272968292\n",
      "4889.761096954346\n",
      "4896.3999581336975\n",
      "4903.03893327713\n",
      "4909.676742553711\n",
      "4916.314656734467\n",
      "4922.95263004303\n",
      "4929.5905838012695\n",
      "4936.228515625\n",
      "4942.866462230682\n",
      "4949.504101276398\n",
      "4956.141791820526\n",
      "4962.779500484467\n",
      "4969.417258739471\n",
      "4976.055042743683\n",
      "4982.692852973938\n",
      "4989.330418586731\n",
      "4995.967967987061\n",
      "5002.605550765991\n",
      "5009.24313211441\n",
      "5015.880730628967\n",
      "5022.5179715156555\n",
      "5029.155151844025\n",
      "5035.792427539825\n",
      "5042.429491519928\n",
      "5049.066556930542\n",
      "5055.703592300415\n",
      "5062.34060049057\n",
      "5068.977601528168\n",
      "5075.614564418793\n",
      "5082.251489639282\n",
      "5088.888397693634\n",
      "5095.525289058685\n",
      "5102.162178039551\n",
      "5108.799072265625\n",
      "5115.435935020447\n",
      "5122.072751998901\n",
      "5128.709529876709\n",
      "5135.346353054047\n",
      "5141.983253002167\n",
      "5148.620254516602\n",
      "5155.257329940796\n",
      "5161.894426345825\n",
      "5168.531512260437\n",
      "5175.168619632721\n",
      "5181.805748939514\n",
      "5188.442911624908\n",
      "5195.08011007309\n",
      "5201.717355251312\n",
      "5208.354305744171\n",
      "5214.991292953491\n",
      "5221.628326892853\n",
      "5228.265435695648\n",
      "5234.902475833893\n",
      "5241.5395154953\n",
      "5248.175127029419\n",
      "5254.810820102692\n",
      "5261.446571350098\n",
      "5268.082360744476\n",
      "5274.718221664429\n",
      "5281.3538699150085\n",
      "5287.9896059036255\n",
      "5294.62517118454\n",
      "5301.260818004608\n",
      "5307.895923137665\n",
      "5314.530566215515\n",
      "5321.165287971497\n",
      "5327.800172328949\n",
      "5334.435168266296\n",
      "5341.070239067078\n",
      "5347.705320358276\n",
      "5354.340392112732\n",
      "5360.97549200058\n",
      "5367.610374927521\n",
      "5374.245306015015\n",
      "5380.880327224731\n",
      "5387.5147976875305\n",
      "5394.149435997009\n",
      "5400.7841510772705\n",
      "5407.418610095978\n",
      "5414.05285692215\n",
      "5420.687126636505\n",
      "5427.321433544159\n",
      "5433.955586433411\n",
      "5440.589807033539\n",
      "5447.224086284637\n",
      "5453.8584179878235\n",
      "5460.49237203598\n",
      "5467.1253933906555\n",
      "5473.758521080017\n",
      "5480.391713142395\n",
      "5487.024904727936\n",
      "5493.658119678497\n",
      "5500.291337966919\n",
      "5506.924558639526\n",
      "5513.557831764221\n",
      "5520.1911363601685\n",
      "5526.82443189621\n",
      "5533.457169532776\n",
      "5540.089599132538\n",
      "5546.722093582153\n",
      "5553.354651927948\n",
      "5559.987273693085\n",
      "5566.619806289673\n",
      "5573.2521595954895\n",
      "5579.884556293488\n",
      "5586.517009735107\n",
      "5593.149525642395\n",
      "5599.782113075256\n",
      "5606.413757324219\n",
      "5613.0455594062805\n",
      "5619.677474498749\n",
      "5626.309059619904\n",
      "5632.940697669983\n",
      "5639.5722398757935\n",
      "5646.203893661499\n",
      "5652.835352420807\n",
      "5659.466913700104\n",
      "5666.098578453064\n",
      "5672.730268955231\n",
      "5679.362002849579\n",
      "5685.993797779083\n",
      "5692.625495433807\n",
      "5699.257237434387\n",
      "5705.889021396637\n",
      "5712.520837306976\n",
      "5719.1524477005005\n",
      "5725.784071922302\n",
      "5732.415692329407\n",
      "5739.047103404999\n",
      "5745.678598403931\n",
      "5752.309474468231\n",
      "5758.940465927124\n",
      "5765.571509838104\n",
      "5772.20258808136\n",
      "5778.833705425262\n",
      "5785.464712142944\n",
      "5792.0952796936035\n",
      "5798.725917816162\n",
      "5805.356613636017\n",
      "5811.987364292145\n",
      "5818.6181383132935\n",
      "5825.2489585876465\n",
      "5831.879803657532\n",
      "5838.510680198669\n",
      "5845.141613960266\n",
      "5851.772494792938\n",
      "5858.403055667877\n",
      "5865.033760070801\n",
      "5871.664551734924\n",
      "5878.295394420624\n",
      "5884.926271438599\n",
      "5891.55721950531\n",
      "5898.188282489777\n",
      "5904.819424152374\n",
      "5911.450660705566\n",
      "5918.081907272339\n",
      "5924.7131996154785\n",
      "5931.344551086426\n",
      "5937.97593832016\n",
      "5944.607374668121\n",
      "5951.238579750061\n",
      "5957.869841575623\n",
      "5964.500797748566\n",
      "5971.131692409515\n",
      "5977.761919021606\n",
      "5984.392230510712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5991.022585391998\n",
      "5997.653008937836\n",
      "6004.28351688385\n",
      "6010.914085388184\n",
      "6017.544734954834\n",
      "6024.174852848053\n",
      "6030.8048939704895\n",
      "6037.435022354126\n",
      "6044.0653557777405\n",
      "6050.69554567337\n",
      "6057.325837612152\n",
      "6063.956182479858\n",
      "6070.586591720581\n",
      "6077.217051029205\n",
      "6083.847570896149\n",
      "6090.478154659271\n",
      "6097.108506679535\n",
      "6103.738454818726\n",
      "6110.367980957031\n",
      "6116.997611999512\n",
      "6123.627311706543\n",
      "6130.257044792175\n",
      "6136.886847496033\n",
      "6143.516707897186\n",
      "6150.146674156189\n",
      "6156.776006221771\n",
      "6163.405471324921\n",
      "6170.03503704071\n",
      "6176.664663314819\n",
      "6183.294397830963\n",
      "6189.923094749451\n",
      "6196.551862716675\n",
      "6203.180698871613\n",
      "6209.809567928314\n",
      "6216.438471317291\n",
      "6223.067437648773\n",
      "6229.6964955329895\n",
      "6236.3251366615295\n",
      "6242.953901767731\n",
      "6249.582754135132\n",
      "6256.211694717407\n",
      "6262.840646743774\n",
      "6269.469641685486\n",
      "6276.098705768585\n",
      "6282.727883338928\n",
      "6289.356083869934\n",
      "6295.984237670898\n",
      "6302.612251281738\n",
      "6309.240010738373\n",
      "6315.867201328278\n",
      "6322.494318008423\n",
      "6329.121527671814\n",
      "6335.748794555664\n",
      "6342.376103401184\n",
      "6349.00346660614\n",
      "6355.630895614624\n",
      "6362.258257389069\n",
      "6368.885680675507\n",
      "6375.513159751892\n",
      "6382.140702724457\n",
      "6388.768301010132\n",
      "6395.395957946777\n",
      "6402.023667812347\n",
      "6408.651421546936\n",
      "6415.279222488403\n",
      "6421.90706205368\n",
      "6428.534961223602\n",
      "6435.1629095077515\n",
      "6441.790877819061\n",
      "6448.418869018555\n",
      "6455.046861171722\n",
      "6461.674909591675\n",
      "6468.303027629852\n",
      "6474.931032180786\n",
      "6481.557728767395\n",
      "6488.184302806854\n",
      "6494.810981273651\n",
      "6501.437729358673\n",
      "6508.064530849457\n",
      "6514.69143819809\n",
      "6521.318478107452\n",
      "6527.944944858551\n",
      "6534.571230888367\n",
      "6541.197609901428\n",
      "6547.824037075043\n",
      "6554.450553417206\n",
      "6561.077148914337\n",
      "6567.703837394714\n",
      "6574.330198764801\n",
      "6580.956649303436\n",
      "6587.583055973053\n",
      "6594.209072113037\n",
      "6600.834857463837\n",
      "6607.460595607758\n",
      "6614.086450576782\n",
      "6620.712384223938\n",
      "6627.338241577148\n",
      "6633.963763713837\n",
      "6640.589040756226\n",
      "6647.214359760284\n",
      "6653.8394474983215\n",
      "6660.464179515839\n",
      "6667.088963031769\n",
      "6673.7138085365295\n",
      "6680.3386516571045\n",
      "6686.963578701019\n",
      "6693.588552951813\n",
      "6700.21360206604\n",
      "6706.838284492493\n",
      "6713.46274805069\n",
      "6720.087247371674\n",
      "6726.711847782135\n",
      "6733.336062431335\n",
      "6739.9604845047\n",
      "6746.585032939911\n",
      "6753.20938205719\n",
      "6759.833870887756\n",
      "6766.458016872406\n",
      "6773.082279682159\n",
      "6779.706653594971\n",
      "6786.331123352051\n",
      "6792.955487728119\n",
      "6799.579251289368\n",
      "6806.203134059906\n",
      "6812.827107429504\n",
      "6819.451173782349\n",
      "6826.075338840485\n",
      "6832.699010372162\n",
      "6839.322893619537\n",
      "6845.9462060928345\n",
      "6852.569658756256\n",
      "6859.193058013916\n",
      "6865.816534042358\n",
      "6872.4400844573975\n",
      "6879.063720703125\n",
      "6885.687171936035\n",
      "6892.310710906982\n",
      "6898.933810710907\n",
      "6905.5569767951965\n",
      "6912.180238246918\n",
      "6918.803599357605\n",
      "6925.42696762085\n",
      "6932.050423622131\n",
      "6938.673991203308\n",
      "6945.29768371582\n",
      "6951.920704841614\n",
      "6958.543823719025\n",
      "6965.167063236237\n",
      "6971.790376663208\n",
      "6978.413456916809\n",
      "6985.0366287231445\n",
      "6991.659884929657\n",
      "6998.2832407951355\n",
      "7004.906697750092\n",
      "7011.530250549316\n",
      "7018.153907775879\n",
      "7024.777626991272\n",
      "7031.401379108429\n",
      "7038.025169849396\n",
      "7044.6490178108215\n",
      "7051.272888660431\n",
      "7057.896803855896\n",
      "7064.5207686424255\n",
      "7071.144778251648\n",
      "7077.768830299377\n",
      "7084.392921924591\n",
      "7091.017077445984\n",
      "7097.641290664673\n",
      "7104.265360832214\n",
      "7110.889501571655\n",
      "7117.513733386993\n",
      "7124.138068199158\n",
      "7130.762150287628\n",
      "7137.386240005493\n",
      "7144.010432243347\n",
      "7150.634455680847\n",
      "7157.258605003357\n",
      "7163.882856369019\n",
      "7170.507310390472\n",
      "7177.131375312805\n",
      "7183.754951953888\n",
      "7190.377233505249\n",
      "7196.998791694641\n",
      "7203.620488166809\n",
      "7210.242303848267\n",
      "7216.864229679108\n",
      "7223.486092567444\n",
      "7230.10804605484\n",
      "7236.7300934791565\n",
      "7243.352259635925\n",
      "7249.974510669708\n",
      "7256.596880912781\n",
      "7263.21826171875\n",
      "7269.839723587036\n",
      "7276.460731983185\n",
      "7283.081811904907\n",
      "7289.703016757965\n",
      "7296.323809623718\n",
      "7302.94469165802\n",
      "7309.565725326538\n",
      "7316.186727523804\n",
      "7322.807794570923\n",
      "7329.428946495056\n",
      "7336.050194740295\n",
      "7342.671540260315\n",
      "7349.2929701805115\n",
      "7355.9141497612\n",
      "7362.535434246063\n",
      "7369.156825065613\n",
      "7375.778301239014\n",
      "7382.3993282318115\n",
      "7389.019775390625\n",
      "7395.640012264252\n",
      "7402.260031223297\n",
      "7408.880087852478\n",
      "7415.500144481659\n",
      "7422.120252132416\n",
      "7428.740405082703\n",
      "7435.360594749451\n",
      "7441.980849742889\n",
      "7448.601197719574\n",
      "7455.2216691970825\n",
      "7461.841973781586\n",
      "7468.461973190308\n",
      "7475.082068443298\n",
      "7481.702085018158\n",
      "7488.322195529938\n",
      "7494.942391872406\n",
      "7501.562397480011\n",
      "7508.182351112366\n",
      "7514.8023982048035\n",
      "7521.422405719757\n",
      "7528.04258108139\n",
      "7534.662641525269\n",
      "7541.282356739044\n",
      "7547.9022097587585\n",
      "7554.522196292877\n",
      "7561.142246723175\n",
      "7567.762459278107\n",
      "7574.3823137283325\n",
      "7581.001720428467\n",
      "7587.621286869049\n",
      "7594.240983963013\n",
      "7600.86075925827\n",
      "7607.4806027412415\n",
      "7614.1004157066345\n",
      "7620.720322132111\n",
      "7627.340341567993\n",
      "7633.960346698761\n",
      "7640.580280303955\n",
      "7647.2003564834595\n",
      "7653.820372581482\n",
      "7660.439903259277\n",
      "7667.05907201767\n",
      "7673.678367137909\n",
      "7680.297765254974\n",
      "7686.917267799377\n",
      "7693.536424636841\n",
      "7700.155036449432\n",
      "7706.772324085236\n",
      "Epoch 1/2, Loss: 7706.7723\n",
      "6.61667013168335\n",
      "13.233193397521973\n",
      "19.84955644607544\n",
      "26.46572971343994\n",
      "33.08170747756958\n",
      "39.696988105773926\n",
      "46.31212568283081\n",
      "52.92712163925171\n",
      "59.541991233825684\n",
      "66.15624666213989\n",
      "72.77038526535034\n",
      "79.38436698913574\n",
      "85.99797248840332\n",
      "92.6110429763794\n",
      "99.22393751144409\n",
      "105.83666944503784\n",
      "112.44898223876953\n",
      "119.06044387817383\n",
      "125.67179107666016\n",
      "132.28297662734985\n",
      "138.89395380020142\n",
      "145.50472736358643\n",
      "152.11535215377808\n",
      "158.72582292556763\n",
      "165.33562660217285\n",
      "171.94409084320068\n",
      "178.55239582061768\n",
      "185.159818649292\n",
      "191.76686334609985\n",
      "198.37375736236572\n",
      "204.98041009902954\n",
      "211.5869016647339\n",
      "218.19319486618042\n",
      "224.7992386817932\n",
      "231.40503597259521\n",
      "238.0103039741516\n",
      "244.61538887023926\n",
      "251.22032690048218\n",
      "257.82511138916016\n",
      "264.4294319152832\n",
      "271.0335669517517\n",
      "277.6374912261963\n",
      "284.2412271499634\n",
      "290.84477186203003\n",
      "297.44811964035034\n",
      "304.05128383636475\n",
      "310.65401315689087\n",
      "317.25657510757446\n",
      "323.8589463233948\n",
      "330.46088457107544\n",
      "337.06266355514526\n",
      "343.6642951965332\n",
      "350.2657313346863\n",
      "356.866735458374\n",
      "363.4675211906433\n",
      "370.068154335022\n",
      "376.6685209274292\n",
      "383.26872396469116\n",
      "389.8687343597412\n",
      "396.4684867858887\n",
      "403.06753492355347\n",
      "409.66616773605347\n",
      "416.26466178894043\n",
      "422.86299324035645\n",
      "429.461124420166\n",
      "436.058970451355\n",
      "442.65636110305786\n",
      "449.25308752059937\n",
      "455.84967041015625\n",
      "462.4458475112915\n",
      "469.04186058044434\n",
      "475.637722492218\n",
      "482.23331451416016\n",
      "488.8287115097046\n",
      "495.4239082336426\n",
      "502.0180630683899\n",
      "508.61190128326416\n",
      "515.2055616378784\n",
      "521.799045085907\n",
      "528.3923225402832\n",
      "534.9853177070618\n",
      "541.5781440734863\n",
      "548.170802116394\n",
      "554.763298034668\n",
      "561.3556532859802\n",
      "567.9478335380554\n",
      "574.539831161499\n",
      "581.1314001083374\n",
      "587.7227511405945\n",
      "594.313018321991\n",
      "600.9030680656433\n",
      "607.4929308891296\n",
      "614.0826354026794\n",
      "620.6721472740173\n",
      "627.261447429657\n",
      "633.8505573272705\n",
      "640.4393954277039\n",
      "647.0280866622925\n",
      "653.6165814399719\n",
      "660.2044544219971\n",
      "666.7920894622803\n",
      "673.3794984817505\n",
      "679.9666790962219\n",
      "686.5536112785339\n",
      "693.1403341293335\n",
      "699.7268600463867\n",
      "706.3132019042969\n",
      "712.8993639945984\n",
      "719.4853324890137\n",
      "726.0711278915405\n",
      "732.6567325592041\n",
      "739.2421741485596\n",
      "745.8273720741272\n",
      "752.4123802185059\n",
      "758.9966044425964\n",
      "765.5803537368774\n",
      "772.163806438446\n",
      "778.7470350265503\n",
      "785.329526424408\n",
      "791.9118485450745\n",
      "798.4940218925476\n",
      "805.0760431289673\n",
      "811.6579236984253\n",
      "818.2396898269653\n",
      "824.821120262146\n",
      "831.4024333953857\n",
      "837.9836139678955\n",
      "844.5646347999573\n",
      "851.1445260047913\n",
      "857.7241320610046\n",
      "864.3035335540771\n",
      "870.8827738761902\n",
      "877.46186876297\n",
      "884.040801525116\n",
      "890.6195755004883\n",
      "897.1981911659241\n",
      "903.7766218185425\n",
      "910.3548879623413\n",
      "916.9329986572266\n",
      "923.5108833312988\n",
      "930.0885672569275\n",
      "936.6659293174744\n",
      "943.2425861358643\n",
      "949.8189463615417\n",
      "956.3949813842773\n",
      "962.9707617759705\n",
      "969.546368598938\n",
      "976.121832370758\n",
      "982.697018623352\n",
      "989.2719860076904\n",
      "995.8467531204224\n",
      "1002.4213624000549\n",
      "1008.995680809021\n",
      "1015.5698204040527\n",
      "1022.1427745819092\n",
      "1028.7155261039734\n",
      "1035.287854194641\n",
      "1041.860056400299\n",
      "1048.431854724884\n",
      "1055.0034728050232\n",
      "1061.574809551239\n",
      "1068.1459827423096\n",
      "1074.7169370651245\n",
      "1081.2877135276794\n",
      "1087.858325958252\n",
      "1094.428743839264\n",
      "1100.9987907409668\n",
      "1107.568627357483\n",
      "1114.1383075714111\n",
      "1120.7078380584717\n",
      "1127.277232170105\n",
      "1133.8464369773865\n",
      "1140.4152154922485\n",
      "1146.9838290214539\n",
      "1153.552034854889\n",
      "1160.120027065277\n",
      "1166.687813282013\n",
      "1173.2554211616516\n",
      "1179.8227977752686\n",
      "1186.3899993896484\n",
      "1192.9569602012634\n",
      "1199.5233979225159\n",
      "1206.0895438194275\n",
      "1212.6554560661316\n",
      "1219.2210659980774\n",
      "1225.7865738868713\n",
      "1232.3519320487976\n",
      "1238.9171271324158\n",
      "1245.4821753501892\n",
      "1252.0470733642578\n",
      "1258.611810684204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265.1763634681702\n",
      "1271.7407450675964\n",
      "1278.3049850463867\n",
      "1284.8690509796143\n",
      "1291.4329271316528\n",
      "1297.9966526031494\n",
      "1304.5602231025696\n",
      "1311.1236362457275\n",
      "1317.6863932609558\n",
      "1324.248939037323\n",
      "1330.8108620643616\n",
      "1337.3725147247314\n",
      "1343.9338760375977\n",
      "1350.4947123527527\n",
      "1357.055413722992\n",
      "1363.615894317627\n",
      "1370.1760439872742\n",
      "1376.7357740402222\n",
      "1383.2952499389648\n",
      "1389.854459285736\n",
      "1396.4134969711304\n",
      "1402.972415447235\n",
      "1409.5312280654907\n",
      "1416.0898733139038\n",
      "1422.6483511924744\n",
      "1429.2066378593445\n",
      "1435.7647461891174\n",
      "1442.3227181434631\n",
      "1448.8805661201477\n",
      "1455.4382643699646\n",
      "1461.9958205223083\n",
      "1468.5532507896423\n",
      "1475.1104578971863\n",
      "1481.6675267219543\n",
      "1488.2244362831116\n",
      "1494.7811884880066\n",
      "1501.3377528190613\n",
      "1507.894157409668\n",
      "1514.4503860473633\n",
      "1521.0064606666565\n",
      "1527.5619525909424\n",
      "1534.1172494888306\n",
      "1540.6724028587341\n",
      "1547.2274012565613\n",
      "1553.782232761383\n",
      "1560.33691072464\n",
      "1566.891444683075\n",
      "1573.445852279663\n",
      "1579.9998207092285\n",
      "1586.5534162521362\n",
      "1593.1068015098572\n",
      "1599.6600441932678\n",
      "1606.213138103485\n",
      "1612.766086101532\n",
      "1619.3188815116882\n",
      "1625.870840549469\n",
      "1632.4220061302185\n",
      "1638.9730768203735\n",
      "1645.5240211486816\n",
      "1652.0748291015625\n",
      "1658.6254835128784\n",
      "1665.1759948730469\n",
      "1671.7263932228088\n",
      "1678.2763977050781\n",
      "1684.8262310028076\n",
      "1691.375922203064\n",
      "1697.925446987152\n",
      "1704.4748034477234\n",
      "1711.023992061615\n",
      "1717.5730056762695\n",
      "1724.1218328475952\n",
      "1730.6704907417297\n",
      "1737.218964099884\n",
      "1743.76726436615\n",
      "1750.3153901100159\n",
      "1756.8633732795715\n",
      "1763.4111909866333\n",
      "1769.9586553573608\n",
      "1776.5059542655945\n",
      "1783.0530834197998\n",
      "1789.6000576019287\n",
      "1796.146876335144\n",
      "1802.693498134613\n",
      "1809.2399406433105\n",
      "1815.7862310409546\n",
      "1822.3323783874512\n",
      "1828.8783679008484\n",
      "1835.4242086410522\n",
      "1841.9699220657349\n",
      "1848.5155062675476\n",
      "1855.0608658790588\n",
      "1861.6051688194275\n",
      "1868.1493172645569\n",
      "1874.693326473236\n",
      "1881.237187385559\n",
      "1887.7808785438538\n",
      "1894.3243322372437\n",
      "1900.8676056861877\n",
      "1907.410744190216\n",
      "1913.9537234306335\n",
      "1920.4965319633484\n",
      "1927.0391907691956\n",
      "1933.581708431244\n",
      "1940.1240811347961\n",
      "1946.6663131713867\n",
      "1953.2084112167358\n",
      "1959.7503609657288\n",
      "1966.292163848877\n",
      "1972.8338437080383\n",
      "1979.375389099121\n",
      "1985.916811466217\n",
      "1992.458116054535\n",
      "1998.9992723464966\n",
      "2005.5402674674988\n",
      "2012.0811591148376\n",
      "2018.6218438148499\n",
      "2025.1623630523682\n",
      "2031.7027616500854\n",
      "2038.2430601119995\n",
      "2044.7831735610962\n",
      "2051.3229393959045\n",
      "2057.8623394966125\n",
      "2064.401544570923\n",
      "2070.940573692322\n",
      "2077.479522705078\n",
      "2084.0180916786194\n",
      "2090.556526184082\n",
      "2097.094829082489\n",
      "2103.6330122947693\n",
      "2110.171061038971\n",
      "2116.709002494812\n",
      "2123.2466683387756\n",
      "2129.784194946289\n",
      "2136.321568965912\n",
      "2142.8588099479675\n",
      "2149.395921230316\n",
      "2155.932903289795\n",
      "2162.469735622406\n",
      "2169.0064301490784\n",
      "2175.542941093445\n",
      "2182.0793194770813\n",
      "2188.615566253662\n",
      "2195.1516852378845\n",
      "2201.6876373291016\n",
      "2208.2234234809875\n",
      "2214.7590680122375\n",
      "2221.2946038246155\n",
      "2227.8300042152405\n",
      "2234.365243911743\n",
      "2240.900372028351\n",
      "2247.4353699684143\n",
      "2253.970226764679\n",
      "2260.504930973053\n",
      "2267.03951215744\n",
      "2273.5739669799805\n",
      "2280.1083250045776\n",
      "2286.642584323883\n",
      "2293.1762766838074\n",
      "2299.709656715393\n",
      "2306.24289560318\n",
      "2312.776021003723\n",
      "2319.3079652786255\n",
      "2325.8396615982056\n",
      "2332.371244907379\n",
      "2338.902690410614\n",
      "2345.434013366699\n",
      "2351.965214252472\n",
      "2358.496289730072\n",
      "2365.0272521972656\n",
      "2371.5580792427063\n",
      "2378.088445186615\n",
      "2384.618697166443\n",
      "2391.1488161087036\n",
      "2397.678813934326\n",
      "2404.2086482048035\n",
      "2410.7383317947388\n",
      "2417.267821788788\n",
      "2423.7971892356873\n",
      "2430.3264260292053\n",
      "2436.855068206787\n",
      "2443.3825163841248\n",
      "2449.909827232361\n",
      "2456.4370198249817\n",
      "2462.964108467102\n",
      "2469.4907512664795\n",
      "2476.0172910690308\n",
      "2482.5437507629395\n",
      "2489.070147037506\n",
      "2495.5964522361755\n",
      "2502.122501373291\n",
      "2508.647877216339\n",
      "2515.173110485077\n",
      "2521.6981682777405\n",
      "2528.2231249809265\n",
      "2534.7479605674744\n",
      "2541.2726740837097\n",
      "2547.7972869873047\n",
      "2554.3217697143555\n",
      "2560.846134662628\n",
      "2567.3703293800354\n",
      "2573.894387245178\n",
      "2580.418300151825\n",
      "2586.9420857429504\n",
      "2593.465754508972\n",
      "2599.9892868995667\n",
      "2606.512722969055\n",
      "2613.0360498428345\n",
      "2619.559278011322\n",
      "2626.0823636054993\n",
      "2632.6049394607544\n",
      "2639.127420425415\n",
      "2645.6497898101807\n",
      "2652.1720366477966\n",
      "2658.6942081451416\n",
      "2665.216296195984\n",
      "2671.738021373749\n",
      "2678.2596893310547\n",
      "2684.781261920929\n",
      "2691.3027358055115\n",
      "2697.823040008545\n",
      "2704.3432388305664\n",
      "2710.863359451294\n",
      "2717.3833651542664\n",
      "2723.9032497406006\n",
      "2730.4228234291077\n",
      "2736.9420852661133\n",
      "2743.4608659744263\n",
      "2749.9795322418213\n",
      "2756.498064994812\n",
      "2763.016477584839\n",
      "2769.5347838401794\n",
      "2776.05296087265\n",
      "2782.5709676742554\n",
      "2789.088840007782\n",
      "2795.6065826416016\n",
      "2802.1242084503174\n",
      "2808.6415495872498\n",
      "2815.1587629318237\n",
      "2821.675881385803\n",
      "2828.1929001808167\n",
      "2834.709815979004\n",
      "2841.22665643692\n",
      "2847.743097782135\n",
      "2854.2594470977783\n",
      "2860.77455329895\n",
      "2867.2895884513855\n",
      "2873.804543018341\n",
      "2880.319396495819\n",
      "2886.8340377807617\n",
      "2893.348541736603\n",
      "2899.8629150390625\n",
      "2906.3769068717957\n",
      "2912.8908400535583\n",
      "2919.4046173095703\n",
      "2925.918312072754\n",
      "2932.431966781616\n",
      "2938.945146560669\n",
      "2945.458206176758\n",
      "2951.9709062576294\n",
      "2958.4835081100464\n",
      "2964.9958691596985\n",
      "2971.508143424988\n",
      "2978.0203142166138\n",
      "2984.532386779785\n",
      "2991.0443749427795\n",
      "2997.556245326996\n",
      "3004.0680027008057\n",
      "3010.579644680023\n",
      "3017.0911631584167\n",
      "3023.602569103241\n",
      "3030.1138854026794\n",
      "3036.6250648498535\n",
      "3043.1361923217773\n",
      "3049.647216320038\n",
      "3056.158163547516\n",
      "3062.669012069702\n",
      "3069.1797428131104\n",
      "3075.69038772583\n",
      "3082.200927734375\n",
      "3088.7113761901855\n",
      "3095.2217354774475\n",
      "3101.73201751709\n",
      "3108.2421946525574\n",
      "3114.7521591186523\n",
      "3121.2610025405884\n",
      "3127.769802093506\n",
      "3134.2780923843384\n",
      "3140.786271572113\n",
      "3147.2943868637085\n",
      "3153.8016266822815\n",
      "3160.3088393211365\n",
      "3166.815782546997\n",
      "3173.322684764862\n",
      "3179.8292145729065\n",
      "3186.3356618881226\n",
      "3192.841733932495\n",
      "3199.346519470215\n",
      "3205.851207256317\n",
      "3212.3558378219604\n",
      "3218.8603892326355\n",
      "3225.364903450012\n",
      "3231.869351387024\n",
      "3238.373746395111\n",
      "3244.877724170685\n",
      "3251.381289958954\n",
      "3257.884819984436\n",
      "3264.388300895691\n",
      "3270.8916907310486\n",
      "3277.3949675559998\n",
      "3283.898084640503\n",
      "3290.401048183441\n",
      "3296.903913974762\n",
      "3303.4066891670227\n",
      "3309.9094014167786\n",
      "3316.4120502471924\n",
      "3322.914629459381\n",
      "3329.417106151581\n",
      "3335.9195399284363\n",
      "3342.4219241142273\n",
      "3348.9241676330566\n",
      "3355.4260692596436\n",
      "3361.9279046058655\n",
      "3368.429428100586\n",
      "3374.930877685547\n",
      "3381.4322752952576\n",
      "3387.933618545532\n",
      "3394.434923171997\n",
      "3400.9360675811768\n",
      "3407.43692779541\n",
      "3413.9377517700195\n",
      "3420.4385380744934\n",
      "3426.9392404556274\n",
      "3433.438964366913\n",
      "3439.9386162757874\n",
      "3446.4382219314575\n",
      "3452.937737464905\n",
      "3459.4371666908264\n",
      "3465.9365377426147\n",
      "3472.435817718506\n",
      "3478.935064315796\n",
      "3485.4338340759277\n",
      "3491.9325938224792\n",
      "3498.4312920570374\n",
      "3504.929859638214\n",
      "3511.4282059669495\n",
      "3517.926474571228\n",
      "3524.424702167511\n",
      "3530.9228801727295\n",
      "3537.420774459839\n",
      "3543.918330669403\n",
      "3550.415783882141\n",
      "3556.9131803512573\n",
      "3563.4105472564697\n",
      "3569.9078187942505\n",
      "3576.4049878120422\n",
      "3582.902097225189\n",
      "3589.3980741500854\n",
      "3595.89369058609\n",
      "3602.389265060425\n",
      "3608.884665966034\n",
      "3615.379967212677\n",
      "3621.875178337097\n",
      "3628.37029504776\n",
      "3634.8653626441956\n",
      "3641.3604035377502\n",
      "3647.8554224967957\n",
      "3654.350416660309\n",
      "3660.8453240394592\n",
      "3667.3401532173157\n",
      "3673.8349266052246\n",
      "3680.329641342163\n",
      "3686.8243069648743\n",
      "3693.3186478614807\n",
      "3699.812255859375\n",
      "3706.3058524131775\n",
      "3712.799017906189\n",
      "3719.292149066925\n",
      "3725.7851824760437\n",
      "3732.2781586647034\n",
      "3738.771052837372\n",
      "3745.2638535499573\n",
      "3751.7566323280334\n",
      "3758.2493920326233\n",
      "3764.7420926094055\n",
      "3771.2347450256348\n",
      "3777.7273240089417\n",
      "3784.2198095321655\n",
      "3790.712248325348\n",
      "3797.204647541046\n",
      "3803.696963787079\n",
      "3810.1891565322876\n",
      "3816.6810688972473\n",
      "3823.1729435920715\n",
      "3829.66482257843\n",
      "3836.1567554473877\n",
      "3842.6486597061157\n",
      "3849.1404938697815\n",
      "3855.632246494293\n",
      "3862.12393283844\n",
      "3868.6155433654785\n",
      "3875.1070675849915\n",
      "3881.598529815674\n",
      "3888.0899624824524\n",
      "3894.5813941955566\n",
      "3901.0728335380554\n",
      "3907.564269065857\n",
      "3914.05547952652\n",
      "3920.5466709136963\n",
      "3927.037895679474\n",
      "3933.529103755951\n",
      "3940.020320892334\n",
      "3946.511459827423\n",
      "3953.002534866333\n",
      "3959.493377685547\n",
      "3965.984172821045\n",
      "3972.474884033203\n",
      "3978.9655270576477\n",
      "3985.4560470581055\n",
      "3991.946464538574\n",
      "3998.4366431236267\n",
      "4004.926710128784\n",
      "4011.4166555404663\n",
      "4017.906506538391\n",
      "4024.396258354187\n",
      "4030.885911464691\n",
      "4037.375472545624\n",
      "4043.864935398102\n",
      "4050.354308605194\n",
      "4056.843587398529\n",
      "4063.3327674865723\n",
      "4069.821852207184\n",
      "4076.310833454132\n",
      "4082.7995429039\n",
      "4089.2881722450256\n",
      "4095.776744365692\n",
      "4102.265278816223\n",
      "4108.753844261169\n",
      "4115.2418332099915\n",
      "4121.7298192977905\n",
      "4128.217790603638\n",
      "4134.7057428359985\n",
      "4141.193489551544\n",
      "4147.681233882904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4154.168933391571\n",
      "4160.656536579132\n",
      "4167.144071102142\n",
      "4173.631527900696\n",
      "4180.118899345398\n",
      "4186.606210708618\n",
      "4193.093500614166\n",
      "4199.580760002136\n",
      "4206.067969799042\n",
      "4212.555189609528\n",
      "4219.042271137238\n",
      "4225.5293707847595\n",
      "4232.015255451202\n",
      "4238.501132965088\n",
      "4244.986975669861\n",
      "4251.4726729393005\n",
      "4257.958301067352\n",
      "4264.443892002106\n",
      "4270.9294629096985\n",
      "4277.414874076843\n",
      "4283.900099277496\n",
      "4290.385261058807\n",
      "4296.870377540588\n",
      "4303.355433940887\n",
      "4309.840389251709\n",
      "4316.325284481049\n",
      "4322.810113430023\n",
      "4329.294913768768\n",
      "4335.779440402985\n",
      "4342.263898849487\n",
      "4348.748314857483\n",
      "4355.232665538788\n",
      "4361.7169399261475\n",
      "4368.2011461257935\n",
      "4374.685285568237\n",
      "4381.1693234443665\n",
      "4387.653298854828\n",
      "4394.137250423431\n",
      "4400.62118768692\n",
      "4407.105085849762\n",
      "4413.588987827301\n",
      "4420.072134971619\n",
      "4426.555255413055\n",
      "4433.038322925568\n",
      "4439.521332740784\n",
      "4446.004281997681\n",
      "4452.487189292908\n",
      "4458.969763278961\n",
      "4465.452324390411\n",
      "4471.934863090515\n",
      "4478.417249679565\n",
      "4484.89950466156\n",
      "4491.381618022919\n",
      "4497.863470554352\n",
      "4504.344967842102\n",
      "4510.826406002045\n",
      "4517.307639598846\n",
      "4523.788756847382\n",
      "4530.269765377045\n",
      "4536.750738143921\n",
      "4543.23165512085\n",
      "4549.712536811829\n",
      "4556.193358421326\n",
      "4562.674179077148\n",
      "4569.1546421051025\n",
      "4575.635094642639\n",
      "4582.115523815155\n",
      "4588.595889568329\n",
      "4595.076191902161\n",
      "4601.556407928467\n",
      "4608.036558628082\n",
      "4614.516699314117\n",
      "4620.996492862701\n",
      "4627.476236820221\n",
      "4633.955888748169\n",
      "4640.435507297516\n",
      "4646.915044307709\n",
      "4653.394495010376\n",
      "4659.873885631561\n",
      "4666.353228569031\n",
      "4672.832573413849\n",
      "4679.311312198639\n",
      "4685.789639472961\n",
      "4692.267971992493\n",
      "4698.746242046356\n",
      "4705.224450588226\n",
      "4711.7026653289795\n",
      "4718.180792331696\n",
      "4724.658836841583\n",
      "4731.136815071106\n",
      "4737.614752292633\n",
      "4744.092648983002\n",
      "4750.570423603058\n",
      "4757.048045158386\n",
      "4763.525150775909\n",
      "4770.001817703247\n",
      "4776.478382110596\n",
      "4782.954911708832\n",
      "4789.431483268738\n",
      "4795.907175540924\n",
      "4802.382870197296\n",
      "4808.858557701111\n",
      "4815.334144115448\n",
      "4821.809635639191\n",
      "4828.285099029541\n",
      "4834.760190010071\n",
      "4841.235294818878\n",
      "4847.710371494293\n",
      "4854.1854519844055\n",
      "4860.660489082336\n",
      "4867.135478019714\n",
      "4873.6101841926575\n",
      "4880.084804534912\n",
      "4886.559392929077\n",
      "4893.033919811249\n",
      "4899.508407592773\n",
      "4905.982528209686\n",
      "4912.456471443176\n",
      "4918.930401325226\n",
      "4925.404141426086\n",
      "4931.877820491791\n",
      "4938.3514041900635\n",
      "4944.824900627136\n",
      "4951.298308849335\n",
      "4957.771617412567\n",
      "4964.244824886322\n",
      "4970.717953681946\n",
      "4977.191002368927\n",
      "4983.663991928101\n",
      "4990.136929988861\n",
      "4996.609773159027\n",
      "5003.0825090408325\n",
      "5009.555126190186\n",
      "5016.027706623077\n",
      "5022.500259399414\n",
      "5028.972822666168\n",
      "5035.445397377014\n",
      "5041.917945384979\n",
      "5048.390431880951\n",
      "5054.8628969192505\n",
      "5061.335341453552\n",
      "5067.807774066925\n",
      "5074.2801995277405\n",
      "5080.752633571625\n",
      "5087.224729061127\n",
      "5093.696819782257\n",
      "5100.168918132782\n",
      "5106.641046524048\n",
      "5113.113033294678\n",
      "5119.584901809692\n",
      "5126.05570602417\n",
      "5132.52648973465\n",
      "5138.997256278992\n",
      "5145.468012809753\n",
      "5151.938766956329\n",
      "5158.409259796143\n",
      "5164.879725456238\n",
      "5171.349981784821\n",
      "5177.820207595825\n",
      "5184.289933204651\n",
      "5190.759208679199\n",
      "5197.228486537933\n",
      "5203.6978187561035\n",
      "5210.167161941528\n",
      "5216.636514186859\n",
      "5223.105825424194\n",
      "5229.575047492981\n",
      "5236.044239044189\n",
      "5242.513175487518\n",
      "5248.982086658478\n",
      "5255.451007843018\n",
      "5261.919512748718\n",
      "5268.388085365295\n",
      "5274.856662273407\n",
      "5281.324962615967\n",
      "5287.793037891388\n",
      "5294.261069774628\n",
      "5300.729070186615\n",
      "5307.196902275085\n",
      "5313.664742469788\n",
      "5320.132580757141\n",
      "5326.600411891937\n",
      "5333.067864894867\n",
      "5339.534512519836\n",
      "5346.001162528992\n",
      "5352.467798233032\n",
      "5358.934372425079\n",
      "5365.400912761688\n",
      "5371.867392063141\n",
      "5378.333811283112\n",
      "5384.800230979919\n",
      "5391.26661157608\n",
      "5397.732894897461\n",
      "5404.198617935181\n",
      "5410.664025306702\n",
      "5417.129427433014\n",
      "5423.594830036163\n",
      "5430.060234069824\n",
      "5436.525530338287\n",
      "5442.990637779236\n",
      "5449.455729484558\n",
      "5455.92081785202\n",
      "5462.385914325714\n",
      "5468.851003646851\n",
      "5475.3152775764465\n",
      "5481.77961730957\n",
      "5488.244000911713\n",
      "5494.708009719849\n",
      "5501.172004699707\n",
      "5507.635867118835\n",
      "5514.0997676849365\n",
      "5520.563397407532\n",
      "5527.027029514313\n",
      "5533.490691184998\n",
      "5539.954304695129\n",
      "5546.417907714844\n",
      "5552.88152551651\n",
      "5559.345027923584\n",
      "5565.808513641357\n",
      "5572.271978855133\n",
      "5578.735398769379\n",
      "5585.198577880859\n",
      "5591.661700725555\n",
      "5598.1247391700745\n",
      "5604.58757019043\n",
      "5611.050390720367\n",
      "5617.512710571289\n",
      "5623.975077629089\n",
      "5630.437421798706\n",
      "5636.899728775024\n",
      "5643.361996173859\n",
      "5649.8241510391235\n",
      "5656.285800933838\n",
      "5662.747452735901\n",
      "5669.209111213684\n",
      "5675.67076253891\n",
      "5682.132374286652\n",
      "5688.593976020813\n",
      "5695.055537223816\n",
      "5701.517060756683\n",
      "5707.978568553925\n",
      "5714.43992805481\n",
      "5720.90096950531\n",
      "5727.362051963806\n",
      "5733.823143005371\n",
      "5740.28422832489\n",
      "5746.745285511017\n",
      "5753.206338405609\n",
      "5759.667409896851\n",
      "5766.128472805023\n",
      "5772.589550971985\n",
      "5779.050570487976\n",
      "5785.511572360992\n",
      "5791.972574710846\n",
      "5798.433539867401\n",
      "5804.89448595047\n",
      "5811.355174541473\n",
      "5817.815848827362\n",
      "5824.276200294495\n",
      "5830.736457824707\n",
      "5837.196196079254\n",
      "5843.65594959259\n",
      "5850.11567401886\n",
      "5856.575397491455\n",
      "5863.03514623642\n",
      "5869.494881153107\n",
      "5875.954619407654\n",
      "5882.413824081421\n",
      "5888.872889995575\n",
      "5895.331956386566\n",
      "5901.79113483429\n",
      "5908.250117301941\n",
      "5914.70912694931\n",
      "5921.168129444122\n",
      "5927.627137184143\n",
      "5934.0861258506775\n",
      "5940.54510641098\n",
      "5947.004074573517\n",
      "5953.462821960449\n",
      "5959.921206474304\n",
      "5966.379247188568\n",
      "5972.837326049805\n",
      "5979.2954087257385\n",
      "5985.753448009491\n",
      "5992.211496353149\n",
      "5998.6695346832275\n",
      "6005.127601623535\n",
      "6011.5851039886475\n",
      "6018.042643070221\n",
      "6024.500216960907\n",
      "6030.957778930664\n",
      "6037.4153690338135\n",
      "6043.872188568115\n",
      "6050.3289885520935\n",
      "6056.785765171051\n",
      "6063.2424783706665\n",
      "6069.699142932892\n",
      "6076.155798435211\n",
      "6082.612458229065\n",
      "6089.068756103516\n",
      "6095.5250725746155\n",
      "6101.981404781342\n",
      "6108.437764167786\n",
      "6114.894067287445\n",
      "6121.350342273712\n",
      "6127.806619644165\n",
      "6134.262920379639\n",
      "6140.7183928489685\n",
      "6147.173761367798\n",
      "6153.628953933716\n",
      "6160.083862781525\n",
      "6166.538210391998\n",
      "6172.992436885834\n",
      "6179.446672439575\n",
      "6185.900886058807\n",
      "6192.355069637299\n",
      "6198.809242248535\n",
      "6205.26341676712\n",
      "6211.717472076416\n",
      "6218.171528339386\n",
      "6224.625570297241\n",
      "6231.0796093940735\n",
      "6237.533640861511\n",
      "6243.987664699554\n",
      "6250.441667556763\n",
      "6256.895645618439\n",
      "6263.349594593048\n",
      "6269.803501605988\n",
      "6276.257390499115\n",
      "6282.711248397827\n",
      "6289.165043354034\n",
      "6295.618780612946\n",
      "6302.072423458099\n",
      "6308.526042938232\n",
      "6314.979643344879\n",
      "6321.433075904846\n",
      "6327.885545253754\n",
      "6334.337870597839\n",
      "6340.7902183532715\n",
      "6347.242575645447\n",
      "6353.694921016693\n",
      "6360.147302150726\n",
      "6366.599727153778\n",
      "6373.051689147949\n",
      "6379.503442287445\n",
      "6385.955222606659\n",
      "6392.406986713409\n",
      "6398.858772754669\n",
      "6405.310567378998\n",
      "6411.76238489151\n",
      "6418.213849544525\n",
      "6424.665322780609\n",
      "6431.116670131683\n",
      "6437.56756401062\n",
      "6444.018177032471\n",
      "6450.468671798706\n",
      "6456.919219493866\n",
      "6463.369763851166\n",
      "6469.82019329071\n",
      "6476.270228862762\n",
      "6482.719966411591\n",
      "6489.169649600983\n",
      "6495.619100570679\n",
      "6502.068142414093\n",
      "6508.517141819\n",
      "6514.966116428375\n",
      "6521.415030479431\n",
      "6527.863954544067\n",
      "6534.312840938568\n",
      "6540.761719226837\n",
      "6547.210231781006\n",
      "6553.658483982086\n",
      "6560.10667514801\n",
      "6566.554889202118\n",
      "6573.002749919891\n",
      "6579.45071554184\n",
      "6585.898743152618\n",
      "6592.3465275764465\n",
      "6598.794395446777\n",
      "6605.241909980774\n",
      "6611.689482688904\n",
      "6618.137103557587\n",
      "6624.584753513336\n",
      "6631.032199382782\n",
      "6637.479156970978\n",
      "6643.926149368286\n",
      "6650.373154163361\n",
      "6656.82017326355\n",
      "6663.26721906662\n",
      "6669.7138023376465\n",
      "6676.160506725311\n",
      "6682.606758117676\n",
      "6689.053069591522\n",
      "6695.4992961883545\n",
      "6701.94553565979\n",
      "6708.391779899597\n",
      "6714.838024139404\n",
      "6721.284015655518\n",
      "6727.73002243042\n",
      "6734.175634860992\n",
      "6740.621233463287\n",
      "6747.0668568611145\n",
      "6753.512519359589\n",
      "6759.958154678345\n",
      "6766.403806686401\n",
      "6772.849492549896\n",
      "6779.295199871063\n",
      "6785.740364074707\n",
      "6792.185554981232\n",
      "6798.630795478821\n",
      "6805.076026916504\n",
      "6811.520994186401\n",
      "6817.965980529785\n",
      "6824.4109716415405\n",
      "6830.855999469757\n",
      "6837.301045894623\n",
      "6843.746096134186\n",
      "6850.1911725997925\n",
      "6856.636239051819\n",
      "6863.081255912781\n",
      "6869.526228904724\n",
      "6875.97117805481\n",
      "6882.416064739227\n",
      "6888.860911846161\n",
      "6895.305723190308\n",
      "6901.75049161911\n",
      "6908.19521856308\n",
      "6914.639897346497\n",
      "6921.084548950195\n",
      "6927.52916431427\n",
      "6933.9735951423645\n",
      "6940.418020248413\n",
      "6946.862468242645\n",
      "6953.306948661804\n",
      "6959.751166820526\n",
      "6966.195352077484\n",
      "6972.639559745789\n",
      "6979.08357334137\n",
      "6985.527632713318\n",
      "6991.971709251404\n",
      "6998.41588973999\n",
      "7004.859653949738\n",
      "7011.302921772003\n",
      "7017.745244026184\n",
      "7024.18696641922\n",
      "7030.6287388801575\n",
      "7037.070561885834\n",
      "7043.512434959412\n",
      "7049.954189300537\n",
      "7056.395965099335\n",
      "7062.837762355804\n",
      "7069.279618263245\n",
      "7075.721487045288\n",
      "7082.163384914398\n",
      "7088.604478359222\n",
      "7095.045548915863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7101.4861125946045\n",
      "7107.926664352417\n",
      "7114.367245197296\n",
      "7120.807422161102\n",
      "7127.247602939606\n",
      "7133.6878571510315\n",
      "7140.128027915955\n",
      "7146.5681848526\n",
      "7153.008355140686\n",
      "7159.448557376862\n",
      "7165.888787746429\n",
      "7172.3290276527405\n",
      "7178.769001483917\n",
      "7185.209008693695\n",
      "7191.649039745331\n",
      "7198.089063644409\n",
      "7204.528699398041\n",
      "7210.967777252197\n",
      "7217.406692504883\n",
      "7223.845414161682\n",
      "7230.284077644348\n",
      "7236.722641944885\n",
      "7243.161169052124\n",
      "7249.599650859833\n",
      "7256.038081169128\n",
      "7262.476498126984\n",
      "7268.914918899536\n",
      "7275.353361606598\n",
      "7281.791636943817\n",
      "7288.22958278656\n",
      "7294.667542934418\n",
      "7301.105387687683\n",
      "7307.543246269226\n",
      "7313.9811091423035\n",
      "7320.418772220612\n",
      "7326.856331825256\n",
      "7333.29390668869\n",
      "7339.731375694275\n",
      "7346.1689438819885\n",
      "7352.606328487396\n",
      "7359.043318271637\n",
      "7365.480378627777\n",
      "7371.917484760284\n",
      "7378.354594707489\n",
      "7384.791754245758\n",
      "7391.228552341461\n",
      "7397.664862155914\n",
      "7404.101263523102\n",
      "7410.537724018097\n",
      "7416.9741768836975\n",
      "7423.410610198975\n",
      "7429.846973419189\n",
      "7436.283352851868\n",
      "7442.719770908356\n",
      "7449.156114578247\n",
      "7455.592353343964\n",
      "7462.028648376465\n",
      "7468.464787006378\n",
      "7474.900419712067\n",
      "7481.335669517517\n",
      "7487.770963668823\n",
      "7494.20627784729\n",
      "7500.641623020172\n",
      "7507.076553344727\n",
      "7513.510942459106\n",
      "7519.944370746613\n",
      "Epoch 2/2, Loss: 7519.9444\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0  # Use a separate variable for total loss\n",
    "    for x, y in generate_data(corpus, window_size, V):\n",
    "        batch_loss, _ = cbow.train_on_batch(x, y)  # Unpack the loss and accuracy\n",
    "        total_loss += batch_loss\n",
    "        print(total_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42799b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(6.4334283, dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "684bed39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.218804 7296.3119468688965\n",
      "Epoch 1/50, Loss: 7296.3119\n",
      "5.9714236 7033.182321548462\n",
      "Epoch 2/50, Loss: 7033.1823\n",
      "5.6952558 6733.02365064621\n",
      "Epoch 3/50, Loss: 6733.0237\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# Use a separate variable for total loss\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m generate_data(corpus, window_size, V):\n\u001b[0;32m----> 6\u001b[0m     batch_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcbow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Unpack the loss and accuracy\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch_loss, total_loss)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:549\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[0;32m--> 549\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:278\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    272\u001b[0m func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mFuncGraph(tracing_options\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    274\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mreduce_retracing\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\n\u001b[1;32m    277\u001b[0m ):\n\u001b[0;32m--> 278\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneralize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcurrent_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_type\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_cache.py:87\u001b[0m, in \u001b[0;36mFunctionCache.generalize\u001b[0;34m(self, context, function_type)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Try to generalize a FunctionType within a FunctionContext.\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_dict:\n\u001b[0;32m---> 87\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_generalizing_function_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m function_type\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/type_dispatch.py:127\u001b[0m, in \u001b[0;36mTypeDispatchTable.try_generalizing_function_type\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a generalized subtype of the one given.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03mThis heuristic aims to reduce the number of future traces by computing a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m  target: The FunctionType to generalize\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m relaxed \u001b[38;5;241m=\u001b[39m target\n\u001b[0;32m--> 127\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_table\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m  \u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrelaxed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_specific_common_subtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mother\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:452\u001b[0m, in \u001b[0;36mFunctionType.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, FunctionType):\n\u001b[1;32m    450\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:150\u001b[0m, in \u001b[0;36mParameter.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Parameter):\n\u001b[1;32m    148\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/trace_type/default_types.py:188\u001b[0m, in \u001b[0;36mWeakref.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Weakref):\n\u001b[1;32m    186\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m other\u001b[38;5;241m.\u001b[39m_ref() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ref() \u001b[38;5;129;01mis\u001b[39;00m other\u001b[38;5;241m.\u001b[39m_ref():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0  # Use a separate variable for total loss\n",
    "    for x, y in generate_data(corpus, window_size, V):\n",
    "        batch_loss, _ = cbow.train_on_batch(x, y)  # Unpack the loss and accuracy\n",
    "        total_loss += batch_loss\n",
    "    print(batch_loss, total_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138aa8bb",
   "metadata": {},
   "source": [
    "4. Compare Embedding Quality\n",
    "In this step, we will compare the quality of embeddings produced by the different models (Word2Vec, RNN) and any pre-trained embeddings.\n",
    "\n",
    "Steps:\n",
    "Use Cosine Similarity: Compare word similarity between embeddings using cosine similarity.\n",
    "t-SNE for Visualization: Use t-SNE to visualize the embeddings in 2D space.\n",
    "Metrics: Use metrics like chatbot performance, word similarity, or visual analysis to compare embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82160c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded successfully.\n",
      "Similarity for 'प्रश्न' between models: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load the Word2Vec embeddings using KeyedVectors\n",
    "try:\n",
    "    word2vec_model = KeyedVectors.load_word2vec_format(\"my_cbow_vectors.txt\", binary=False)\n",
    "    print(\"Embeddings loaded successfully.\")\n",
    "except EOFError as e:\n",
    "    print(\"Error loading embeddings: EOFError\", e)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "# Load RNN embeddings\n",
    "rnn_embeddings = cbow.get_weights()[0]  # Extract embeddings from the trained RNN model\n",
    "rnn_vocab = tokenizer.word_index         # Word index from the tokenizer\n",
    "\n",
    "# Function to compare embeddings\n",
    "def embedding_similarity(word, word2vec_model, rnn_embeddings, rnn_vocab):\n",
    "    if word in word2vec_model and word in rnn_vocab:\n",
    "        # Get Word2Vec embedding directly from KeyedVectors\n",
    "        emb1 = word2vec_model[word].reshape(1, -1)\n",
    "        \n",
    "        # Get RNN embedding (using the index from the tokenizer's word index)\n",
    "        rnn_index = rnn_vocab[word]\n",
    "        emb2 = rnn_embeddings[rnn_index].reshape(1, -1)\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity(emb1, emb2)[0][0]\n",
    "        print(f\"Similarity for '{word}' between models: {similarity}\")\n",
    "    else:\n",
    "        print(f\"'{word}' not in vocabulary for one or both models.\")\n",
    "\n",
    "# Test comparison for a word\n",
    "embedding_similarity(\"प्रश्न\", word2vec_model, rnn_embeddings, rnn_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "203185b7",
   "metadata": {
    "code_folding": [
     2,
     7,
     17
    ]
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Assuming `generate_data` yields batches of (x, y)\n",
    "# def data_generator():\n",
    "#     for x, y in generate_data(corpus, window_size, V):\n",
    "#         yield x, y\n",
    "\n",
    "# # Create a tf.data.Dataset from the generator\n",
    "# batch_size = 32  # Adjust batch size as needed\n",
    "# dataset = tf.data.Dataset.from_generator(data_generator, output_signature=(\n",
    "#     tf.TensorSpec(shape=(None,), dtype=tf.int32),  # Adjust shape and dtype as per your data\n",
    "#     tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "# )).batch(batch_size)\n",
    "\n",
    "# # Compile the model (if not already compiled)\n",
    "# cbow.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# # Train the model for multiple epochs using `fit`\n",
    "# epochs = 10\n",
    "# cbow.fit(dataset, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4b6ff07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings have been saved to 'my_cbow_vectors.txt'.\n"
     ]
    }
   ],
   "source": [
    "# # # Training the model\n",
    "# # epochs = 20\n",
    "# # for epoch in range(epochs):\n",
    "# #     loss = 0.0\n",
    "# #     for x, y in generate_data(corpus, window_size, V):\n",
    "# #         loss += cbow.train_on_batch(x, y)\n",
    "# #     print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}')\n",
    "\n",
    "# # Save the embeddings to a file\n",
    "# with open('my_cbow_vectors.txt', 'w') as f:\n",
    "#     f.write(f'{V-1} {dim}\\n')\n",
    "#     vectors = cbow.get_weights()[0]\n",
    "#     for word, i in tokenizer.word_index.items():\n",
    "#         str_vec = ' '.join(map(str, vectors[i]))\n",
    "#         f.write(f'{word} {str_vec}\\n')\n",
    "\n",
    "# print(\"Embeddings have been saved to 'my_cbow_vectors.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "156274a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings have been saved to 'my_cbow_vectors.txt' in KeyedVectors format.\n"
     ]
    }
   ],
   "source": [
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# # Save the embeddings to a file in KeyedVectors format\n",
    "# with open('my_cbow_vectors.txt', 'w') as f:\n",
    "#     f.write(f\"{V} {dim}\\n\")  # Header with vocab size and dimensions\n",
    "#     vectors = cbow.get_weights()[0]\n",
    "    \n",
    "#     # Write each word and its vector to the file\n",
    "#     for word, i in tokenizer.word_index.items():\n",
    "#         str_vec = ' '.join(map(str, vectors[i]))\n",
    "#         f.write(f\"{word} {str_vec}\\n\")\n",
    "\n",
    "# print(\"Embeddings have been saved to 'my_cbow_vectors.txt' in KeyedVectors format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fda68c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings have been saved to 'my_cbow_vectors.txt' in KeyedVectors format.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Get the actual vocabulary size\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "\n",
    "# Save the embeddings to a file in KeyedVectors format\n",
    "with open('my_cbow_vectors.txt', 'w') as f:\n",
    "    # Write the header with the correct vocab size and embedding dimensions\n",
    "    f.write(f\"{vocab_size} {dim}\\n\")\n",
    "    vectors = cbow.get_weights()[0]\n",
    "    \n",
    "    # Write each word and its corresponding vector to the file\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i < len(vectors):  # Ensure we have an embedding for this index\n",
    "            str_vec = ' '.join(map(str, vectors[i]))\n",
    "            f.write(f\"{word} {str_vec}\\n\")\n",
    "\n",
    "print(\"Embeddings have been saved to 'my_cbow_vectors.txt' in KeyedVectors format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9fa692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudarshan/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 4.5428\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.0000e+00 - loss: 4.5194\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 4.5602\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.0000e+00 - loss: 4.5637\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.0000e+00 - loss: 4.5521\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.0000e+00 - loss: 4.5324\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.0000e+00 - loss: 4.5789\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.0000e+00 - loss: 4.5780\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.0000e+00 - loss: 4.5922\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 4.6098  \n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudarshan/anaconda3/lib/python3.11/contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 13:59:04.504038: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x53867f790>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "random_sentences\n",
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(random_sentences)\n",
    "corpus = tokenizer.texts_to_sequences(random_sentences)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Function to generate training data\n",
    "def generate_data(corpus, window_size, V):\n",
    "    maxlen = window_size * 2\n",
    "    for words in corpus:\n",
    "        L = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            contexts = []\n",
    "            labels = []\n",
    "            s = index - window_size\n",
    "            e = index + window_size + 1\n",
    "            context = [words[i] for i in range(s, e) if 0 <= i < L and i != index]\n",
    "            \n",
    "            contexts.append(context)\n",
    "            labels.append(word)\n",
    "            \n",
    "            x = pad_sequences(contexts, maxlen=maxlen, padding='post')\n",
    "            y = tf.keras.utils.to_categorical(labels, V)\n",
    "            yield (x, y)\n",
    "\n",
    "# Parameters for the embedding\n",
    "dim = 100\n",
    "window_size = 2\n",
    "V = vocab_size\n",
    "\n",
    "# Define the DNN-based embedding model (Shallow Model)\n",
    "dnn_model = Sequential()\n",
    "dnn_model.add(Embedding(input_dim=V, output_dim=dim, input_length=window_size * 2))\n",
    "dnn_model.add(Flatten())  # Flatten the context embeddings\n",
    "dnn_model.add(Dense(128, activation='relu'))  # Fully connected layer\n",
    "dnn_model.add(Dense(V, activation='softmax'))  # Output layer\n",
    "\n",
    "dnn_model.summary()\n",
    "\n",
    "# Compile the model\n",
    "dnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training the DNN model\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Train the DNN model using the data generator\n",
    "dnn_model.fit(generate_data(corpus, window_size, V), steps_per_epoch=len(corpus), epochs=epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da8ee4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_embeddings = dnn_model.get_layer('embedding_8').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b37cfe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_embeddings = cbow.get_weights()[0]  # Extract embeddings from the trained RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35409c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['त्यात भारतीय होते तसेच चिनी वा जपानीसुद्धा खूप होते.',\n",
       " 'दिल्ली मेट्रो रेल्वे कॉर्पोरेशनने (डीएमआरसी) केलेल्या अहवालातील प्राथमिक अंदाजानुसार मेट्रोच्या कामासाठी  मिळकतींचे भूसंपादन करावे लागणार आहे.',\n",
       " 'त्\\u200dया सभेत पंडित भारवी याला विजयी घोषित करण्\\u200dयात आले.',\n",
       " 'त्यामुळे पर्यायी सरकार स्थापन होऊ शकते.',\n",
       " 'परंतु त्याआधी शरीरचना आणि मनोरचना ह्यांचा अपंगतेच्या संदर्भात परस्परांशी काय संबंध आहे हे पाहणे आवश्यक आहे.',\n",
       " 'ओरिसा) यांनी चाकण पोलिसांत दिलेल्या फिर्यादी दिली होती.',\n",
       " 'टक्के मतदान झाले आहे.',\n",
       " 'ओबामा यांच्या स्वागतासाठी जातांना श्री.',\n",
       " 'त्यावेळी इतर मिळून  उमेदवार निवडणूक रिंगणात होते.',\n",
       " 'पुत्राच्या मूर्ख वागण्याने प्रजेला संभ्रमात टाकले आहे, प्रजेने त्याच्यावर विश्वास ठेवला तर मला वनवासात जावं लागेल हे राज्य सोडून.']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05c5dcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity (RNN): -0.20146295428276062\n",
      "Cosine similarity (DNN): 0.07591843605041504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example words: \"test\" and \"sentence\"\n",
    "word_1 = tokenizer.word_index[\"त्यात\"] - 1  # Token index of \"test\"\n",
    "word_2 = tokenizer.word_index['यांच्या'] - 1  # Token index of \"sentence\"\n",
    "\n",
    "# Cosine similarity between embeddings of two words\n",
    "rnn_sim = cosine_similarity([rnn_embeddings[word_1]], [rnn_embeddings[word_2]])[0][0]\n",
    "dnn_sim = cosine_similarity([dnn_embeddings[word_1]], [dnn_embeddings[word_2]])[0][0]\n",
    "\n",
    "print(f\"Cosine similarity (RNN): {rnn_sim}\")\n",
    "print(f\"Cosine similarity (DNN): {dnn_sim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed733dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
