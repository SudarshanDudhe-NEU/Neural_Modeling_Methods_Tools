{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fefa9ee",
   "metadata": {},
   "source": [
    "Assignment - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d5f97",
   "metadata": {},
   "source": [
    "# Text Generation using RNNs\n",
    "\n",
    "In this notebook, we will explore how to build and train a Recurrent Neural Network (RNN) to generate text based on a corpus. We will use a trigram approach for input and output sequence generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f78f9",
   "metadata": {},
   "source": [
    "#### Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e0f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import operator\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3d1576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/sudarshan/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK model data (you need to do this once)\n",
    "nltk.download(\"book\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c933e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 1. Data Preprocessing\n",
    "\n",
    "In this section, we preprocess the text data by:\n",
    "- Removing unnecessary characters and multiple spaces.\n",
    "- Converting the text to lowercase for consistency.\n",
    "\n",
    "### Steps:\n",
    "1. Load the raw text data.\n",
    "2. Apply regex for cleaning.\n",
    "3. Tokenize the text into individual words.\n",
    "\n",
    "```python\n",
    "# Example Python code for preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7866d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_roman_numerals(text):\n",
    "    pattern = r\"\\b(?=[MDCLXVIΙ])M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})([IΙ]X|[IΙ]V|V?[IΙ]{0,3})\\b\\.?\"\n",
    "    return re.sub(pattern, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81b193fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading txt file...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk import tokenize\n",
    "\n",
    "#alphabets= \"([A-Za-z])\"\n",
    "#prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "#suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "#starters = \"(Mr|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "#acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "#websites = \"[.](com|net|org|io|gov|edu|me)\"\n",
    "#digits = \"([0-9])\"\n",
    "\n",
    "# If you want to restrict the size of the voabulary\n",
    "# Right now, we set it in the next cell to be the entire vocabular: vocabulary_size = len(word_freq.items())\n",
    "#vocabulary_size = 3000\n",
    "\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\"\n",
    "\n",
    "# Read the data and append SENTENCE_START and SENTENCE_END tokens\n",
    "text = ''\n",
    "print( \"Reading txt file...\")\n",
    "with open(r'data/Mahabharata.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "#text = text.replace(\",\\n\",\"\\n\")\n",
    "\n",
    "# too many commas if i do this\n",
    "#text = text.replace(\",\",\" ,\")\n",
    "#text = text.replace(\":\",\" ,\")\n",
    "#text = text.replace(\";\",\" ,\")\n",
    "\n",
    "#.. so i do this instead\n",
    "text = text.replace(\",\",\"\")\n",
    "text = text.replace(\":\",\"\")\n",
    "text = text.replace(\";\",\"\")\n",
    "\n",
    "# too many apostrophes in shakespeare\n",
    "text = text.replace(\"’\",\"\")\n",
    "\n",
    "text = text.replace(\"?\\n\",\".\\n\")\n",
    "text = text.replace(\"!\\n\",\".\\n\")\n",
    "text = text.replace(\"?\",\"\")\n",
    "text = text.replace(\"!\",\"\")\n",
    "#text = text.replace(\"\\n\",\" \")\n",
    "\n",
    "text = text.replace('I ', 'i ')\n",
    "text = clean_roman_numerals(text)\n",
    "#text = text.replace('&', '')\n",
    "\n",
    "_RE_COMBINE_WHITESPACE = re.compile(r\"\\s+\")\n",
    "text = _RE_COMBINE_WHITESPACE.sub(\" \", text).strip()\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49a0f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower()\n",
    "text = text.replace('i ', 'I ')\n",
    "\n",
    "leftovers = ['ii', 'iii', 'cxi', 'cx', 'cxx', 'xx', 'xxxvi', 'xxxvi', 'xxxv', 'xxxi', 'xxi', 'cvi ', 'ci ', 'xvi ', 'lxi ', \n",
    "             'lxv','lxvi', 'lxxi', 'lxxvi', 'lxxvi', 'lxxv', 'lxxxi', 'cxxxi', 'cxxxi', 'cxxx', 'cxli', 'cxlvi', 'cxvl', \n",
    "             'cli ', 'cl ', 'cxxxvi','cvi ', 'cv ', 'ci ', 'cx ', 'cxx', 'cxi', 'li ' , 'xxx', 'xxvi', 'xxv', 'cxv', 'xci', \n",
    "             'xli', 'lxvi', 'lxi ', ' c ', 'lxxxvi', 'lxxxvi', 'lxxxv', ' v ', 'vi ', ' l ', 'lvi ', 'lv ', 'xlv ', ' x ', \n",
    "             'xi ', 'xl ', 'ix ']\n",
    "for rn in leftovers:\n",
    "    text = text.replace(rn, '')\n",
    "\n",
    "text = text.replace('.  ', '. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f9e217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I shall therefore speak to you something.\n",
      "\n",
      "mark ye.\n",
      "\n",
      "to dwell with a king is alas difficult.\n",
      "\n",
      "I shall tell you ye princes how ye may reside in the royal household avoiding every fault.\n",
      "\n",
      "ye kauravas honourably or otherwise ye will have to pass this year in the king's palace undiscovered by those that know you.\n",
      "\n",
      "then in the fourteenth year ye will live happy.\n",
      "\n",
      "o son of pandu in this world that cherisher and protector of all beings the king who is a deity in an embodied form is as a great fire sanctified with all the _mantras_.\n",
      "\n",
      "[6] one should present himself before the king after having obtained his permission at the gate.\n",
      "\n",
      "no one should keep contact with royal secrets.\n",
      "\n",
      "nor should one desire a seat which another may covet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = tokenize.sent_tokenize(text)\n",
    "for i in range(100, 110):\n",
    "    print(sentences[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae0b27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 40000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11d8f5",
   "metadata": {},
   "source": [
    "### 2. Creating Word Mappings\n",
    "Here, we convert the cleaned text into numerical form by creating two dictionaries:\n",
    "\n",
    "word_to_index: Maps each word to a unique index.\n",
    "index_to_word: Reverse mapping to retrieve words from their corresponding indices.\n",
    "This allows us to prepare the data for model training.\n",
    "### Example code for word mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a90441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 2800 sentences.\n",
      "Found 6399 unique words tokens.\n",
      "The least frequent word in our vocabulary is 'newsletter' and appeared 1 times.\n",
      "Using vocabulary size 6399.\n",
      "\n",
      "Example sentence: 'SENTENCE_START title the mahabharata of krishna-dwaipayana vyasa translated into english prose translator kisarI mohan gangulI release date april 1 2004 [ebook #12058] most recently updated december 14 2020 language english credits produced by john b. hare juliet sutherland david king and the online distributed proofreading team *** start of the project gutenberg ebook the mahabharata of krishna-dwaipayana vyasa translated into english prose *** produced by john b. hare juliet sutherland david king and the online distributed proofreading team the mahabharata of krishna-dwaipayana vyasa book 4 virata parva translated into english prose from the original sanskrit text by kisarI mohan gangulI [1883-1896] the mahabharata virata parva section (_pandava-pravesa parva_) om having bowed down to narayana and nara the most exalted of male beings and also to the goddess saraswatI must the word _jaya_ be uttered SENTENCE_END'\n",
      "\n",
      "Example sentence after Pre-processing: '['SENTENCE_START', 'title', 'the', 'mahabharata', 'of', 'krishna-dwaipayana', 'vyasa', 'translated', 'into', 'english', 'prose', 'translator', 'kisarI', 'mohan', 'gangulI', 'release', 'date', 'april', '1', '2004', '[', 'ebook', '#', '12058', ']', 'most', 'recently', 'updated', 'december', '14', '2020', 'language', 'english', 'credits', 'produced', 'by', 'john', 'b', 'hare', 'juliet', 'sutherland', 'david', 'king', 'and', 'the', 'online', 'distributed', 'proofreading', 'team', '*', '*', '*', 'start', 'of', 'the', 'project', 'gutenberg', 'ebook', 'the', 'mahabharata', 'of', 'krishna-dwaipayana', 'vyasa', 'translated', 'into', 'english', 'prose', '*', '*', '*', 'produced', 'by', 'john', 'b', 'hare', 'juliet', 'sutherland', 'david', 'king', 'and', 'the', 'online', 'distributed', 'proofreading', 'team', 'the', 'mahabharata', 'of', 'krishna-dwaipayana', 'vyasa', 'book', '4', 'virata', 'parva', 'translated', 'into', 'english', 'prose', 'from', 'the', 'original', 'sanskrit', 'text', 'by', 'kisarI', 'mohan', 'gangulI', '[', '1883-1896', ']', 'the', 'mahabharata', 'virata', 'parva', 'section', '(', '_pandava-pravesa', 'parva_', ')', 'om', 'having', 'bowed', 'down', 'to', 'narayana', 'and', 'nara', 'the', 'most', 'exalted', 'of', 'male', 'beings', 'and', 'also', 'to', 'the', 'goddess', 'saraswatI', 'must', 'the', 'word', '_jaya_', 'be', 'uttered', 'SENTENCE_END']'\n"
     ]
    }
   ],
   "source": [
    "# Append SENTENCE_START and SENTENCE_END\n",
    "sentences = [\"%s %s %s\" % (sentence_start_token, x[:-1].replace(\"&\",\"\"), sentence_end_token) for x in sentences] \n",
    "print(  \"Parsed %d sentences.\" % (len(sentences)))\n",
    "\n",
    "# Tokenize the sentences into words, making sure to remove end-of-sentence period\n",
    "tokenized_sentences = [nltk.word_tokenize(sent.replace('.', '')) for sent in sentences]\n",
    "\n",
    "# Count the word frequencies\n",
    "word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
    "print(  \"Found %d unique words tokens.\" % len(word_freq.items()))\n",
    "\n",
    "# Get the most common words and build index_to_word and word_to_index vectors\n",
    "vocab = word_freq.most_common(vocabulary_size-1)\n",
    "index_to_word = [x[0] for x in vocab]\n",
    "index_to_word.append(unknown_token)\n",
    "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
    "print(\"The least frequent word in our vocabulary is '%s' and appeared %d times.\" % (vocab[-1][0], vocab[-1][1]))\n",
    "\n",
    "# Replace all words not in our vocabulary with the unknown token\n",
    "#for i, sent in enumerate(tokenized_sentences):\n",
    "#    tokenized_sentences[i] = [w if w in word_to_index else unknown_token for w in sent]\n",
    "vocabulary_size = len(word_freq.items())\n",
    "print(\"Using vocabulary size %d.\" % vocabulary_size)\n",
    "\n",
    "print(  \"\\nExample sentence: '%s'\" % sentences[0])\n",
    "print(  \"\\nExample sentence after Pre-processing: '%s'\" % tokenized_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b438ffed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4269),\n",
       " ('of', 3388),\n",
       " ('and', 3277),\n",
       " ('SENTENCE_START', 2800),\n",
       " ('SENTENCE_END', 2800),\n",
       " ('in', 1208),\n",
       " ('with', 1073),\n",
       " ('to', 1057),\n",
       " ('that', 1023),\n",
       " ('a', 912),\n",
       " ('by', 691),\n",
       " ('is', 638),\n",
       " ('his', 596),\n",
       " ('o', 555),\n",
       " ('thou', 502),\n",
       " ('I', 467),\n",
       " ('this', 429),\n",
       " ('as', 428),\n",
       " ('king', 396),\n",
       " ('on', 391)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58109a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SENTENCE_START title the mahabharata of krishna-dwaipayana vyasa translated into english prose translator kisarI mohan gangulI release date april 1 2004 [ebook #12058] most recently updated december 14 2020 language english credits produced by john b. hare juliet sutherland david king and the online distributed proofreading team *** start of the project gutenberg ebook the mahabharata of krishna-dwaipayana vyasa translated into english prose *** produced by john b. hare juliet sutherland david king and the online distributed proofreading team the mahabharata of krishna-dwaipayana vyasa book 4 virata parva translated into english prose from the original sanskrit text by kisarI mohan gangulI [1883-1896] the mahabharata virata parva section (_pandava-pravesa parva_) om having bowed down to narayana and nara the most exalted of male beings and also to the goddess saraswatI must the word _jaya_ be uttered SENTENCE_END',\n",
       " 'SENTENCE_START janamejaya said \"how did my great-grandfathers afflicted with the fear of duryodhana pass their days undiscovered in the city of virata and o brahman how did the highly blessed draupadI stricken with woe devoted to her lords and ever adoring the deity[1] spend her days unrecognised\" [1] _brahma vadini_--nilakantha explains this as _krishna-kirtanasila._ vaisampayana said \"listen o lord of men how thy great grandfathers passed the period of unrecognition in the city of virata SENTENCE_END',\n",
       " 'SENTENCE_START having in this way obtained boons from the god of justice that best of virtuous men yudhishthira returned to the asylum and related unto the brahmanas all that had happened SENTENCE_END',\n",
       " 'SENTENCE_START and having related everything unto them yudhishthira restored to that regenerate brahmana who had followed him the churning staff and the fire-sticks he had lost SENTENCE_END',\n",
       " \"SENTENCE_START and o bharata the son of the god of justice the royal yudhishthira of high soul then called together all his younger brothers and addressed them saying 'exiled from our kingdom we have passed twelve years SENTENCE_END\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba022d67",
   "metadata": {},
   "source": [
    "### 3. Preparing Trigrams and Sequences\n",
    "We now prepare the input sequences (bigrams) and the target word (third word) using trigrams. The process involves:\n",
    "\n",
    "Creating sequences of n-grams (specifically trigrams).\n",
    "Mapping each word in the sequence to its index.\n",
    "### Example code for creating n-grams and sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "409e05cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 ms, sys: 1.73 ms, total: 23.7 ms\n",
      "Wall time: 23.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('of', 'the'), 665),\n",
       " (('in', 'the'), 289),\n",
       " (('and', 'the'), 258),\n",
       " (('son', 'of'), 234),\n",
       " (('to', 'the'), 167),\n",
       " (('by', 'the'), 166),\n",
       " (('the', 'son'), 152),\n",
       " (('the', 'king'), 148),\n",
       " (('on', 'the'), 144),\n",
       " (('with', 'the'), 143)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "bigram_counts = Counter(ngrams(text.split(), 2))\n",
    "bigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d8d68c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.1 ms, sys: 1.85 ms, total: 26 ms\n",
      "Wall time: 29.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('of', 'the'), 665),\n",
       " (('in', 'the'), 289),\n",
       " (('and', 'the'), 258),\n",
       " (('son', 'of'), 234),\n",
       " (('to', 'the'), 167),\n",
       " (('by', 'the'), 166),\n",
       " (('the', 'son'), 152),\n",
       " (('the', 'king'), 148),\n",
       " (('on', 'the'), 144),\n",
       " (('with', 'the'), 143)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import collections\n",
    "def ngrams(text, n=2):\n",
    "    return zip(*[text[i:] for i in range(n)])\n",
    "bigram_counts = collections.Counter(ngrams(text.split(), 2))\n",
    "bigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7593ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title the mahabharata of krishna-dwaipayana vyasa translated into english prose translator kisarI mohan gangulI release date april 1 2004 [ebook #12058] most recently updated december 14 2020 language english credits produced by john b. hare juliet sutherland david king and the online distributed proofreading team *** start of the project gutenberg ebook the mahabharata of krishna-dwaipayana vyasa translated into english prose *** produced by john b. hare juliet sutherland david king and the online distributed proofreading team the mahabharata of krishna-dwaipayana vyasa book 4 virata parva translated into english prose from the original sanskrit text by kisarI mohan gangulI [1883-1896] the mahabharata virata parva section (_pandava-pravesa parva_) om having bowed down to narayana and nara the most exalted of male beings and also to the goddess saraswatI must the word _jaya_ be uttered. janamejaya said \"how did my great-grandfathers afflicted with the fear of duryodhana pass their days'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11f83c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 914),\n",
       " (\".'\", 243),\n",
       " ('I', 112),\n",
       " ('the', 97),\n",
       " ('o', 70),\n",
       " ('it', 59),\n",
       " ('thou', 51),\n",
       " ('let', 46),\n",
       " ('do', 41),\n",
       " ('.\"', 37)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_word_counts = Counter([ p.replace('. ', '') for p in re.findall('\\..[^\" \"]*', text)])\n",
    "first_word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7042bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = [[sentence_start_token] for sent,times in first_word_counts if sent != 'o.']\n",
    "#y_train = [sent for sent in first_word_counts if sent != 'o.']\n",
    "X_train = [[sentence_start_token]*c for sent,c in first_word_counts.items() if sent != 'o.']\n",
    "y_train = [[sent]*c for sent,c in first_word_counts.items() if sent != 'o.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9ce2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [item for sublist in X_train for item in sublist]\n",
    "y_train = [item for sublist in y_train for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "339915ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SENTENCE_START',\n",
       " 'SENTENCE_START',\n",
       " 'SENTENCE_START',\n",
       " 'SENTENCE_START',\n",
       " 'SENTENCE_START',\n",
       " 'SENTENCE_START',\n",
       " 'SENTENCE_START',\n",
       " 'SENTENCE_START',\n",
       " 'SENTENCE_START',\n",
       " 'SENTENCE_START']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51d1bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hare', 'hare', 'janamejaya', '._', '._', '._', '._', 'having', 'having', 'having', 'having', 'having', 'having', 'having', 'having', 'having', 'having', 'having', 'having', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', 'do', \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", \".'\", 'still', 'still', 'surrounding', 'which', 'which', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'surely', 'surely', 'surely', 'surely', 'surely', 'surely', 'surely', 'surely', 'surely', 'surely', 'surely', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'even', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'how', 'how', 'how', 'how', 'how', 'presenting', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'but', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'wearing', 'wearing', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', 'then', '.\"[2]', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'section', 'section', 'section', 'section', 'section', 'section', 'section', 'section', 'section', 'section', 'section', 'section', 'besides', 'at', '.[3]', 'thus', 'thus', 'thus', 'thus', 'thus', 'thus', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', '[4]', '', '', '', '', '', '', '', '', '', 'passing', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'let', 'formerly', 'formerly', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'indeed', 'verily', 'verily', 'verily', 'verily', 'unacquainted', 'devoted', 'devoted', 'devoted', 'other', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', '.--wilson.', 'chaste', 'ye', 'ye', 'ye', 'ye', 'ye', 'ye', 'yet', 'mark', 'mark', 'mark', '.[6]', 'nor', 'nor', 'nor', 'nor', 'nor', 'nor', 'nor', 'nor', 'nor', 'nor', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'paying', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'one', 'one', 'one', 'behaving', 'kings', 'kings', 'renouncing', 'after', 'after', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'always', 'always', 'always', 'always', '.[7]', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'none', 'none', '.[8]', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'by', 'commissioned', 'regaining', '[7]', 'nilakantha', 'nilakantha', 'nilakantha', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', '[8]', 'following', 'following', 'blessed', 'blessed', 'blessed', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', 'there', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', '.\"', 'from', 'from', 'pass', 'just', 'just', 'further', 'further', 'stowing', 'we', 'we', 'we', 'we', 'we', 'we', 'we', 'we', 'we', 'we', 'we', 'we', 'we', 'we', 'jaya', 'salutations', 'salutations', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'thou', 'sable', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'grant', 'thy', 'thy', 'thy', 'thy', 'thy', 'thy', 'thy', 'thy', 'capable', 'capable', 'those', 'those', 'durga', '[10]', 'vaisampayana', 'vaisampayana', 'vaisampayana', 'vaisampayana', 'vaisampayana', 'vaisampayana', 'vaisampayana', 'vaisampayana', 'vaisampayana', 'vaisampayana', 'vaisampayana', 'methinks', 'methinks', '.--I', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'when', 'revolving', 'beholding', 'beholding', 'beholding', 'beholding', 'beholding', 'be', 'be', 'be', '(on', 'your', 'art', 'art', 'draupadI', 'attracted', 'any', 'any', 'any', 'was', 'people', 'people', 'people', 'my', 'my', 'my', 'my', 'my', 'my', 'my', 'my', 'my', 'my', 'my', 'my', 'my', 'also', 'all', 'all', 'all', 'all', 'all', 'all', 'all', 'all', 'all', 'all', 'all', 'henceforth', 'am', 'am', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'as', 'instruct', 'not', 'not', 'not', 'oh', 'oh', 'oh', 'oh', 'an', '.[12]', '_some_', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'this', 'or', 'or', 'or', 'or', 'or', 'or', 'or', 'or', 'or', 'or', 'or', 'or', 'who', 'who', 'who', 'who', 'who', 'who', 'who', 'who', 'who', 'both', 'both', 'both', 'both', 'both', 'both', 'resembling', 'union', 'decked', 'drinking', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'therefore', 'overcome', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'becoming', 'know', 'know', 'know', 'enraged', 'come', 'come', 'thereupon', 'thereupon', 'thereupon', 'thereupon', 'thereupon', 'thereupon', 'thereat', 'alas', 'alas', 'alas', 'alas', 'alas', 'alas', 'alas', 'alas', 'alas', 'alas', 'alas', 'alas', 'alas', 'alas', 'alas', 'where', 'where', 'kichaka', 'kichaka', 'these', 'these', 'these', 'these', 'these', 'retire', 'whither', 'whether', 'whether', 'whether', '.--thus', 'censure', 'bards', 'possessed', 'possessed', 'possessed', 'possessed', 'sairindhrI', 'seeing', 'seeing', 'ardently', 'delicate', 'behold', 'behold', 'behold', 'behold', 'behold', 'granthika', '.[14]', 'success', 'prosperity', 'nothing', 'plunged', 'queen', 'surrounded', 'sorely', 'you', 'you', 'you', 'you', 'you', 'you', 'she', 'she', 'she', 'she', 'she', 'yudhishthira', 'yudhishthira', 'lopamudra', 'angry', 'understanding', 'felling', 'rebuked', 'shall', 'although', 'although', 'presuming', 'far', '.e.', 'they', 'they', 'they', 'they', 'they', 'they', 'they', 'they', 'they', 'attacked', 'commanding', 'neither', 'promise', 'afflicted', 'afflicted', 'meanwhile', 'meanwhile', 'meanwhile', 'meanwhile', 'meanwhile', 'alone', 'alone', 'alone', 'alone', 'alone', 'alone', 'alone', 'alone', 'alone', 'alone', 'slay', 'except', '.e._', 'skilled', 'thyself', 'impetuously', '.[17]', \"._'\", 'return', '_sairindhri_', '_sairindhri_', 'men', 'men', 'devise', 'go', 'go', 'go', 'protected', 'protected', 'protected', 'protected', '.\"\\'', '.\"\\'', '.--the', 'without', 'without', 'without', 'without', 'without', '.[20]', 'searched', 'searched', 'searched', 'searched', 'good', 'king', 'discern', 'filled', 'perhaps', 'brave', 'heroic', 'intelligent', 'knowing', 'knowing', 'endued', 'endued', 'endued', 'endued', 'aided', 'aided', 'counsels', 'charitable', 'agreeable', '.--taste', 'regarding', 'reflecting', 'instead', '[22]', 'listen', 'listen', 'listen', '.[25]', '[24]', '[25]', 'crooked', 'uniting', 'consulting', 'give', 'bearing', 'bearing', 'each', '[28]', '.[29]', '.[30]', '[30]', '.[31]', 'uprooting', 'take', 'take', 'take', 'fighting', 'within', 'within', 'is', '[33]', 'delivered', 'mayst', 'rise', '.\"--oh', 'its', '.[34]', 'vanquishing', 'vanquishing', 'son', 'briefly', 'along', 'look', 'penetrating', 'like', 'like', 'like', 'like', 'like', 'finding', 'tried', '.[38]', '[37]', '[38]', '(by', 'requested', 'love.', 'think', \"'if\", 'defeating', '.[40]', 'see', 'see', 'see', 'vrihannala', 'his', 'turn', 'turn', 'fear', 'our', 'our', '.[41]', 'such', 'such', 'such', 'stay', 'stay', 'protect', 'protect', 'stand', 'put', 'taught', 'arjuna', 'arjuna', '[42]', 'nadijI', '_lankesa-vanari-ketu_', 'nagahvaya', 'nagri-sunu', 'large', 'heir', 'whose', 'great', '[44]', '[45]', '[46]', '[47]', 'embellished', 'worshipped', 'shiva', 'afterwards', '.[49]', 'adored', 'partha', 'partha', 'partha', 'cased', '[49]', 'accomplishing', 'tie', 'foolish', 'trained', '.[51]', '.[52]', 'never', 'never', 'truly', 'yon', 'lo', 'things', 'vultures', 'sending', '.[54]', 'vibhatsu', '.[55]', '.[56]', 'make', 'make', 'make', 'everything', 'everything', 'everything', 'preceptors', 'performing', 'disregarding', 'disregarding', 'placing', 'place', 'some', '[55]', 'duryodhana', 'shot', 'discharged', 'discharged', 'strongly', 'slaying', 'hard', 'irresistible', 'pierced', 'pierced', 'struck', 'struck', 'learned', 'considering', 'taking', 'dishonestly', 'fire', 'mutely', 'actuated', 'employ', 'bound', 'should', 'proceed', 'myself', 'completing', 'leaving', 'strive', 'foes', 'entertained', 'while', 'forgiveness', 'today', 'abandoning', 'fettered', 'reap', 'assure', \"'take\", 'jishnu', 'dhananjaya', 'dhananjaya', '.--', 'bravo', 'wonderful', 'so', 'so', 'on', 'ever', 'inflamed', 'anger', 'had', 'equal', 'kind', 'steady', 'well-versed', 'under', 'surpassing', 'creating', '.s.', '.s.', '.s.', '.s.', '.s.', '.s.', 'special', 'project', 'project', 'project', 'redistribution', 'start', '.gutenberg.org/license.', 'general', 'general', '.a.', '.e.8.', '.e.8.', '.b.', 'below.', '.e', '1.', '1.', 'nearly', 'copyright', '1.e.', '.e.1.', '.e.1.', '.gutenberg.org.', '.gutenberg.org.', '.gutenberg.org.', '1.e.2.', '.e.1', '.e.1', '.e.1', '.e.7', '.e.7', '.e.8', '.e.8', '.e.9.', '.e.9.', '.e.3.', 'additional', '1.e.4.', '1.e.5.', '1.e.6.', 'however', '.gutenberg.org)', '.e.7.', 'royalty', 'royalty', '.”', '•', '•', '.f.3', '.f.3', '.f.3', '1.e.9.', 'contact', '1.f.', '.f.1.', 'despite', '1.f.2.', '.f.3.', '1.f.3.', '1.f.4.', '1.f.5.', '1.f.6.', 'information', 'information', 'information', 'volunteers', 'contributions', 'email', '.gutenberg.org/contact', 'many', 'compliance', '.gutenberg.org/donate.', '.gutenberg.org/donate.', 'international', 'u.s.', 'please', 'donations', 'hart', 'most']\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75aa3f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2828, 2828)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2103cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def fisher_yates (arr1, arr2):\n",
    "     \n",
    "    # We will Start from the last element\n",
    "    # and swap one by one.\n",
    "    n = len(arr1)\n",
    "    if n != len(arr2):\n",
    "        return None\n",
    "    \n",
    "    for i in range(n - 1, 0, -1):\n",
    "\n",
    "        # Pick a random index from 0 to i\n",
    "        j = random.randint(0, i)\n",
    "        #print(i, j)\n",
    "\n",
    "        # Swap arr[i] with the element at random index\n",
    "        arr1[i], arr1[j] = arr1[j], arr1[i]\n",
    "        arr2[i], arr2[j] = arr2[j], arr2[i]\n",
    "        \n",
    "    return arr1, arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43d2326b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['a', 'b', 'c'], ['1', '2', '3'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random as rd\n",
    "one = ['a', 'b', 'c']\n",
    "two = ['1', '2', '3']\n",
    "one, two = fisher_yates(one, two)\n",
    "one, two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bcafdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['b'], ['c'], ['a']], [['2'], ['3'], ['1']])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = [['a'], ['b'], ['c']]\n",
    "two = [['1'], ['2'], ['3']]\n",
    "one, two = fisher_yates(one, two)\n",
    "one, two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "669d47c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2828, 2828)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = fisher_yates(X_train, y_train)\n",
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14173882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokens = [[word_to_index[symbol]] for symbol,word in zip(X_train, y_train) if word in word_to_index]\n",
    "y_tokens = [[word_to_index[word]] for symbol,word in zip(X_train, y_train) if word in word_to_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c878b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_tokens\n",
    "y_train = y_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70eb2358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2424, 2424)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a1922c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[3], [3], [3], [3], [3]], [[15], [2], [2], [2], [2]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:5], y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aaa1a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram- 2 length: 36579\n",
      "ngram- 3 length: 56161\n",
      "ngram- 4 length: 62475\n",
      "ngram- 5 length: 64577\n",
      "ngram- 6 length: 65318\n",
      "ngram- 7 length: 65561\n",
      "ngram- 8 length: 65656\n",
      "ngram- 9 length: 65698\n",
      "ngram- 10 length: 65723\n",
      "ngram- 11 length: 65736\n",
      "ngram- 12 length: 65747\n",
      "ngram- 13 length: 65755\n",
      "ngram- 14 length: 65763\n",
      "ngram- 15 length: 65771\n",
      "ngram- 16 length: 65779\n",
      "ngram- 17 length: 65784\n",
      "ngram- 18 length: 65786\n",
      "ngram- 19 length: 65787\n",
      "ngram- 20 length: 65788\n"
     ]
    }
   ],
   "source": [
    "ngrams_up_to_20 = []\n",
    "for i in range(2, 21):\n",
    "    ngram_counts = Counter(ngrams(text.split(), i))\n",
    "    print('ngram-', i, 'length:', len(ngram_counts))\n",
    "    ngrams_up_to_20.append(ngram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12fa9858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_periods(ngram):\n",
    "    for wrd in ngram[0]:\n",
    "        if '.' in wrd or \"’\" in wrd or \"‘\" in wrd:\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "def my_filter(ngrams):\n",
    "    return filter(remove_periods, ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5aa51df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7793,\n",
       " [(('of', 'the'), 665),\n",
       "  (('in', 'the'), 289),\n",
       "  (('and', 'the'), 258),\n",
       "  (('son', 'of'), 234),\n",
       "  (('to', 'the'), 167),\n",
       "  (('by', 'the'), 166),\n",
       "  (('the', 'son'), 152),\n",
       "  (('the', 'king'), 148),\n",
       "  (('on', 'the'), 144),\n",
       "  (('with', 'the'), 143),\n",
       "  (('of', 'a'), 113),\n",
       "  (('of', 'his'), 94),\n",
       "  (('foremost', 'of'), 85),\n",
       "  (('like', 'a'), 85),\n",
       "  (('of', 'pandu'), 83),\n",
       "  (('began', 'to'), 83),\n",
       "  (('vaisampayana', 'continued'), 82),\n",
       "  (('from', 'the'), 76),\n",
       "  (('it', 'is'), 76),\n",
       "  (('o', 'king'), 75),\n",
       "  (('sons', 'of'), 75),\n",
       "  (('endued', 'with'), 72),\n",
       "  (('the', 'kurus'), 69),\n",
       "  (('as', 'the'), 69),\n",
       "  (('king', 'of'), 67),\n",
       "  (('I', 'am'), 67),\n",
       "  (('to', 'be'), 67),\n",
       "  (('all', 'the'), 65),\n",
       "  (('o', 'thou'), 61),\n",
       "  (('I', 'shall'), 59),\n",
       "  (('in', 'a'), 59),\n",
       "  (('and', 'having'), 58),\n",
       "  (('at', 'the'), 58),\n",
       "  (('and', 'beholding'), 57),\n",
       "  (('of', 'all'), 56),\n",
       "  (('with', 'a'), 56),\n",
       "  (('like', 'the'), 55),\n",
       "  (('project', 'gutenberg™'), 55),\n",
       "  (('with', 'his'), 53),\n",
       "  (('in', 'battle'), 53),\n",
       "  (('the', 'sons'), 53),\n",
       "  (('do', 'thou'), 52),\n",
       "  (('thou', 'of'), 52),\n",
       "  (('the', 'matsyas'), 52),\n",
       "  (('is', 'the'), 52),\n",
       "  (('of', 'foes'), 52),\n",
       "  (('vaisampayana', 'said'), 50),\n",
       "  (('for', 'the'), 50),\n",
       "  (('these', 'words'), 50),\n",
       "  (('of', 'this'), 49),\n",
       "  (('and', 'then'), 49),\n",
       "  (('I', 'will'), 48),\n",
       "  (('do', 'not'), 48),\n",
       "  (('and', 'that'), 48),\n",
       "  (('the', 'city'), 47),\n",
       "  (('thou', 'art'), 47),\n",
       "  (('means', 'of'), 47),\n",
       "  (('and', 'o'), 46),\n",
       "  (('possessed', 'of'), 46),\n",
       "  (('as', 'a'), 45),\n",
       "  (('lord', 'of'), 44),\n",
       "  (('of', 'men'), 44),\n",
       "  (('thou', 'o'), 44),\n",
       "  (('I', 'have'), 44),\n",
       "  (('like', 'unto'), 44),\n",
       "  (('of', 'pritha'), 44),\n",
       "  (('will', 'be'), 43),\n",
       "  (('the', 'field'), 43),\n",
       "  (('the', 'kuru'), 42),\n",
       "  (('section', 'vaisampayana'), 42),\n",
       "  (('by', 'means'), 42),\n",
       "  (('of', 'their'), 42),\n",
       "  (('of', 'virata'), 41),\n",
       "  (('unto', 'the'), 41),\n",
       "  (('that', 'the'), 41),\n",
       "  (('among', 'men'), 40),\n",
       "  (('with', 'great'), 40),\n",
       "  (('on', 'his'), 40),\n",
       "  (('in', 'this'), 39),\n",
       "  (('best', 'of'), 39),\n",
       "  (('of', 'kuntI'), 39),\n",
       "  (('who', 'is'), 39),\n",
       "  (('the', 'mighty'), 39),\n",
       "  (('of', 'that'), 38),\n",
       "  (('that', 'is'), 38),\n",
       "  (('furnished', 'with'), 37),\n",
       "  (('each', 'other'), 37),\n",
       "  (('have', 'been'), 36),\n",
       "  (('that', 'I'), 35),\n",
       "  (('that', 'foremost'), 35),\n",
       "  (('capable', 'of'), 35),\n",
       "  (('it', 'was'), 35),\n",
       "  (('desirous', 'of'), 34),\n",
       "  (('decked', 'with'), 34),\n",
       "  (('towards', 'the'), 33),\n",
       "  (('of', 'battle'), 33),\n",
       "  (('the', 'project'), 31),\n",
       "  (('of', 'great'), 31),\n",
       "  (('field', 'of'), 31),\n",
       "  (('words', 'of'), 31),\n",
       "  (('o', 'bharata'), 30),\n",
       "  (('the', 'midst'), 30),\n",
       "  (('midst', 'of'), 30),\n",
       "  (('fight', 'with'), 29),\n",
       "  (('of', 'my'), 29),\n",
       "  (('the', '_gandiva_'), 29),\n",
       "  (('the', 'very'), 29),\n",
       "  (('the', 'kine'), 29),\n",
       "  (('that', 'are'), 28),\n",
       "  (('even', 'as'), 28),\n",
       "  (('the', 'pandavas'), 28),\n",
       "  (('and', 'with'), 28),\n",
       "  (('king', 'yudhishthira'), 28),\n",
       "  (('his', 'car'), 28),\n",
       "  (('and', 'he'), 27),\n",
       "  (('that', 'mighty'), 27),\n",
       "  (('the', 'sun'), 27),\n",
       "  (('his', 'own'), 27),\n",
       "  (('and', 'other'), 27),\n",
       "  (('bull', 'among'), 27),\n",
       "  (('and', 'it'), 27),\n",
       "  (('and', 'as'), 27),\n",
       "  (('the', 'foe'), 27),\n",
       "  (('and', 'in'), 26),\n",
       "  (('and', 'when'), 26),\n",
       "  (('the', 'other'), 26),\n",
       "  (('in', 'that'), 26),\n",
       "  (('and', 'they'), 26),\n",
       "  (('who', 'was'), 26),\n",
       "  (('slayer', 'of'), 26),\n",
       "  (('had', 'been'), 26),\n",
       "  (('and', 'all'), 25),\n",
       "  (('filled', 'with'), 25),\n",
       "  (('by', 'a'), 25),\n",
       "  (('drona', 'and'), 25),\n",
       "  (('cut', 'off'), 25),\n",
       "  (('project', 'gutenberg'), 24),\n",
       "  (('afflicted', 'with'), 24),\n",
       "  (('not', 'be'), 24),\n",
       "  (('is', 'not'), 24),\n",
       "  (('then', 'the'), 24),\n",
       "  (('to', 'thee'), 24),\n",
       "  (('and', 'those'), 24),\n",
       "  (('when', 'the'), 24),\n",
       "  (('and', 'his'), 24),\n",
       "  (('of', 'those'), 24),\n",
       "  (('he', 'is'), 23),\n",
       "  (('as', 'thou'), 23),\n",
       "  (('the', 'earth'), 23),\n",
       "  (('is', 'a'), 23),\n",
       "  (('what', 'is'), 23),\n",
       "  (('and', 'let'), 23),\n",
       "  (('this', 'is'), 23),\n",
       "  (('the', 'whole'), 23),\n",
       "  (('set', 'out'), 23),\n",
       "  (('thou', 'hast'), 23),\n",
       "  (('deprived', 'of'), 23),\n",
       "  (('a', 'hundred'), 23),\n",
       "  (('all', 'this'), 23),\n",
       "  (('king', 'and'), 22),\n",
       "  (('city', 'of'), 22),\n",
       "  (('all', 'his'), 22),\n",
       "  (('kuru', 'race'), 22),\n",
       "  (('skilled', 'in'), 22),\n",
       "  (('and', 'who'), 22),\n",
       "  (('the', 'foremost'), 22),\n",
       "  (('able', 'to'), 22),\n",
       "  (('is', 'that'), 22),\n",
       "  (('with', 'their'), 22),\n",
       "  (('on', 'their'), 22),\n",
       "  (('said', 'unto'), 22),\n",
       "  (('the', 'kauravas'), 22),\n",
       "  (('I', 'do'), 22),\n",
       "  (('with', 'gold'), 22),\n",
       "  (('the', 'ground'), 22),\n",
       "  (('arrows.', 'and'), 22),\n",
       "  (('said', \"'o\"), 21),\n",
       "  (('may', 'not'), 21),\n",
       "  (('among', 'the'), 21),\n",
       "  (('as', 'they'), 21),\n",
       "  (('from', 'his'), 21),\n",
       "  (('in', 'his'), 21),\n",
       "  (('that', 'of'), 21),\n",
       "  (('in', 'battle.'), 21),\n",
       "  (('for', 'a'), 21),\n",
       "  (('dost', 'thou'), 21),\n",
       "  (('hath', 'been'), 21),\n",
       "  (('incapable', 'of'), 21),\n",
       "  (('the', 'trigartas'), 21),\n",
       "  (('we', 'have'), 20),\n",
       "  (('of', 'mighty'), 20),\n",
       "  (('said', \"'I\"), 20),\n",
       "  (('horses', 'and'), 20),\n",
       "  (('to', 'me'), 20),\n",
       "  (('this', 'that'), 20),\n",
       "  (('by', 'me'), 20),\n",
       "  (('beholding', 'that'), 20),\n",
       "  (('into', 'the'), 20),\n",
       "  (('and', 'seeing'), 20),\n",
       "  (('of', 'thy'), 20),\n",
       "  (('the', 'celestials'), 20),\n",
       "  (('of', 'being'), 20),\n",
       "  (('therefore', 'o'), 19),\n",
       "  (('living', 'in'), 19),\n",
       "  (('it', 'behoveth'), 19),\n",
       "  (('he', 'that'), 19),\n",
       "  (('out', 'of'), 19),\n",
       "  (('the', 'illustrious'), 19),\n",
       "  (('the', 'great'), 19),\n",
       "  (('decked', 'in'), 19),\n",
       "  (('for', 'this'), 19),\n",
       "  (('gold', 'and'), 19),\n",
       "  (('king', 'virata'), 19),\n",
       "  (('and', 'a'), 19),\n",
       "  (('great', 'energy'), 19),\n",
       "  (('the', 'princess'), 19),\n",
       "  (('the', 'car'), 19),\n",
       "  (('devoted', 'to'), 18),\n",
       "  (('that', 'best'), 18),\n",
       "  (('elephants', 'and'), 18),\n",
       "  (('car', 'and'), 18),\n",
       "  (('o', 'son'), 18),\n",
       "  (('thee', 'o'), 18),\n",
       "  (('o', 'bull'), 18),\n",
       "  (('daughter', 'of'), 18),\n",
       "  (('such', 'a'), 18),\n",
       "  (('there', 'is'), 18),\n",
       "  (('without', 'doubt'), 18),\n",
       "  (('is', 'for'), 18),\n",
       "  (('at', 'this'), 18),\n",
       "  (('will', 'not'), 18),\n",
       "  (('unto', 'a'), 18),\n",
       "  (('let', 'the'), 18),\n",
       "  (('and', 'your'), 18),\n",
       "  (('and', 'both'), 18),\n",
       "  (('and', 'at'), 18),\n",
       "  (('adorned', 'with'), 18),\n",
       "  (('that', 'slayer'), 18),\n",
       "  (('that', 'hero'), 18),\n",
       "  (('the', 'preceptor'), 18),\n",
       "  (('gutenberg™', 'electronic'), 18),\n",
       "  (('o', 'lord'), 17),\n",
       "  (('who', 'had'), 17),\n",
       "  (('tell', 'me'), 17),\n",
       "  (('dhananjaya', 'the'), 17),\n",
       "  (('o', 'monarch'), 17),\n",
       "  (('they', 'are'), 17),\n",
       "  (('as', 'I'), 17),\n",
       "  (('to', 'his'), 17),\n",
       "  (('of', 'an'), 17),\n",
       "  (('yudhishthira', 'the'), 17),\n",
       "  (('that', 'bull'), 17),\n",
       "  (('sight', 'of'), 17),\n",
       "  (('thou', 'that'), 17),\n",
       "  (('that', 'thou'), 17),\n",
       "  (('an', 'elephant'), 17),\n",
       "  (('the', 'same'), 17),\n",
       "  (('art', 'thou'), 17),\n",
       "  (('me', 'to'), 17),\n",
       "  (('and', 'kripa'), 17),\n",
       "  (('of', 'mail'), 17),\n",
       "  (('arrows', 'shot'), 17),\n",
       "  (('shot', 'from'), 17),\n",
       "  (('bhishma', 'and'), 17),\n",
       "  (('\"uttara', 'said'), 17),\n",
       "  (('terms', 'of'), 17),\n",
       "  (('one', 'of'), 16),\n",
       "  (('o', 'child'), 16),\n",
       "  (('before', 'the'), 16),\n",
       "  (('the', 'lord'), 16),\n",
       "  (('kinds', 'of'), 16),\n",
       "  (('by', 'that'), 16),\n",
       "  (('the', 'forest'), 16),\n",
       "  (('wielder', 'of'), 16),\n",
       "  (('with', 'all'), 16),\n",
       "  (('celestial', 'weapons'), 16),\n",
       "  (('weapons', 'and'), 16),\n",
       "  (('the', 'bharata'), 16),\n",
       "  (('in', 'order'), 16),\n",
       "  (('as', 'also'), 16),\n",
       "  (('and', 'there'), 16),\n",
       "  (('of', 'them'), 16),\n",
       "  (('in', 'all'), 16),\n",
       "  (('to', 'a'), 16),\n",
       "  (('cars', 'and'), 16),\n",
       "  (('those', 'mighty'), 16),\n",
       "  (('of', 'hostile'), 16),\n",
       "  (('to', 'fight'), 16),\n",
       "  (('that', 'hath'), 16),\n",
       "  (('beholding', 'the'), 16),\n",
       "  (('even', 'like'), 16),\n",
       "  (('hearing', 'these'), 16),\n",
       "  (('the', 'sky'), 16),\n",
       "  (('with', 'golden'), 16),\n",
       "  (('the', 'arrows'), 16),\n",
       "  (('and', 'I'), 15),\n",
       "  (('men', 'and'), 15),\n",
       "  (('bull', 'of'), 15),\n",
       "  (('bharata', 'race'), 15),\n",
       "  (('to', 'live'), 15),\n",
       "  (('as', 'he'), 15),\n",
       "  (('presence', 'of'), 15),\n",
       "  (('in', 'their'), 15),\n",
       "  (('in', 'consequence'), 15),\n",
       "  (('the', 'heroic'), 15),\n",
       "  (('covered', 'with'), 15),\n",
       "  (('unto', 'him'), 15),\n",
       "  (('him', 'with'), 15),\n",
       "  (('various', 'kinds'), 15),\n",
       "  (('and', 'elephants'), 15),\n",
       "  (('they', 'were'), 15),\n",
       "  (('is', 'this'), 15),\n",
       "  (('the', 'twang'), 15),\n",
       "  (('twang', 'of'), 15),\n",
       "  (('the', 'mighty-armed'), 15),\n",
       "  (('of', 'arrows'), 15),\n",
       "  (('the', 'hostile'), 15),\n",
       "  (('and', 'drona'), 15),\n",
       "  (('kripa', 'and'), 15),\n",
       "  (('the', 'royal'), 14),\n",
       "  (('was', 'the'), 14),\n",
       "  (('and', 'mighty'), 14),\n",
       "  (('on', 'a'), 14),\n",
       "  (('a', 'single'), 14),\n",
       "  (('tiger', 'among'), 14),\n",
       "  (('be', 'able'), 14),\n",
       "  (('according', 'to'), 14),\n",
       "  (('may', 'be'), 14),\n",
       "  (('a', 'great'), 14),\n",
       "  (('worthy', 'of'), 14),\n",
       "  (('gods', 'and'), 14),\n",
       "  (('or', 'the'), 14),\n",
       "  (('and', 'whose'), 14),\n",
       "  (('arms', 'and'), 14),\n",
       "  (('thee', 'to'), 14),\n",
       "  (('continued', '\"thus'), 14),\n",
       "  (('\"thus', 'addressed'), 14),\n",
       "  (('battle.', 'and'), 14),\n",
       "  (('a', 'large'), 14),\n",
       "  (('with', 'an'), 14),\n",
       "  (('the', 'gods'), 14),\n",
       "  (('and', 'by'), 14),\n",
       "  (('with', 'him'), 14),\n",
       "  (('him', 'saying'), 14),\n",
       "  (('to', 'thy'), 14),\n",
       "  (('if', 'thou'), 14),\n",
       "  (('arrows', 'and'), 14),\n",
       "  (('looked', 'like'), 14),\n",
       "  (('of', 'thine'), 14),\n",
       "  (('protected', 'by'), 14),\n",
       "  (('with', 'wrath'), 14),\n",
       "  (('when', 'thou'), 14),\n",
       "  (('have', 'not'), 14),\n",
       "  (('the', 'matsya'), 14),\n",
       "  (('through', 'the'), 14),\n",
       "  (('conversant', 'with'), 14),\n",
       "  (('arrows', 'of'), 14),\n",
       "  (('shot', 'by'), 14),\n",
       "  (('the', 'prince'), 14),\n",
       "  (('electronic', 'works'), 14),\n",
       "  (('if', 'you'), 14),\n",
       "  (('this', 'agreement'), 14),\n",
       "  (('virata', 'and'), 13),\n",
       "  (('he', 'had'), 13),\n",
       "  (('thou', 'therefore'), 13),\n",
       "  (('\"arjuna', 'said'), 13),\n",
       "  (('to', 'bear'), 13),\n",
       "  (('like', 'an'), 13),\n",
       "  (('me', 'in'), 13),\n",
       "  (('in', 'such'), 13),\n",
       "  (('that', 'they'), 13),\n",
       "  (('the', 'best'), 13),\n",
       "  (('the', 'wielder'), 13),\n",
       "  (('of', 'kings'), 13),\n",
       "  (('continued', '\"having'), 13),\n",
       "  (('accompanied', 'by'), 13),\n",
       "  (('behoveth', 'thee'), 13),\n",
       "  (('should', 'not'), 13),\n",
       "  (('a', 'person'), 13),\n",
       "  (('also', 'the'), 13),\n",
       "  (('this', 'one'), 13),\n",
       "  (('addressed', 'by'), 13),\n",
       "  (('strength', 'and'), 13),\n",
       "  (('is', 'there'), 13),\n",
       "  (('consequence', 'of'), 13),\n",
       "  (('the', 'full'), 13),\n",
       "  (('in', 'thy'), 13),\n",
       "  (('be', 'thou'), 13),\n",
       "  (('him.', 'and'), 13),\n",
       "  (('addressed', 'him'), 13),\n",
       "  (('of', 'gold'), 13),\n",
       "  (('is', 'like'), 13),\n",
       "  (('the', 'high-souled'), 13),\n",
       "  (('\"virata', 'said'), 13),\n",
       "  (('a', 'thousand'), 13),\n",
       "  (('the', 'people'), 13),\n",
       "  (('could', 'not'), 13),\n",
       "  (('ground.', 'and'), 13),\n",
       "  (('o', 'beauteous'), 13),\n",
       "  (('energy', 'and'), 13),\n",
       "  (('this', 'the'), 13),\n",
       "  (('the', 'ground.'), 13),\n",
       "  (('down', 'on'), 13),\n",
       "  (('addressed', 'the'), 13),\n",
       "  (('of', 'her'), 13),\n",
       "  (('thousands', 'of'), 13),\n",
       "  ((\"pritha's\", 'son'), 13),\n",
       "  (('thou', 'hadst'), 13),\n",
       "  (('taking', 'up'), 13),\n",
       "  (('the', 'time'), 13),\n",
       "  (('coat', 'of'), 13),\n",
       "  (('shafts.', 'and'), 13),\n",
       "  (('his', 'bow'), 13),\n",
       "  ((\"virata's\", 'son'), 13),\n",
       "  (('and', 'bhishma'), 13),\n",
       "  (('of', 'weapons'), 13),\n",
       "  (('the', 'steeds'), 13),\n",
       "  (('gutenberg', 'literary'), 13),\n",
       "  (('literary', 'archive'), 13),\n",
       "  (('and', 'also'), 12),\n",
       "  (('that', 'had'), 12),\n",
       "  (('made', 'of'), 12),\n",
       "  (('all', 'those'), 12),\n",
       "  (('me', 'as'), 12),\n",
       "  (('with', 'me'), 12),\n",
       "  (('the', 'thunderbolt'), 12),\n",
       "  (('me', 'and'), 12),\n",
       "  (('under', 'the'), 12),\n",
       "  (('of', 'earth'), 12),\n",
       "  (('princess', 'of'), 12),\n",
       "  (('engaged', 'in'), 12),\n",
       "  (('the', \"king's\"), 12),\n",
       "  (('those', 'that'), 12),\n",
       "  (('the', 'place'), 12),\n",
       "  (('mighty', 'warriors'), 12),\n",
       "  (('a', 'mighty'), 12),\n",
       "  (('they', 'will'), 12),\n",
       "  (('he', 'will'), 12),\n",
       "  (('beauty', 'and'), 12),\n",
       "  (('saying', \"'o\"), 12),\n",
       "  (('a', 'lion'), 12),\n",
       "  (('that', 'he'), 12),\n",
       "  (('who', 'are'), 12),\n",
       "  (('to', 'have'), 12),\n",
       "  (('of', 'pandu.'), 12),\n",
       "  (('as', 'if'), 12),\n",
       "  (('acquainted', 'with'), 12),\n",
       "  (('continued', '\"then'), 12),\n",
       "  (('the', 'powerful'), 12),\n",
       "  (('afflicted', 'by'), 12),\n",
       "  (('of', 'immeasurable'), 12),\n",
       "  (('like', 'that'), 12),\n",
       "  (('thus', 'addressed'), 12),\n",
       "  (('who', 'hath'), 12),\n",
       "  (('o', 'bhima'), 12),\n",
       "  (('hero', 'of'), 12),\n",
       "  (('upon', 'the'), 12),\n",
       "  (('karna', 'and'), 12),\n",
       "  (('along', 'with'), 12),\n",
       "  (('off', 'by'), 12),\n",
       "  (('of', 'cars'), 12),\n",
       "  (('all', 'sides'), 12),\n",
       "  (('the', 'blare'), 12),\n",
       "  (('blare', 'of'), 12),\n",
       "  (('the', 'united'), 12),\n",
       "  (('the', 'terms'), 12),\n",
       "  (('thirteenth', 'year'), 11),\n",
       "  (('\"yudhishthira', 'said'), 11),\n",
       "  (('by', 'his'), 11),\n",
       "  (('as', 'one'), 11),\n",
       "  (('on', 'my'), 11),\n",
       "  (('down', 'from'), 11),\n",
       "  (('the', 'inner'), 11),\n",
       "  (('said', 'this'), 11),\n",
       "  (('no', 'one'), 11),\n",
       "  (('and', 'what'), 11),\n",
       "  (('thou', 'wilt'), 11),\n",
       "  (('also', 'with'), 11),\n",
       "  (('all', 'these'), 11),\n",
       "  (('and', 'arjuna'), 11),\n",
       "  (('have', 'to'), 11),\n",
       "  (('by', 'those'), 11),\n",
       "  (('about', 'the'), 11),\n",
       "  (('and', 'of'), 11),\n",
       "  (('the', 'latter'), 11),\n",
       "  (('and', 'for'), 11),\n",
       "  (('the', 'country'), 11),\n",
       "  (('of', 'elephants'), 11),\n",
       "  (('let', 'us'), 11),\n",
       "  (('that', 'son'), 11),\n",
       "  (('and', 'their'), 11),\n",
       "  (('the', 'moon'), 11),\n",
       "  (('the', 'entire'), 11),\n",
       "  (('that', 'will'), 11),\n",
       "  (('chastiser', 'of'), 11),\n",
       "  (('said', '\"then'), 11),\n",
       "  (('and', 'like'), 11),\n",
       "  (('and', 'possessed'), 11),\n",
       "  (('a', 'celestial'), 11),\n",
       "  (('what', 'thou'), 11),\n",
       "  (('in', 'hand'), 11),\n",
       "  (('those', 'of'), 11),\n",
       "  (('the', 'gandharvas'), 11),\n",
       "  (('or', 'a'), 11),\n",
       "  (('surrounded', 'by'), 11),\n",
       "  (('and', 'bhima'), 11),\n",
       "  (('and', 'each'), 11),\n",
       "  (('was', 'thus'), 11),\n",
       "  (('my', 'heart'), 11),\n",
       "  (('resembling', 'the'), 11),\n",
       "  (('with', 'such'), 11),\n",
       "  (('not', 'o'), 11),\n",
       "  (('forth', 'in'), 11),\n",
       "  (('of', 'kichaka'), 11),\n",
       "  (('as', 'his'), 11),\n",
       "  (('of', 'time'), 11),\n",
       "  (('bhishma', 'the'), 11),\n",
       "  (('and', 'furnished'), 11),\n",
       "  (('we', 'will'), 11),\n",
       "  (('order', 'of'), 11),\n",
       "  (('shower', 'of'), 11),\n",
       "  (('off', 'the'), 11),\n",
       "  (('son', 'and'), 11),\n",
       "  (('o', 'vrihannala'), 11),\n",
       "  (('array', 'of'), 11),\n",
       "  (('by', 'partha'), 11),\n",
       "  (('whose', 'is'), 11),\n",
       "  (('of', 'partha'), 11),\n",
       "  (('mighty', 'car-warrior'), 11),\n",
       "  (('inflamed', 'with'), 11),\n",
       "  (('for', 'its'), 11),\n",
       "  (('electronic', 'work'), 11),\n",
       "  (('archive', 'foundation'), 11),\n",
       "  (('all', 'that'), 10),\n",
       "  (('the', 'thirteenth'), 10),\n",
       "  (('of', 'these'), 10),\n",
       "  (('o', 'foremost'), 10),\n",
       "  (('mighty', 'arms'), 10),\n",
       "  (('I', 'was'), 10),\n",
       "  (('the', 'name'), 10),\n",
       "  (('the', 'abode'), 10),\n",
       "  (('replied', \"'o\"), 10),\n",
       "  (('inner', 'apartments'), 10),\n",
       "  (('of', 'king'), 10),\n",
       "  (('agreeable', 'to'), 10),\n",
       "  (('and', 'horses'), 10),\n",
       "  (('and', 'taking'), 10),\n",
       "  (('knowledge', 'of'), 10),\n",
       "  (('wife', 'of'), 10),\n",
       "  (('the', 'king.'), 10),\n",
       "  (('and', 'always'), 10),\n",
       "  (('repair', 'to'), 10),\n",
       "  (('even', 'this'), 10),\n",
       "  (('is', 'my'), 10),\n",
       "  (('go', 'to'), 10),\n",
       "  (('one', 'another'), 10),\n",
       "  (('a', 'royal'), 10),\n",
       "  (('which', 'is'), 10),\n",
       "  (('even', 'if'), 10),\n",
       "  (('should', 'be'), 10),\n",
       "  (('the', 'presence'), 10),\n",
       "  (('for', 'their'), 10),\n",
       "  (('after', 'the'), 10),\n",
       "  (('and', 'various'), 10),\n",
       "  (('part', 'of'), 10),\n",
       "  (('is', 'in'), 10),\n",
       "  (('loss', 'of'), 10),\n",
       "  (('him', 'in'), 10),\n",
       "  (('in', 'these'), 10),\n",
       "  (('thou', 'shalt'), 10),\n",
       "  (('the', 'world'), 10),\n",
       "  (('beauty', 'of'), 10),\n",
       "  (('in', 'every'), 10),\n",
       "  (('him', 'to'), 10),\n",
       "  (('seems', 'to'), 10),\n",
       "  (('the', 'head'), 10),\n",
       "  (('sweet', 'smiles'), 10),\n",
       "  (('came', 'to'), 10),\n",
       "  (('beauteous', 'lady'), 10),\n",
       "  (('of', 'sweet'), 10),\n",
       "  (('bow', 'and'), 10),\n",
       "  (('the', 'matsyas.'), 10),\n",
       "  (('steeds', 'and'), 10),\n",
       "  (('to', 'their'), 10),\n",
       "  (('and', 'terrible'), 10),\n",
       "  (('off', 'his'), 10),\n",
       "  (('other', 'with'), 10),\n",
       "  (('and', 'many'), 10),\n",
       "  (('with', 'thee'), 10),\n",
       "  (('fierce', 'and'), 10),\n",
       "  (('desire', 'of'), 10),\n",
       "  (('and', 'this'), 10),\n",
       "  (('by', 'thee'), 10),\n",
       "  (('of', 'graceful'), 10),\n",
       "  ((\"'do\", 'thou'), 10),\n",
       "  (('to', 'my'), 10),\n",
       "  (('a', 'golden'), 10),\n",
       "  (('unable', 'to'), 10),\n",
       "  (('where', 'king'), 10),\n",
       "  (('then', 'addressed'), 10),\n",
       "  (('heart', 'is'), 10),\n",
       "  (('of', 'terrible'), 10),\n",
       "  (('equal', 'unto'), 10),\n",
       "  (('I', 'would'), 10),\n",
       "  (('and', 'karna'), 10),\n",
       "  (('the', 'work'), 10),\n",
       "  (('rushed', 'towards'), 10),\n",
       "  (('his', 'body'), 10),\n",
       "  (('the', 'words'), 10),\n",
       "  (('they', 'have'), 10),\n",
       "  (('use', 'of'), 10),\n",
       "  (('between', 'the'), 10),\n",
       "  (('of', 'car-warriors'), 10),\n",
       "  (('the', 'reins'), 10),\n",
       "  (('of', 'arjuna'), 10),\n",
       "  ((\"drona's\", 'son'), 10),\n",
       "  (('arrows', 'furnished'), 10),\n",
       "  (('cased', 'in'), 10),\n",
       "  (('his', 'steeds'), 10),\n",
       "  (('pierced', 'the'), 10),\n",
       "  (('that', 'warrior'), 10),\n",
       "  (('access', 'to'), 10),\n",
       "  (('to', 'her'), 9),\n",
       "  (('the', 'brahmanas'), 9),\n",
       "  (('to', 'that'), 9),\n",
       "  (('and', 'is'), 9),\n",
       "  (('bulls', 'among'), 9),\n",
       "  (('name', 'of'), 9),\n",
       "  (('shall', 'not'), 9),\n",
       "  (('of', 'any'), 9),\n",
       "  (('and', 'on'), 9),\n",
       "  (('as', 'regards'), 9),\n",
       "  (('abode', 'of'), 9),\n",
       "  (('of', 'diverse'), 9),\n",
       "  (('the', 'palace'), 9),\n",
       "  (('the', 'kurus.'), 9),\n",
       "  (('of', 'whose'), 9),\n",
       "  (('beloved', 'wife'), 9),\n",
       "  (('all', 'of'), 9),\n",
       "  (('said', '\"having'), 9),\n",
       "  (('to', 'pass'), 9),\n",
       "  (('one', 'should'), 9),\n",
       "  (('he', 'who'), 9),\n",
       "  (('doth', 'not'), 9),\n",
       "  (('objects', 'of'), 9),\n",
       "  (('long', 'as'), 9),\n",
       "  (('set', 'forth'), 9),\n",
       "  (('and', 'not'), 9),\n",
       "  (('respect', 'of'), 9),\n",
       "  (('which', 'the'), 9),\n",
       "  (('those', 'heroes'), 9),\n",
       "  (('went', 'to'), 9),\n",
       "  (('great', 'strength'), 9),\n",
       "  (('took', 'up'), 9),\n",
       "  (('with', 'which'), 9),\n",
       "  (('which', 'he'), 9),\n",
       "  (('that', 'bow'), 9),\n",
       "  (('entered', 'the'), 9),\n",
       "  (('and', 'beautiful'), 9),\n",
       "  (('hath', 'come'), 9),\n",
       "  (('in', 'any'), 9),\n",
       "  (('equal', 'to'), 9),\n",
       "  (('head', 'of'), 9),\n",
       "  (('you', 'are'), 9),\n",
       "  (('the', '_sairindhri_'), 9),\n",
       "  (('tell', 'thee'), 9),\n",
       "  (('place', 'where'), 9),\n",
       "  (('any', 'other'), 9),\n",
       "  (('time', 'and'), 9),\n",
       "  (('and', 'arrows'), 9),\n",
       "  (('and', 'decked'), 9),\n",
       "  (('lords', 'of'), 9),\n",
       "  (('those', 'warriors'), 9),\n",
       "  (('is', 'no'), 9),\n",
       "  (('of', 'desire'), 9),\n",
       "  (('and', 'endued'), 9),\n",
       "  (('robes', 'and'), 9),\n",
       "  (('obedient', 'to'), 9),\n",
       "  (('o', 'timid'), 9),\n",
       "  (('why', 'dost'), 9),\n",
       "  (('continued', '\"hearing'), 9),\n",
       "  (('gems', 'and'), 9),\n",
       "  (('hostile', 'heroes'), 9),\n",
       "  (('for', 'his'), 9),\n",
       "  (('the', 'sound'), 9),\n",
       "  (('bhima', 'of'), 9),\n",
       "  (('of', 'matsya'), 9),\n",
       "  (('is', 'now'), 9),\n",
       "  (('o', 'hero'), 9),\n",
       "  (('that', 'terrible'), 9),\n",
       "  (('the', 'bharatas'), 9),\n",
       "  ((\"kunti's\", 'son'), 9),\n",
       "  (('of', 'wicked'), 9),\n",
       "  (('the', 'pandava'), 9),\n",
       "  (('with', 'mighty'), 9),\n",
       "  (('slain', 'by'), 9),\n",
       "  (('the', 'bristles'), 9),\n",
       "  (('king', 'duryodhana'), 9),\n",
       "  (('of', 'santanu'), 9),\n",
       "  (('battle', 'the'), 9),\n",
       "  (('arrayed', 'in'), 9),\n",
       "  (('clouds', 'of'), 9),\n",
       "  (('the', 'warriors'), 9),\n",
       "  (('excellent', 'bow'), 9),\n",
       "  (('kurus', 'and'), 9),\n",
       "  (('the', 'wind'), 9),\n",
       "  (('pierced', 'by'), 9),\n",
       "  (('car', 'of'), 9),\n",
       "  (('united', 'states'), 9),\n",
       "  (('the', 'most'), 8),\n",
       "  (('of', 'virata.'), 8),\n",
       "  (('abounding', 'in'), 8),\n",
       "  (('such', 'as'), 8),\n",
       "  (('wilt', 'thou'), 8),\n",
       "  (('a', 'king'), 8),\n",
       "  (('what', 'I'), 8),\n",
       "  (('a', 'brahmana'), 8),\n",
       "  (('what', 'office'), 8),\n",
       "  (('he', 'was'), 8),\n",
       "  (('is', 'as'), 8),\n",
       "  (('the', 'celestial'), 8),\n",
       "  (('from', 'my'), 8),\n",
       "  (('the', 'third'), 8),\n",
       "  (('of', \"virata's\"), 8),\n",
       "  (('by', 'this'), 8),\n",
       "  (('brother', 'of'), 8),\n",
       "  (('some', 'texts'), 8),\n",
       "  (('within', 'the'), 8),\n",
       "  (('live', 'in'), 8),\n",
       "  ((\"'I\", 'will'), 8),\n",
       "  (('the', 'daughter'), 8),\n",
       "  (('garlands', 'and'), 8),\n",
       "  (('there', 'are'), 8),\n",
       "  (('not', 'know'), 8),\n",
       "  (('where', 'the'), 8),\n",
       "  (('yudhishthira', 'and'), 8),\n",
       "  (('to', 'make'), 8),\n",
       "  (('be', 'a'), 8),\n",
       "  (('royal', 'household.'), 8),\n",
       "  (('on', 'all'), 8),\n",
       "  (('not', 'to'), 8),\n",
       "  (('to', 'do'), 8),\n",
       "  (('the', 'left'), 8),\n",
       "  (('before', 'him'), 8),\n",
       "  (('if', 'the'), 8),\n",
       "  (('his', 'son'), 8),\n",
       "  (('long', 'and'), 8),\n",
       "  (('in', 'respect'), 8),\n",
       "  (('as', 'an'), 8),\n",
       "  (('and', 'others'), 8),\n",
       "  (('with', 'various'), 8),\n",
       "  (('_sami_', 'tree'), 8),\n",
       "  (('I', 'think'), 8),\n",
       "  (('was', 'like'), 8),\n",
       "  (('the', 'roar'), 8),\n",
       "  (('roar', 'of'), 8),\n",
       "  (('of', 'battle.'), 8),\n",
       "  (('his', 'brothers'), 8),\n",
       "  (('of', 'fair'), 8),\n",
       "  (('both', 'of'), 8),\n",
       "  (('couple', 'of'), 8),\n",
       "  (('an', 'excellent'), 8),\n",
       "  (('thou', 'the'), 8),\n",
       "  (('them', 'that'), 8),\n",
       "  (('also', 'that'), 8),\n",
       "  (('on', 'earth'), 8),\n",
       "  (('having', 'said'), 8),\n",
       "  (('looking', 'like'), 8),\n",
       "  (('addressed', 'his'), 8),\n",
       "  (('he', 'hath'), 8),\n",
       "  (('come', 'to'), 8),\n",
       "  (('thee', 'and'), 8),\n",
       "  (('will', 'surely'), 8),\n",
       "  (('in', 'beauty'), 8),\n",
       "  (('without', 'a'), 8),\n",
       "  (('in', 'my'), 8),\n",
       "  (('beholding', 'him'), 8),\n",
       "  (('it', 'seems'), 8),\n",
       "  (('of', 'yudhishthira'), 8),\n",
       "  (('and', 'she'), 8),\n",
       "  (('with', 'every'), 8),\n",
       "  (('himself', 'of'), 8),\n",
       "  (('would', 'be'), 8),\n",
       "  (('there', 'that'), 8),\n",
       "  (('of', 'faultless'), 8),\n",
       "  (('if', 'it'), 8),\n",
       "  (('those', 'bulls'), 8),\n",
       "  (('else', 'save'), 8),\n",
       "  (('ten', 'thousand'), 8),\n",
       "  (('and', 'desirous'), 8),\n",
       "  (('there', 'in'), 8),\n",
       "  (('seemed', 'to'), 8),\n",
       "  (('by', 'him'), 8),\n",
       "  (('have', 'I'), 8),\n",
       "  (('of', 'various'), 8),\n",
       "  (('they', 'had'), 8),\n",
       "  (('up', 'his'), 8),\n",
       "  (('the', 'encounter'), 8),\n",
       "  (('encounter', 'that'), 8),\n",
       "  (('that', 'took'), 8),\n",
       "  (('took', 'place'), 8),\n",
       "  (('wealth', 'of'), 8),\n",
       "  (('of', 'panchala'), 8),\n",
       "  (('and', 'cars'), 8),\n",
       "  (('the', 'fierce'), 8),\n",
       "  (('thou', 'dost'), 8),\n",
       "  ((\"_suta's_\", 'son'), 8),\n",
       "  (('the', 'wicked'), 8),\n",
       "  (('a', '_suta_'), 8),\n",
       "  (('hands', 'of'), 8),\n",
       "  (('o', '_sairindhri_'), 8),\n",
       "  (('an', 'infuriate'), 8),\n",
       "  (('today', 'the'), 8),\n",
       "  (('him', 'that'), 8),\n",
       "  (('the', 'firmament'), 8),\n",
       "  (('and', 'afflicted'), 8),\n",
       "  (('having', 'been'), 8),\n",
       "  (('then', 'o'), 8),\n",
       "  (('can', 'be'), 8),\n",
       "  (('when', 'I'), 8),\n",
       "  (('have', 'heard'), 8),\n",
       "  (('as', 'it'), 8),\n",
       "  (('wicked', 'soul'), 8),\n",
       "  (('a', 'loud'), 8),\n",
       "  (('the', 'dancing-hall'), 8),\n",
       "  (('thee', 'in'), 8),\n",
       "  (('the', 'kichakas'), 8),\n",
       "  (('son.', 'and'), 8),\n",
       "  (('prince', 'of'), 8),\n",
       "  (('good', 'luck'), 8),\n",
       "  (('without', 'loss'), 8),\n",
       "  (('and', 'capable'), 8),\n",
       "  (('o', 'prince'), 8),\n",
       "  (('observant', 'of'), 8),\n",
       "  (('their', 'own'), 8),\n",
       "  (('yudhishthira', 'resides'), 8),\n",
       "  (('the', 'clouds'), 8),\n",
       "  (('there', 'where'), 8),\n",
       "  (('on', 'this'), 8),\n",
       "  (('the', 'kine.'), 8),\n",
       "  (('arrowy', 'shower'), 8),\n",
       "  (('shafts', 'and'), 8),\n",
       "  (('battle', 'and'), 8),\n",
       "  (('army', 'of'), 8),\n",
       "  (('with', 'that'), 8),\n",
       "  (('he', 'said'), 8),\n",
       "  (('away', 'the'), 8),\n",
       "  (('vanquished', 'the'), 8),\n",
       "  (('arjuna', 'and'), 8),\n",
       "  (('partha', 'the'), 8),\n",
       "  (('car.', 'and'), 8),\n",
       "  (('bow', 'of'), 8),\n",
       "  (('the', 'breast'), 8),\n",
       "  (('the', 'four'), 8),\n",
       "  (('of', 'celestial'), 8),\n",
       "  (('stationed', 'on'), 8),\n",
       "  (('the', 'bow-string'), 8),\n",
       "  (('with', 'arrows'), 8),\n",
       "  (('the', 'spectators'), 8),\n",
       "  (('device', 'of'), 8),\n",
       "  (('came', 'there'), 8),\n",
       "  (('the', 'foundation'), 8),\n",
       "  (('this', 'work'), 8),\n",
       "  (('of', 'project'), 8),\n",
       "  (('period', 'of'), 7),\n",
       "  (('unto', 'them'), 7),\n",
       "  (('brothers', 'and'), 7),\n",
       "  (('arjuna', 'the'), 7),\n",
       "  (('we', 'shall'), 7),\n",
       "  (('king', 'is'), 7),\n",
       "  (('that', 'it'), 7),\n",
       "  (('will', 'fight'), 7),\n",
       "  (('any', 'of'), 7),\n",
       "  (('be', 'performed'), 7),\n",
       "  (('in', 'fight'), 7),\n",
       "  (('arjuna', 'who'), 7),\n",
       "  (('the', 'ocean'), 7),\n",
       "  (('the', 'wife'), 7),\n",
       "  (('by', 'arjuna'), 7),\n",
       "  (('for', 'five'), 7),\n",
       "  (('the', 'neuter'), 7),\n",
       "  (('king', 'I'), 7),\n",
       "  (('the', 'women'), 7),\n",
       "  (('arjuna', 'that'), 7),\n",
       "  (('of', 'every'), 7),\n",
       "  (('virata', 'that'), 7),\n",
       "  (('let', 'thy'), 7),\n",
       "  (('I', 'can'), 7),\n",
       "  (('kind', 'of'), 7),\n",
       "  (('of', 'drupada'), 7),\n",
       "  (('let', 'all'), 7),\n",
       "  (('to', 'you'), 7),\n",
       "  (('is', 'alone'), 7),\n",
       "  (('alone', 'worthy'), 7),\n",
       "  (('dwelling', 'in'), 7),\n",
       "  (('of', 'which'), 7),\n",
       "  (('as', 'long'), 7),\n",
       "  (('of', 'life'), 7),\n",
       "  (('the', 'wise'), 7),\n",
       "  (('for', 'those'), 7),\n",
       "  (('of', 'what'), 7),\n",
       "  (('to', 'them'), 7),\n",
       "  (('is', 'none'), 7),\n",
       "  (('over', 'the'), 7),\n",
       "  (('and', 'looking'), 7),\n",
       "  (('cars', 'of'), 7),\n",
       "  (('at', 'a'), 7),\n",
       "  (('the', 'night'), 7),\n",
       "  (('a', 'herd'), 7),\n",
       "  (('so', 'that'), 7),\n",
       "  ((\"pandu's\", 'son'), 7),\n",
       "  (('the', 'just'), 7),\n",
       "  (('would', 'not'), 7),\n",
       "  (('up', 'a'), 7),\n",
       "  (('hundred', 'and'), 7),\n",
       "  (('city', 'with'), 7),\n",
       "  (('attired', 'in'), 7),\n",
       "  (('and', 'began'), 7),\n",
       "  (('thou', 'shinest'), 7),\n",
       "  (('as', 'that'), 7),\n",
       "  (('art', 'the'), 7),\n",
       "  (('and', 'thou'), 7),\n",
       "  (('the', 'three'), 7),\n",
       "  (('of', 'wealth'), 7),\n",
       "  (('who', 'have'), 7),\n",
       "  (('with', 'thy'), 7),\n",
       "  (('come', 'hither'), 7),\n",
       "  (('is', 'thy'), 7),\n",
       "  (('am', 'a'), 7),\n",
       "  (('to', 'thee.'), 7),\n",
       "  (('him', 'as'), 7),\n",
       "  (('and', 'without'), 7),\n",
       "  (('my', 'mind'), 7),\n",
       "  (('not', 'however'), 7),\n",
       "  (('virata.', 'and'), 7),\n",
       "  (('into', 'a'), 7),\n",
       "  (('by', 'her'), 7),\n",
       "  (('me', 'o'), 7),\n",
       "  (('and', 'my'), 7),\n",
       "  (('damsel', 'of'), 7),\n",
       "  (('other', 'person'), 7),\n",
       "  (('\"hearing', 'these'), 7),\n",
       "  (('said', \"'thou\"), 7),\n",
       "  (('me.', 'I'), 7),\n",
       "  (('by', 'which'), 7),\n",
       "  (('in', 'disguise'), 7),\n",
       "  (('as', 'to'), 7),\n",
       "  (('have', 'come'), 7),\n",
       "  (('clouds.', 'and'), 7),\n",
       "  (('of', 'horses'), 7),\n",
       "  (('chief', 'of'), 7),\n",
       "  (('that', 'tiger'), 7),\n",
       "  (('once', 'more'), 7),\n",
       "  (('men', 'the'), 7),\n",
       "  (('of', 'dhritarashtra'), 7),\n",
       "  (('and', 'after'), 7),\n",
       "  (('from', 'all'), 7),\n",
       "  (('and', 'great'), 7),\n",
       "  (('elephants', 'of'), 7),\n",
       "  (('him', 'on'), 7),\n",
       "  (('between', 'those'), 7),\n",
       "  (('battle', 'with'), 7),\n",
       "  (('texts', 'read'), 7),\n",
       "  (('with', 'her'), 7),\n",
       "  (('no', 'other'), 7),\n",
       "  (('every', 'kind'), 7),\n",
       "  (('of', 'beautiful'), 7),\n",
       "  (('hast', 'thou'), 7),\n",
       "  (('the', 'beautiful'), 7),\n",
       "  (('graceful', 'hips'), 7),\n",
       "  (('in', 'beautiful'), 7),\n",
       "  (('are', 'now'), 7),\n",
       "  (('dost', 'not'), 7),\n",
       "  (('his', 'senses'), 7),\n",
       "  (('who', 'am'), 7),\n",
       "  (('it', 'in'), 7),\n",
       "  (('by', 'my'), 7),\n",
       "  (('will', 'slay'), 7),\n",
       "  (('thee', 'that'), 7),\n",
       "  (('the', \"_suta's_\"), 7),\n",
       "  (('the', '_suta_'), 7),\n",
       "  (('the', 'court'), 7),\n",
       "  (('stood', 'on'), 7),\n",
       "  (('infuriate', 'elephant'), 7),\n",
       "  (('also', 'is'), 7),\n",
       "  (('they', 'all'), 7),\n",
       "  (('and', 'said'), 7),\n",
       "  (('on', 'which'), 7),\n",
       "  (('sound', 'of'), 7),\n",
       "  (('if', 'he'), 7),\n",
       "  (('the', '_vedas_'), 7),\n",
       "  (('mighty', 'king'), 7),\n",
       "  (('celestials', 'and'), 7),\n",
       "  (('indra', 'himself'), 7),\n",
       "  (('of', 'old'), 7),\n",
       "  (('mighty', 'son'), 7),\n",
       "  (('not', 'the'), 7),\n",
       "  (('also', 'of'), 7),\n",
       "  (('their', 'respective'), 7),\n",
       "  (('spake', 'unto'), 7),\n",
       "  ...])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(filter(lambda x: 1 < int(x[1]), ngrams_up_to_20[0].most_common()))\n",
    "len(l), l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea72ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_filter(ngrams):\n",
    "    return filter(remove_periods, list(filter(lambda x: 1 < int(x[1]), ngrams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d58c9890",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_to_learn = ngrams_up_to_20[0]\n",
    "X_train_example = [[word_to_index[sent[0][0]]] for sent in my_filter(bigrams_to_learn.most_common())\n",
    "                  if sent[0][0] in word_to_index and sent[0][1] in word_to_index]\n",
    "y_train_example = [[word_to_index[sent[0][1]]] for sent in my_filter(bigrams_to_learn.most_common())\n",
    "                  if sent[0][0] in word_to_index and sent[0][1] in word_to_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1ee8779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1], [5], [2], [20], [7], [10], [0], [0], [19], [6]],\n",
       " [[0], [0], [0], [1], [0], [0], [20], [18], [0], [0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_example[0:10], y_train_example[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f937868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7124, 7124)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_example), len(y_train_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89ad6bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'son', 'of'),\n",
       " ('the', 'sons', 'of'),\n",
       " ('the', 'king', 'of'),\n",
       " ('king', 'of', 'the'),\n",
       " ('o', 'thou', 'of'),\n",
       " ('son', 'of', 'pandu'),\n",
       " ('section', 'vaisampayana', 'said'),\n",
       " ('by', 'means', 'of'),\n",
       " ('of', 'the', 'matsyas'),\n",
       " ('sons', 'of', 'pandu'),\n",
       " ('son', 'of', 'kuntI'),\n",
       " ('that', 'foremost', 'of'),\n",
       " ('son', 'of', 'pritha'),\n",
       " ('the', 'midst', 'of'),\n",
       " ('the', 'field', 'of'),\n",
       " ('of', 'the', 'kuru'),\n",
       " ('in', 'the', 'midst'),\n",
       " ('on', 'the', 'field'),\n",
       " ('endued', 'with', 'great'),\n",
       " ('field', 'of', 'battle'),\n",
       " ('the', 'kuru', 'race'),\n",
       " ('of', 'the', 'kurus'),\n",
       " ('son', 'of', 'virata'),\n",
       " ('the', 'city', 'of'),\n",
       " ('these', 'words', 'of'),\n",
       " ('the', 'foremost', 'of'),\n",
       " ('foremost', 'of', 'all'),\n",
       " ('bull', 'among', 'men'),\n",
       " ('I', 'do', 'not'),\n",
       " ('the', 'project', 'gutenberg'),\n",
       " ('that', 'best', 'of'),\n",
       " ('o', 'son', 'of'),\n",
       " ('that', 'slayer', 'of'),\n",
       " ('project', 'gutenberg™', 'electronic'),\n",
       " ('of', 'the', 'king'),\n",
       " ('like', 'unto', 'a'),\n",
       " ('on', 'the', 'ground'),\n",
       " ('and', 'the', 'son'),\n",
       " ('hearing', 'these', 'words'),\n",
       " ('o', 'lord', 'of'),\n",
       " ('dhananjaya', 'the', 'son'),\n",
       " ('bull', 'of', 'the'),\n",
       " ('of', 'the', 'bharata'),\n",
       " ('the', 'bharata', 'race'),\n",
       " ('the', 'twang', 'of'),\n",
       " ('and', 'then', 'the'),\n",
       " ('the', 'lord', 'of'),\n",
       " ('be', 'able', 'to'),\n",
       " ('vaisampayana', 'continued', '\"thus'),\n",
       " ('it', 'is', 'for'),\n",
       " ('possessed', 'of', 'great'),\n",
       " ('wielder', 'of', 'the'),\n",
       " ('in', 'the', 'city'),\n",
       " ('lord', 'of', 'the'),\n",
       " ('and', 'o', 'king'),\n",
       " ('vaisampayana', 'continued', '\"having'),\n",
       " ('that', 'bull', 'among'),\n",
       " ('in', 'consequence', 'of'),\n",
       " ('is', 'for', 'this'),\n",
       " ('endued', 'with', 'the'),\n",
       " ('and', 'beholding', 'that'),\n",
       " ('and', 'it', 'was'),\n",
       " ('down', 'on', 'the'),\n",
       " ('and', 'kripa', 'and'),\n",
       " ('the', 'project', 'gutenberg™'),\n",
       " ('project', 'gutenberg', 'literary'),\n",
       " ('gutenberg', 'literary', 'archive'),\n",
       " ('lord', 'of', 'men'),\n",
       " ('the', 'wielder', 'of'),\n",
       " ('it', 'behoveth', 'thee'),\n",
       " ('for', 'this', 'that'),\n",
       " ('vaisampayana', 'continued', '\"then'),\n",
       " ('and', 'beholding', 'the'),\n",
       " ('and', 'all', 'the'),\n",
       " ('incapable', 'of', 'being'),\n",
       " ('slayer', 'of', 'foes'),\n",
       " ('with', 'great', 'energy'),\n",
       " ('on', 'his', 'car'),\n",
       " ('the', 'blare', 'of'),\n",
       " ('the', 'terms', 'of'),\n",
       " ('son', 'of', 'the'),\n",
       " ('the', 'king', 'and'),\n",
       " ('even', 'as', 'the'),\n",
       " ('the', 'best', 'of'),\n",
       " ('one', 'of', 'the'),\n",
       " ('to', 'the', 'city'),\n",
       " ('that', 'son', 'of'),\n",
       " ('o', 'thou', 'that'),\n",
       " ('chastiser', 'of', 'foes'),\n",
       " ('vaisampayana', 'said', '\"then'),\n",
       " ('and', 'possessed', 'of'),\n",
       " ('sons', 'of', 'pritha'),\n",
       " ('acquainted', 'with', 'the'),\n",
       " ('son', 'of', 'a'),\n",
       " ('and', 'at', 'this'),\n",
       " ('midst', 'of', 'the'),\n",
       " ('and', 'furnished', 'with'),\n",
       " ('whose', 'is', 'this'),\n",
       " ('literary', 'archive', 'foundation'),\n",
       " ('do', 'thou', 'therefore'),\n",
       " ('o', 'foremost', 'of'),\n",
       " ('of', 'mighty', 'arms'),\n",
       " ('foremost', 'of', 'men'),\n",
       " ('o', 'bull', 'of'),\n",
       " ('the', 'presence', 'of'),\n",
       " ('like', 'unto', 'the'),\n",
       " ('and', 'when', 'the'),\n",
       " ('tiger', 'among', 'men'),\n",
       " ('each', 'other', 'with'),\n",
       " ('where', 'king', 'yudhishthira'),\n",
       " ('slayer', 'of', 'hostile'),\n",
       " ('coat', 'of', 'mail'),\n",
       " ('with', 'gold', 'and'),\n",
       " ('in', 'order', 'of'),\n",
       " ('arrows', 'shot', 'from'),\n",
       " ('arrows', 'furnished', 'with'),\n",
       " ('gutenberg™', 'electronic', 'works'),\n",
       " ('terms', 'of', 'this'),\n",
       " ('of', 'the', 'project'),\n",
       " ('city', 'of', 'virata'),\n",
       " ('the', 'name', 'of'),\n",
       " ('the', 'abode', 'of'),\n",
       " ('the', 'inner', 'apartments'),\n",
       " ('best', 'of', 'men'),\n",
       " ('vaisampayana', 'said', '\"having'),\n",
       " ('in', 'a', 'royal'),\n",
       " ('in', 'the', 'presence'),\n",
       " ('presence', 'of', 'the'),\n",
       " ('continued', '\"thus', 'addressed'),\n",
       " ('\"thus', 'addressed', 'by'),\n",
       " ('those', 'mighty', 'warriors'),\n",
       " ('and', 'the', 'king'),\n",
       " ('various', 'kinds', 'of'),\n",
       " ('like', 'the', 'sun'),\n",
       " ('of', 'the', 'thunderbolt'),\n",
       " ('to', 'fight', 'with'),\n",
       " ('of', 'the', 'celestials'),\n",
       " ('and', 'endued', 'with'),\n",
       " ('do', 'thou', 'o'),\n",
       " ('why', 'dost', 'thou'),\n",
       " ('vaisampayana', 'continued', '\"hearing'),\n",
       " ('of', 'hostile', 'heroes'),\n",
       " ('like', 'that', 'of'),\n",
       " ('that', 'hero', 'of'),\n",
       " ('that', 'I', 'have'),\n",
       " ('bhishma', 'the', 'son'),\n",
       " ('son', 'of', 'santanu'),\n",
       " ('of', 'the', 'trigartas'),\n",
       " ('and', 'drona', 'and'),\n",
       " ('the', 'kurus', 'and'),\n",
       " ('of', 'the', 'foe'),\n",
       " ('fight', 'with', 'the'),\n",
       " ('shot', 'from', 'the'),\n",
       " ('and', 'o', 'bharata'),\n",
       " ('the', 'thirteenth', 'year'),\n",
       " ('may', 'not', 'be'),\n",
       " ('the', 'daughter', 'of'),\n",
       " ('king', 'yudhishthira', 'the'),\n",
       " ('among', 'the', 'kurus'),\n",
       " ('and', 'it', 'is'),\n",
       " ('of', 'the', 'sons'),\n",
       " ('addressed', 'him', 'saying'),\n",
       " ('the', 'head', 'of'),\n",
       " ('o', 'beauteous', 'lady'),\n",
       " ('the', 'place', 'where'),\n",
       " ('of', 'sweet', 'smiles'),\n",
       " ('and', 'desirous', 'of'),\n",
       " ('yudhishthira', 'the', 'son'),\n",
       " ('in', 'the', 'forest'),\n",
       " ('that', 'took', 'place'),\n",
       " ('the', 'princess', 'of'),\n",
       " ('princess', 'of', 'panchala'),\n",
       " ('of', 'a', '_suta_'),\n",
       " ('afflicted', 'by', 'the'),\n",
       " ('the', 'gods', 'and'),\n",
       " ('in', 'the', 'very'),\n",
       " ('my', 'heart', 'is'),\n",
       " ('and', 'karna', 'and'),\n",
       " ('of', 'wicked', 'soul'),\n",
       " ('without', 'loss', 'of'),\n",
       " ('and', 'capable', 'of'),\n",
       " ('foremost', 'of', 'car-warriors'),\n",
       " ('on', 'the', 'car'),\n",
       " ('furnished', 'with', 'golden'),\n",
       " ('twang', 'of', 'the'),\n",
       " ('of', 'the', '_gandiva_'),\n",
       " ('the', 'car', 'of'),\n",
       " ('in', 'the', 'united'),\n",
       " ('the', 'united', 'states'),\n",
       " ('set', 'forth', 'in'),\n",
       " ('of', 'this', 'agreement'),\n",
       " ('of', 'project', 'gutenberg™'),\n",
       " ('as', 'thou', 'art'),\n",
       " ('me', 'in', 'the'),\n",
       " ('as', 'the', 'sun'),\n",
       " ('is', 'the', 'foremost'),\n",
       " ('of', 'the', 'earth'),\n",
       " ('of', 'the', 'neuter'),\n",
       " ('living', 'in', 'the'),\n",
       " ('as', 'they', 'are'),\n",
       " ('do', 'not', 'know'),\n",
       " ('as', 'long', 'as'),\n",
       " ('he', 'that', 'is'),\n",
       " ('to', 'the', 'king'),\n",
       " ('in', 'respect', 'of'),\n",
       " ('behoveth', 'thee', 'to'),\n",
       " ('of', 'the', 'pandavas'),\n",
       " ('yudhishthira', 'the', 'just'),\n",
       " ('was', 'like', 'unto'),\n",
       " ('the', 'roar', 'of'),\n",
       " ('and', 'began', 'to'),\n",
       " ('thou', 'art', 'the'),\n",
       " ('it', 'is', 'that'),\n",
       " ('great', 'energy', 'and'),\n",
       " ('o', 'bull', 'among'),\n",
       " ('\"hearing', 'these', 'words'),\n",
       " ('and', 'decked', 'with'),\n",
       " ('city', 'of', 'the'),\n",
       " ('that', 'tiger', 'among'),\n",
       " ('there', 'is', 'no'),\n",
       " ('thou', 'of', 'graceful'),\n",
       " ('furnished', 'with', 'a'),\n",
       " ('and', 'as', 'the'),\n",
       " ('the', 'sound', 'of'),\n",
       " ('mighty', 'son', 'of'),\n",
       " ('with', 'mighty', 'energy'),\n",
       " ('out', 'of', 'the'),\n",
       " ('loss', 'of', 'time'),\n",
       " ('will', 'not', 'be'),\n",
       " ('conversant', 'with', 'the'),\n",
       " ('and', 'elephants', 'and'),\n",
       " ('coats', 'of', 'mail'),\n",
       " ('arrayed', 'in', 'order'),\n",
       " ('of', 'his', 'car'),\n",
       " ('bhishma', 'and', 'drona'),\n",
       " ('the', 'reins', 'of'),\n",
       " ('furnished', 'with', 'vulturine'),\n",
       " ('that', 'mighty', 'car-warrior'),\n",
       " ('inflamed', 'with', 'wrath'),\n",
       " ('the', 'device', 'of'),\n",
       " ('the', 'matsya', 'king'),\n",
       " ('to', 'the', 'project'),\n",
       " ('the', 'god', 'of'),\n",
       " ('in', 'the', 'guise'),\n",
       " ('of', 'men', 'and'),\n",
       " ('continued', '\"having', 'said'),\n",
       " ('to', 'thee', 'o'),\n",
       " ('in', 'order', 'to'),\n",
       " ('lord', 'of', 'earth'),\n",
       " ('daughter', 'of', 'drupada'),\n",
       " ('by', 'the', 'king'),\n",
       " ('in', 'such', 'a'),\n",
       " ('according', 'to', 'the'),\n",
       " ('even', 'this', 'is'),\n",
       " ('go', 'to', 'the'),\n",
       " ('of', 'pandu', 'the'),\n",
       " ('is', 'alone', 'worthy'),\n",
       " ('there', 'is', 'none'),\n",
       " ('that', 'of', 'the'),\n",
       " ('a', 'herd', 'of'),\n",
       " ('which', 'he', 'had'),\n",
       " ('roar', 'of', 'the'),\n",
       " ('from', 'the', 'field'),\n",
       " ('decked', 'with', 'a'),\n",
       " ('the', 'bodies', 'of'),\n",
       " ('this', 'that', 'thou'),\n",
       " ('the', 'entire', 'earth'),\n",
       " ('possessed', 'of', 'the'),\n",
       " ('king', 'of', 'kings'),\n",
       " ('at', 'the', 'head'),\n",
       " ('is', 'there', 'that'),\n",
       " ('thou', 'of', 'sweet'),\n",
       " ('even', 'as', 'a'),\n",
       " ('that', 'lord', 'of'),\n",
       " ('chief', 'of', 'the'),\n",
       " ('the', 'very', 'sight'),\n",
       " ('very', 'sight', 'of'),\n",
       " ('of', 'various', 'kinds'),\n",
       " ('in', 'the', 'inner'),\n",
       " ('both', 'of', 'them'),\n",
       " ('took', 'place', 'between'),\n",
       " ('other', 'with', 'their'),\n",
       " ('were', 'filled', 'with'),\n",
       " ('and', 'in', 'the'),\n",
       " ('every', 'kind', 'of'),\n",
       " ('elephants', 'and', 'horses'),\n",
       " ('and', 'horses', 'and'),\n",
       " ('thou', 'dost', 'not'),\n",
       " ('o', 'timid', 'one'),\n",
       " ('that', 'I', 'am'),\n",
       " ('the', 'hands', 'of'),\n",
       " ('the', \"_suta's_\", 'son'),\n",
       " ('not', 'be', 'able'),\n",
       " ('having', 'said', 'this'),\n",
       " ('that', 'had', 'been'),\n",
       " ('an', 'infuriate', 'elephant'),\n",
       " ('words', 'of', 'the'),\n",
       " ('like', 'a', 'lion'),\n",
       " ('of', 'immeasurable', 'soul'),\n",
       " ('of', 'all', 'the'),\n",
       " ('of', 'the', 'bharatas'),\n",
       " ('as', 'I', 'am'),\n",
       " ('o', 'chastiser', 'of'),\n",
       " ('the', 'might', 'of'),\n",
       " ('of', 'graceful', 'hips'),\n",
       " ('the', 'duties', 'of'),\n",
       " ('to', 'the', 'best'),\n",
       " ('deprived', 'of', 'his'),\n",
       " ('some', 'texts', 'read'),\n",
       " ('endued', 'with', 'mighty'),\n",
       " ('the', 'bristles', 'of'),\n",
       " ('and', 'the', 'twang'),\n",
       " ('the', 'words', 'of'),\n",
       " ('king', 'yudhishthira', 'resides'),\n",
       " ('decked', 'with', 'gold'),\n",
       " ('those', 'foremost', 'of'),\n",
       " ('and', 'o', 'bull'),\n",
       " ('cut', 'off', 'by'),\n",
       " ('army', 'of', 'the'),\n",
       " ('in', 'all', 'directions'),\n",
       " ('section', '\"uttara', 'said'),\n",
       " ('the', 'use', 'of'),\n",
       " ('continued', '\"hearing', 'these'),\n",
       " ('by', 'the', 'kurus'),\n",
       " ('the', 'kuru', 'army'),\n",
       " ('with', 'the', 'speed'),\n",
       " ('the', 'speed', 'of'),\n",
       " ('horses', 'and', 'elephants'),\n",
       " ('array', 'of', 'cars'),\n",
       " ('of', 'all', 'wielders'),\n",
       " ('all', 'wielders', 'of'),\n",
       " ('with', 'vulturine', 'wings'),\n",
       " ('with', 'golden', 'wings'),\n",
       " ('from', 'the', '_gandiva_'),\n",
       " ('by', 'the', 'arrows'),\n",
       " ('arrows', 'shot', 'by'),\n",
       " ('the', 'arrows', 'of'),\n",
       " ('bow', 'in', 'hand'),\n",
       " ('the', 'full', 'project'),\n",
       " ('full', 'project', 'gutenberg™'),\n",
       " ('project', 'gutenberg™', 'license'),\n",
       " ('gutenberg™', 'electronic', 'work'),\n",
       " ('king', 'and', 'the'),\n",
       " ('the', 'period', 'of'),\n",
       " ('in', 'this', 'way'),\n",
       " ('said', \"'o\", 'thou'),\n",
       " (\"'o\", 'thou', 'of'),\n",
       " ('thou', 'of', 'mighty'),\n",
       " ('before', 'the', 'king'),\n",
       " ('bulls', 'among', 'men'),\n",
       " ('I', 'shall', 'say'),\n",
       " ('and', 'I', 'shall'),\n",
       " ('will', 'fight', 'with'),\n",
       " ('what', 'office', 'will'),\n",
       " ('will', 'be', 'performed'),\n",
       " ('the', 'forest', 'of'),\n",
       " ('the', 'guise', 'of'),\n",
       " ('guise', 'of', 'a'),\n",
       " ('of', 'all', 'weapons'),\n",
       " ('celestial', 'weapons', 'and'),\n",
       " ('of', 'the', 'third'),\n",
       " ('of', 'the', 'inner'),\n",
       " ('o', 'king', 'I'),\n",
       " ('foremost', 'of', 'kings'),\n",
       " ('in', 'the', 'palace'),\n",
       " ('the', 'dominions', 'of'),\n",
       " ('o', 'king', 'of'),\n",
       " ('as', 'well', 'as'),\n",
       " ('to', 'the', 'abode'),\n",
       " ('for', 'the', 'protection'),\n",
       " ('the', 'protection', 'of'),\n",
       " ('of', 'pandu', 'in'),\n",
       " ('in', 'this', 'world'),\n",
       " ('nor', 'should', 'one'),\n",
       " ('alone', 'worthy', 'of'),\n",
       " ('dwelling', 'in', 'a'),\n",
       " ('and', 'with', 'the'),\n",
       " ('of', 'foes', 'the'),\n",
       " ('when', 'the', 'king'),\n",
       " ('in', 'expectation', 'of'),\n",
       " ('the', 'country', 'of'),\n",
       " ('country', 'of', 'the'),\n",
       " ('leader', 'of', 'a'),\n",
       " ('of', 'a', 'herd'),\n",
       " ('of', 'the', 'city'),\n",
       " ('bull', 'among', 'the'),\n",
       " ('the', 'string', 'of'),\n",
       " ('with', 'which', 'he'),\n",
       " ('sight', 'of', 'the'),\n",
       " ('the', 'vow', 'of'),\n",
       " ('thou', 'of', 'fair'),\n",
       " ('as', 'that', 'of'),\n",
       " ('a', 'couple', 'of'),\n",
       " ('been', 'deprived', 'of'),\n",
       " ('in', 'these', 'words'),\n",
       " ('in', 'the', 'country'),\n",
       " ('and', 'like', 'unto'),\n",
       " ('looking', 'like', 'the'),\n",
       " ('o', 'sinless', 'one'),\n",
       " ('explained', 'by', 'nilakantha'),\n",
       " ('by', 'the', 'name'),\n",
       " ('of', 'this', 'realm'),\n",
       " ('the', 'matsyas', 'and'),\n",
       " ('like', 'those', 'of'),\n",
       " ('those', 'of', 'a'),\n",
       " ('of', 'the', 'gandharvas'),\n",
       " ('said', \"'I\", 'will'),\n",
       " ('I', 'tell', 'thee'),\n",
       " ('of', 'great', 'energy'),\n",
       " ('bulls', 'of', 'the'),\n",
       " ('grinder', 'of', 'foes'),\n",
       " ('\"arjuna', 'said', \"'I\"),\n",
       " ('vaisampayana', 'said', '\"after'),\n",
       " ('son', 'of', 'dhritarashtra'),\n",
       " ('encounter', 'that', 'took'),\n",
       " ('the', 'people', 'of'),\n",
       " ('as', 'also', 'the'),\n",
       " ('who', 'is', 'there'),\n",
       " ('of', 'an', 'elephant'),\n",
       " ('good', 'betide', 'thee'),\n",
       " ('the', 'wicked', 'kichaka'),\n",
       " ('the', 'destruction', 'of'),\n",
       " ('to', 'the', 'other'),\n",
       " ('tresses', 'ending', 'in'),\n",
       " ('vaisampayana', 'continued', '\"and'),\n",
       " ('by', 'the', 'hair'),\n",
       " ('the', 'very', 'presence'),\n",
       " ('very', 'presence', 'of'),\n",
       " ('and', 'that', 'slayer'),\n",
       " ('a', '_suta_', 'hath'),\n",
       " ('_suta_', 'hath', 'kicked'),\n",
       " ('hath', 'kicked', 'today'),\n",
       " ('kicked', 'today', 'the'),\n",
       " ('today', 'the', 'proud'),\n",
       " ('the', 'proud', 'and'),\n",
       " ('proud', 'and', 'beloved'),\n",
       " ('and', 'beloved', 'wife'),\n",
       " ('beloved', 'wife', 'of'),\n",
       " ('wife', 'of', 'those'),\n",
       " ('that', 'of', 'a'),\n",
       " ('these', 'words', 'the'),\n",
       " ('vaisampayana', 'said', '\"thus'),\n",
       " ('in', 'the', 'woods'),\n",
       " ('afflicted', 'with', 'such'),\n",
       " ('I', 'have', 'been'),\n",
       " ('do', 'thou', 'now'),\n",
       " ('at', 'sight', 'of'),\n",
       " ('of', 'terrible', 'prowess'),\n",
       " ('the', 'celestial', 'weapons'),\n",
       " ('foremost', 'of', 'the'),\n",
       " ('devoted', 'to', 'the'),\n",
       " ('the', 'return', 'of'),\n",
       " ('and', 'that', 'mighty'),\n",
       " ('rushed', 'towards', 'the'),\n",
       " ('duties', 'of', 'the'),\n",
       " ('of', 'the', 'matsya'),\n",
       " ('o', 'best', 'of'),\n",
       " ('the', 'mighty-armed', 'bhima'),\n",
       " ('and', 'the', 'mighty'),\n",
       " ('with', 'each', 'other'),\n",
       " ('and', 'beholding', 'him'),\n",
       " ('and', 'seeing', 'that'),\n",
       " ('of', 'the', '_suta_'),\n",
       " ('then', 'o', 'king'),\n",
       " ('slain', 'by', 'the'),\n",
       " ('good', 'luck', 'it'),\n",
       " ('luck', 'it', 'is'),\n",
       " ('have', 'not', 'been'),\n",
       " ('of', 'pandu', 'who'),\n",
       " ('a', 'knowledge', 'of'),\n",
       " ('is', 'capable', 'of'),\n",
       " ('will', 'always', 'be'),\n",
       " ('there', 'where', 'king'),\n",
       " ('yudhishthira', 'resides', 'the'),\n",
       " ('hostile', 'heroes', 'the'),\n",
       " ('those', 'bulls', 'among'),\n",
       " ('himself', 'of', 'the'),\n",
       " ('order', 'of', 'battle'),\n",
       " ('gods', 'and', 'the'),\n",
       " ('said', 'unto', 'the'),\n",
       " ('means', 'of', 'his'),\n",
       " ('how', 'couldst', 'thou'),\n",
       " ('and', 'bhishma', 'and'),\n",
       " ('the', 'arrows', 'shot'),\n",
       " ('use', 'of', 'the'),\n",
       " ('as', 'they', 'were'),\n",
       " ('speed', 'of', 'the'),\n",
       " ('the', 'time', 'of'),\n",
       " ('is', 'like', 'unto'),\n",
       " ('cut', 'off', 'the'),\n",
       " ('and', \"drona's\", 'son'),\n",
       " ('unable', 'to', 'bear'),\n",
       " ('adorned', 'with', 'gold'),\n",
       " ('said', 'unto', 'him'),\n",
       " ('cased', 'in', 'a'),\n",
       " ('the', 'whole', 'of'),\n",
       " ('in', 'battle', 'the'),\n",
       " ('the', 'breast', 'of'),\n",
       " ('the', 'energy', 'of'),\n",
       " ('lords', 'of', 'earth'),\n",
       " ('the', 'spot', 'where'),\n",
       " ('shot', 'by', 'partha'),\n",
       " ('cut', 'off', 'his'),\n",
       " ('means', 'of', 'a'),\n",
       " ('beareth', 'the', 'device'),\n",
       " ('device', 'of', 'a'),\n",
       " ('with', 'a', 'cheerful'),\n",
       " ('kine', 'have', 'been'),\n",
       " ('a', 'large', 'army'),\n",
       " ('not', 'protected', 'by'),\n",
       " ('terms', 'of', 'the'),\n",
       " ('a', 'project', 'gutenberg™'),\n",
       " ('the', 'mahabharata', 'of'),\n",
       " ('mahabharata', 'of', 'krishna-dwaipayana'),\n",
       " ('of', 'krishna-dwaipayana', 'vyasa'),\n",
       " ('translated', 'into', 'english'),\n",
       " ('into', 'english', 'prose'),\n",
       " ('thou', 'therefore', 'o'),\n",
       " ('arjuna', 'the', 'son'),\n",
       " ('sons', 'of', 'the'),\n",
       " ('wilt', 'thou', 'o'),\n",
       " ('I', 'am', 'skilled'),\n",
       " ('am', 'skilled', 'in'),\n",
       " ('with', 'me', 'in'),\n",
       " ('I', 'shall', 'not'),\n",
       " ('office', 'will', 'be'),\n",
       " ('be', 'performed', 'by'),\n",
       " ('descendant', 'of', 'the'),\n",
       " ('foremost', 'of', 'warriors'),\n",
       " ('I', 'shall', 'o'),\n",
       " ('in', 'singing', 'and'),\n",
       " ('\"having', 'said', 'this'),\n",
       " ('possessed', 'of', 'a'),\n",
       " ('tell', 'me', 'all'),\n",
       " ('is', 'agreeable', 'to'),\n",
       " ('to', 'live', 'in'),\n",
       " ('and', 'o', 'monarch'),\n",
       " ('repair', 'to', 'the'),\n",
       " ('this', 'is', 'my'),\n",
       " ('all', 'of', 'them'),\n",
       " ('worthy', 'of', 'dwelling'),\n",
       " ('of', 'dwelling', 'in'),\n",
       " ('unto', 'the', 'king'),\n",
       " ('those', 'that', 'are'),\n",
       " ('if', 'an', 'individual'),\n",
       " ('repressers', 'of', 'foes'),\n",
       " ('what', 'is', 'agreeable'),\n",
       " ('do', 'what', 'is'),\n",
       " ('the', 'purpose', 'of'),\n",
       " ('the', 'correct', 'reading'),\n",
       " ('set', 'out', 'for'),\n",
       " ('the', 'cars', 'of'),\n",
       " ('cars', 'of', 'the'),\n",
       " ('with', 'great', 'strength'),\n",
       " ('great', 'strength', 'and'),\n",
       " ('herd', 'of', 'elephants'),\n",
       " ('the', 'vicinity', 'of'),\n",
       " ('entering', 'the', 'city'),\n",
       " ('will', 'without', 'doubt'),\n",
       " ('the', '_sami_', 'tree'),\n",
       " ('the', 'city', 'and'),\n",
       " ('of', 'that', 'bow'),\n",
       " ('and', 'the', 'heroic'),\n",
       " ('and', 'the', 'other'),\n",
       " ('parts', 'of', 'the'),\n",
       " ('he', 'began', 'to'),\n",
       " ('who', 'is', 'the'),\n",
       " ('thee', 'o', 'thou'),\n",
       " ('that', 'thou', 'art'),\n",
       " ('have', 'been', 'deprived'),\n",
       " ('the', 'ranks', 'of'),\n",
       " ('said', 'these', 'words'),\n",
       " ('these', 'words', 'unto'),\n",
       " ('with', 'strength', 'and'),\n",
       " ('him', 'to', 'be'),\n",
       " ('an', 'elephant', 'in'),\n",
       " ('him', 'saying', \"'o\"),\n",
       " ('I', 'am', 'a'),\n",
       " ('belonging', 'to', 'the'),\n",
       " ('known', 'by', 'the'),\n",
       " ('shall', 'not', 'be'),\n",
       " ('and', 'various', 'kinds'),\n",
       " ('of', 'a', 'lion'),\n",
       " ('it', 'seems', 'to'),\n",
       " ('to', 'me', 'that'),\n",
       " ('\"virata', 'said', \"'I\"),\n",
       " ('is', 'equal', 'to'),\n",
       " ('do', 'not', 'however'),\n",
       " ('and', 'beholding', 'her'),\n",
       " ('men', 'and', 'women'),\n",
       " ('or', 'art', 'thou'),\n",
       " ('that', 'the', 'king'),\n",
       " ('the', 'king', 'himself'),\n",
       " ('thou', 'of', 'faultless'),\n",
       " ('of', 'faultless', 'limbs'),\n",
       " ('any', 'other', 'person'),\n",
       " ('that', 'hath', 'been'),\n",
       " ('surrounded', 'by', 'the'),\n",
       " ('of', 'pandu', 'had'),\n",
       " ('a', 'hundred', 'thousand'),\n",
       " ('of', 'the', 'great'),\n",
       " ('of', 'great', 'strength'),\n",
       " ('bow', 'and', 'arrows'),\n",
       " ('be', 'of', 'the'),\n",
       " ('and', 'skilled', 'in'),\n",
       " ('vaisampayana', 'continued', '\"the'),\n",
       " ('those', 'descendants', 'of'),\n",
       " ('of', 'the', 'high-souled'),\n",
       " ('of', 'men', 'the'),\n",
       " ('were', 'endued', 'with'),\n",
       " ('and', 'bhima', 'then'),\n",
       " ('of', 'them', 'were'),\n",
       " ('and', 'both', 'were'),\n",
       " ('the', 'encounter', 'that'),\n",
       " ('him', 'on', 'the'),\n",
       " ('struck', 'each', 'other'),\n",
       " ('the', 'crash', 'of'),\n",
       " ('the', 'power', 'of'),\n",
       " ('in', 'that', 'encounter'),\n",
       " ('the', 'slayer', 'of'),\n",
       " ('the', 'splendour', 'of'),\n",
       " ('the', 'beauty', 'of'),\n",
       " ('thou', 'of', 'beautiful'),\n",
       " ('of', 'the', 'most'),\n",
       " ('union', 'with', 'thee'),\n",
       " ('the', 'desire', 'of'),\n",
       " ('and', 'adorned', 'with'),\n",
       " ('words', 'of', 'his'),\n",
       " ('addressed', 'by', 'the'),\n",
       " ('by', 'the', '_sairindhri_'),\n",
       " ('even', 'like', 'a'),\n",
       " ('even', 'like', 'an'),\n",
       " ('thou', 'of', 'tresses'),\n",
       " ('of', 'tresses', 'ending'),\n",
       " ('and', 'filled', 'with'),\n",
       " ('ending', 'in', 'beautiful'),\n",
       " ('in', 'beautiful', 'curls'),\n",
       " ('while', 'she', 'was'),\n",
       " ('of', 'the', 'wicked'),\n",
       " ('was', 'on', 'the'),\n",
       " ('alas', 'the', 'son'),\n",
       " ('is', 'like', 'that'),\n",
       " ('let', 'all', 'the'),\n",
       " ('and', 'they', 'all'),\n",
       " ('that', 'bull', 'of'),\n",
       " ('for', 'the', 'sake'),\n",
       " ('the', 'sake', 'of'),\n",
       " ('abode', 'of', 'yama'),\n",
       " ('proceeded', 'towards', 'the'),\n",
       " ('again', 'and', 'again'),\n",
       " ('who', 'else', 'save'),\n",
       " ('o', 'tiger', 'among'),\n",
       " ('on', 'his', 'own'),\n",
       " ('on', 'account', 'of'),\n",
       " ('now', 'living', 'in'),\n",
       " ('the', 'clatter', 'of'),\n",
       " ('like', 'an', 'elephant'),\n",
       " ('virata', 'the', 'king'),\n",
       " ('it', 'was', 'with'),\n",
       " ('is', 'what', 'I'),\n",
       " ('the', 'whole', 'earth'),\n",
       " ('on', 'the', 'might'),\n",
       " ('a', 'mighty', 'elephant'),\n",
       " ('I', 'have', 'not'),\n",
       " ('filled', 'with', 'wrath'),\n",
       " ('said', \"'do\", 'thou'),\n",
       " ('to', 'the', 'dancing-hall'),\n",
       " ('to', 'their', 'respective'),\n",
       " ('and', 'deprived', 'of'),\n",
       " ('and', 'who', 'was'),\n",
       " ('elephant', 'huge', 'as'),\n",
       " ('the', 'mighty', 'bhima'),\n",
       " ('in', 'battle', 'by'),\n",
       " ('and', 'that', 'foremost'),\n",
       " ('thus', 'addressed', 'by'),\n",
       " ('along', 'with', 'the'),\n",
       " ('at', 'this', 'the'),\n",
       " ('set', 'out', 'with'),\n",
       " ('the', 'aid', 'of'),\n",
       " ('and', 'taking', 'up'),\n",
       " ('that', 'mighty', 'hero'),\n",
       " ('and', 'by', 'the'),\n",
       " ('on', 'the', 'earth'),\n",
       " ('therefore', 'o', 'king'),\n",
       " ('then', 'addressed', 'his'),\n",
       " ('prince', 'of', 'the'),\n",
       " ('who', 'had', 'been'),\n",
       " (\"'by\", 'good', 'luck'),\n",
       " ('that', 'thou', 'hast'),\n",
       " ('by', 'good', 'luck'),\n",
       " (\"'do\", 'thou', 'o'),\n",
       " ('an', 'object', 'of'),\n",
       " ('without', 'doubt', 'the'),\n",
       " ('it', 'was', 'thus'),\n",
       " ('karna', 'and', 'kripa'),\n",
       " ('in', 'the', 'search'),\n",
       " ('searched', 'have', 'we'),\n",
       " ('it', 'seems', 'that'),\n",
       " ('the', 'track', 'of'),\n",
       " ('we', 'have', 'not'),\n",
       " ('obedient', 'to', 'the'),\n",
       " ('of', 'pandu', 'with'),\n",
       " ('grandsire', 'of', 'the'),\n",
       " ('of', 'the', 'kshatriya'),\n",
       " ('of', 'the', 'country'),\n",
       " ('the', 'country', 'where'),\n",
       " ('people', 'of', 'the'),\n",
       " ('any', 'of', 'the'),\n",
       " ('the', 'mighty', 'king'),\n",
       " ('if', 'it', 'pleases'),\n",
       " ('the', 'preceptor', 'drona'),\n",
       " ('the', 'expiry', 'of'),\n",
       " ('expiry', 'of', 'the'),\n",
       " ('had', 'been', 'seized'),\n",
       " ('seated', 'on', 'the'),\n",
       " ('and', 'surrounded', 'by'),\n",
       " ('the', 'coat', 'of'),\n",
       " ('of', 'mail', 'that'),\n",
       " ('yudhishthira', 'and', 'bhima'),\n",
       " ('and', 'bhima', 'and'),\n",
       " ('and', 'the', '_asuras_'),\n",
       " ('in', 'that', 'conflict'),\n",
       " ('of', 'battle', 'was'),\n",
       " ('off', 'by', 'means'),\n",
       " ('on', 'their', 'cars'),\n",
       " ('in', 'battle', 'and'),\n",
       " ('the', 'hearts', 'of'),\n",
       " ('the', 'whole', 'army'),\n",
       " ('that', 'he', 'may'),\n",
       " ('vaisampayana', 'continued', '\"beholding'),\n",
       " ('a', 'shower', 'of'),\n",
       " ('from', 'the', 'car'),\n",
       " ('down', 'from', 'his'),\n",
       " ('from', 'his', 'car'),\n",
       " ('and', 'sorely', 'afflicted'),\n",
       " ('of', 'their', 'own'),\n",
       " ('his', 'car', 'and'),\n",
       " ('this', 'is', 'the'),\n",
       " ('and', 'having', 'saluted'),\n",
       " ('sovereignty', 'of', 'the'),\n",
       " ('decked', 'in', 'ornaments'),\n",
       " ('the', 'city', 'with'),\n",
       " ('and', 'vikarna', 'and'),\n",
       " ('and', 'the', 'kauravas'),\n",
       " ('all', 'sides', 'with'),\n",
       " ('the', 'chief', 'of'),\n",
       " ('and', 'he', 'said'),\n",
       " ('enhancer', 'of', 'the'),\n",
       " ('of', 'the', 'bow'),\n",
       " ('as', 'soon', 'as'),\n",
       " ('of', 'the', 'steeds'),\n",
       " ('having', 'vanquished', 'the'),\n",
       " ('vanquished', 'the', 'kurus'),\n",
       " ('the', 'virtues', 'of'),\n",
       " ('the', 'neuter', 'sex'),\n",
       " ('hold', 'the', 'reins'),\n",
       " ('reins', 'of', 'my'),\n",
       " ('with', 'a', 'golden'),\n",
       " ('why', 'art', 'thou'),\n",
       " ('away', 'by', 'the'),\n",
       " ('with', 'the', 'kurus'),\n",
       " ('partha', 'the', 'son'),\n",
       " ('with', 'vrihannala', 'as'),\n",
       " ('have', 'come', 'hither'),\n",
       " ('of', 'the', 'wind'),\n",
       " ('the', 'army', 'of'),\n",
       " ('the', 'kurus', 'the'),\n",
       " ('the', 'sky', 'and'),\n",
       " ('the', 'sight', 'of'),\n",
       " ('of', 'being', 'vanquished'),\n",
       " ('elephants', 'and', 'cars'),\n",
       " ('my', 'mind', 'is'),\n",
       " ('person', 'of', 'the'),\n",
       " ('do', 'not', 'see'),\n",
       " ('it', 'was', 'he'),\n",
       " ('drona', 'and', 'kripa'),\n",
       " ('to', 'bear', 'the'),\n",
       " ('this', 'excellent', 'bow'),\n",
       " ('is', 'this', 'excellent'),\n",
       " ('and', 'cased', 'in'),\n",
       " ('whetted', 'on', 'stone'),\n",
       " ('in', 'a', 'sheath'),\n",
       " ('a', 'sheath', 'of'),\n",
       " ('held', 'it', 'for'),\n",
       " ('whole', 'of', 'the'),\n",
       " ('of', 'pritha', 'and'),\n",
       " ('yoked', 'unto', 'the'),\n",
       " ('steeds', 'endued', 'with'),\n",
       " ('stationed', 'in', 'the'),\n",
       " ('with', 'the', 'blare'),\n",
       " ('the', 'earth', 'itself'),\n",
       " ('seem', 'to', 'be'),\n",
       " ('it', 'may', 'be'),\n",
       " ('may', 'be', 'that'),\n",
       " ('on', 'all', 'sides'),\n",
       " ('stationed', 'on', 'his'),\n",
       " ('and', 'afflicted', 'by'),\n",
       " ('an', 'encounter', 'with'),\n",
       " (\"drona's\", 'son', 'and'),\n",
       " ('the', 'celestials', 'and'),\n",
       " ('of', 'pandu', 'is'),\n",
       " ('and', 'the', 'kurus'),\n",
       " ('addressed', 'the', 'son'),\n",
       " ('by', 'partha', 'the'),\n",
       " ('those', 'mighty', 'car-warriors'),\n",
       " ('from', 'his', 'bow'),\n",
       " ('with', 'an', 'arrow'),\n",
       " ('the', 'van', 'of'),\n",
       " ('son', 'of', 'radha'),\n",
       " ('mangled', 'by', 'the'),\n",
       " ('end', 'of', 'the'),\n",
       " ('and', 'beholding', 'those'),\n",
       " ('that', 'warrior', 'whose'),\n",
       " ('warrior', 'whose', 'flag'),\n",
       " ('whose', 'flag', 'beareth'),\n",
       " ('flag', 'beareth', 'the'),\n",
       " ('feathers', 'of', 'the'),\n",
       " ('of', 'the', '_kanka_'),\n",
       " ('clouds', 'of', 'arrows'),\n",
       " ('a', 'cloud', 'of'),\n",
       " ('with', 'his', 'own'),\n",
       " ('a', 'cheerful', 'heart'),\n",
       " ('have', 'been', 'recovered'),\n",
       " ('the', 'kine', 'have'),\n",
       " ('vrihannala', 'as', 'his'),\n",
       " ('of', 'his', 'son'),\n",
       " ('couldst', 'thou', 'o'),\n",
       " ('thou', 'o', 'child'),\n",
       " ('o', 'child', 'encounter'),\n",
       " ('part', 'of', 'this'),\n",
       " ('the', 'phrase', '“project'),\n",
       " ('work', 'or', 'any'),\n",
       " ('project', 'gutenberg™', 'work'),\n",
       " ('krishna-dwaipayana', 'vyasa', 'translated'),\n",
       " ('vyasa', 'translated', 'into'),\n",
       " ('afflicted', 'with', 'the'),\n",
       " ('devoted', 'to', 'her'),\n",
       " ('to', 'her', 'lords'),\n",
       " ('unto', 'the', 'brahmanas'),\n",
       " ('o', 'bharata', 'the'),\n",
       " ('and', 'abounding', 'in'),\n",
       " ('of', 'virata', 'o'),\n",
       " ('ye', 'sons', 'of'),\n",
       " ('I', 'shall', 'become'),\n",
       " ('me', 'I', 'shall'),\n",
       " ('pass', 'my', 'days'),\n",
       " ('section', '\"bhima', 'said'),\n",
       " ('of', 'virata', 'as'),\n",
       " ('of', 'the', 'royal'),\n",
       " ('the', 'royal', 'household'),\n",
       " ('of', 'viands', 'and'),\n",
       " ('in', 'the', 'lists'),\n",
       " ('take', 'the', 'life'),\n",
       " ('the', 'life', 'of'),\n",
       " ('while', 'he', 'was'),\n",
       " ('forest', 'of', 'khandava'),\n",
       " ('on', 'a', 'single'),\n",
       " ('a', 'single', 'car'),\n",
       " ('and', '_rakshasas_', 'and'),\n",
       " ('is', 'the', 'best'),\n",
       " ('best', 'of', 'all'),\n",
       " ('the', 'first', 'of'),\n",
       " ('first', 'of', 'all'),\n",
       " ('and', 'who', 'is'),\n",
       " ('for', 'five', 'years'),\n",
       " ('years', 'in', 'the'),\n",
       " ('the', 'science', 'of'),\n",
       " ('the', 'third', 'sex'),\n",
       " ('king', 'I', 'shall'),\n",
       " ('of', 'draupadI', 'in'),\n",
       " ('and', 'foremost', 'of'),\n",
       " ('foremost', 'of', 'virtuous'),\n",
       " ('the', 'king', 'addressed'),\n",
       " ('the', 'keeper', 'of'),\n",
       " ('me', 'and', 'I'),\n",
       " ('thee', 'o', 'king'),\n",
       " ('will', 'be', 'able'),\n",
       " ('replied', \"'I\", 'will'),\n",
       " ('well-acquainted', 'with', 'the'),\n",
       " ('as', 'also', 'with'),\n",
       " ('as', 'a', '_sairindhri_'),\n",
       " ('the', 'wife', 'of'),\n",
       " ('thou', 'knowest', 'not'),\n",
       " ('such', 'a', 'way'),\n",
       " ('and', 'let', 'all'),\n",
       " ('will', 'have', 'to'),\n",
       " ('have', 'to', 'pass'),\n",
       " ('with', 'all', 'the'),\n",
       " ('no', 'one', 'should'),\n",
       " ('with', 'the', \"king's\"),\n",
       " ('as', 'he', 'is'),\n",
       " ('a', 'person', 'should'),\n",
       " ('the', 'king', 'in'),\n",
       " ('to', 'indulge', 'in'),\n",
       " ('that', 'is', 'not'),\n",
       " ('the', 'king', 'is'),\n",
       " ('that', 'is', 'the'),\n",
       " ('this', 'is', 'a'),\n",
       " ('is', 'that', 'the'),\n",
       " ('of', 'the', 'whole'),\n",
       " ('out', 'for', 'the'),\n",
       " ('went', 'to', 'the'),\n",
       " ('the', 'panchalas', 'and'),\n",
       " ('part', 'of', 'the'),\n",
       " ('the', 'leader', 'of'),\n",
       " ('bow', 'the', '_gandiva_'),\n",
       " ('nor', 'is', 'there'),\n",
       " ('is', 'in', 'the'),\n",
       " ('midst', 'of', 'an'),\n",
       " ('he', 'had', 'conquered'),\n",
       " ('gods', 'and', 'men'),\n",
       " ('string', 'of', 'that'),\n",
       " ('that', 'bow', 'with'),\n",
       " ('bow', 'with', 'which'),\n",
       " ('of', 'the', 'thunder'),\n",
       " ('the', 'splitting', 'of'),\n",
       " ('in', 'accordance', 'with'),\n",
       " ('vaisampayana', 'said', '\"and'),\n",
       " ('began', 'to', 'praise'),\n",
       " ('bright', 'as', 'the'),\n",
       " ('the', 'moon', 'in'),\n",
       " ('with', 'an', 'excellent'),\n",
       " ('for', 'this', 'o'),\n",
       " ('and', 'worshipped', 'by'),\n",
       " ('worshipped', 'by', 'the'),\n",
       " ('by', 'the', 'gods'),\n",
       " ('protection', 'of', 'the'),\n",
       " ('of', 'the', 'three'),\n",
       " ('there', 'is', 'nothing'),\n",
       " ('in', 'the', 'great'),\n",
       " ('deprived', 'of', 'my'),\n",
       " ('acting', 'according', 'to'),\n",
       " ('by', 'the', 'son'),\n",
       " ('addressed', 'him', 'in'),\n",
       " ('to', 'these', 'words'),\n",
       " ('of', 'the', 'kauravas'),\n",
       " ('through', 'my', 'grace'),\n",
       " ('and', 'they', 'also'),\n",
       " ('in', 'the', 'world'),\n",
       " ('I', 'will', 'bestow'),\n",
       " ('beauty', 'of', 'person'),\n",
       " ('and', 'having', 'said'),\n",
       " ('that', 'chastiser', 'of'),\n",
       " ('of', 'foes', 'and'),\n",
       " ('in', 'his', 'court'),\n",
       " ('the', 'full', 'moon'),\n",
       " ('virata', 'addressed', 'his'),\n",
       " ('the', 'twice-born', 'ones'),\n",
       " ('who', 'it', 'is'),\n",
       " ('like', 'a', 'king'),\n",
       " ('he', 'is', 'a'),\n",
       " ('even', 'as', 'an'),\n",
       " ('the', 'means', 'of'),\n",
       " ('unto', 'him', 'saying'),\n",
       " ('him', 'with', 'a'),\n",
       " ('with', 'a', 'glad'),\n",
       " ('a', 'glad', 'heart'),\n",
       " ('is', 'explained', 'by'),\n",
       " ('and', 'I', 'am'),\n",
       " ('thou', 'on', 'the'),\n",
       " ('on', 'the', 'other'),\n",
       " ('is', 'that', 'I'),\n",
       " ('began', 'to', 'live'),\n",
       " ('is', 'like', 'the'),\n",
       " ('seems', 'to', 'me'),\n",
       " ('up', 'to', 'the'),\n",
       " ('younger', 'brother', 'of'),\n",
       " ('saying', \"'o\", 'foremost'),\n",
       " (\"'o\", 'foremost', 'of'),\n",
       " ('I', 'am', 'also'),\n",
       " ('is', 'worthy', 'of'),\n",
       " ('of', 'those', 'who'),\n",
       " ('continued', 'to', 'live'),\n",
       " ('addressed', 'her', 'saying'),\n",
       " ('I', 'desire', 'to'),\n",
       " ('and', 'it', 'came'),\n",
       " ('it', 'came', 'to'),\n",
       " ('came', 'to', 'pass'),\n",
       " ('to', 'pass', 'that'),\n",
       " ('daughter', 'of', 'the'),\n",
       " ('her', 'saying', \"'o\"),\n",
       " ('the', 'mistress', 'of'),\n",
       " ('and', 'like', 'a'),\n",
       " ('art', 'thou', 'the'),\n",
       " ('art', 'thou', 'o'),\n",
       " ('tell', 'thee', 'this'),\n",
       " ('the', 'pandavas', 'and'),\n",
       " ('and', 'the', 'foremost'),\n",
       " ('that', 'I', 'should'),\n",
       " ('if', 'it', 'is'),\n",
       " ('came', 'to', 'the'),\n",
       " ('those', 'bulls', 'of'),\n",
       " ('those', 'lions', 'among'),\n",
       " ('said', \"'I\", 'have'),\n",
       " ('continued', '\"then', 'o'),\n",
       " ('virata', 'began', 'to'),\n",
       " ('at', 'the', 'gate'),\n",
       " ('the', 'gate', 'of'),\n",
       " ('gate', 'of', 'the'),\n",
       " ('earth', 'with', 'his'),\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_to_learn = ngrams_up_to_20[1].copy()\n",
    "[sent[0] for sent in my_filter(trigrams_to_learn.most_common())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab72928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_example.extend([[word_to_index[w] for w in sent[0][:-1]] for sent in my_filter(trigrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])])\n",
    "y_train_example.extend([[word_to_index[w] for w in sent[0][1:]] for sent in my_filter(trigrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f81ed38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11267, 11267)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_example), len(y_train_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36c0a301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[516], [601], [59], [489], [19], [0], [12], [16], [165], [57]],\n",
       " [[1], [6], [46], [0], [8], [747], [271], [55], [0], [12]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_example[1575:1585], y_train_example[1575:1585]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "935c700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_to_learn = ngrams_up_to_20[0]\n",
    "X_train_2 = [[word_to_index[sent[0][0]]] for sent in my_filter(bigrams_to_learn.most_common())\n",
    "                  if sent[0][0] in word_to_index and sent[0][1] in word_to_index]\n",
    "y_train_2 = [[word_to_index[sent[0][1]]] for sent in my_filter(bigrams_to_learn.most_common())\n",
    "                  if sent[0][0] in word_to_index and sent[0][1] in word_to_index]\n",
    "X_train_2, y_train_2 = fisher_yates(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c82c6fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7124, 7124)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_2), len(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1079ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[5], [2], [1], [2415], [6], [2252], [42], [862], [11], [54]],\n",
       " [[402], [257], [571], [6], [556], [5], [676], [9], [70], [5]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2[0:10], y_train_2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8246b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.extend(X_train_2)\n",
    "y_train.extend(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2af69cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9548, 9548)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6d350e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([645], [36]),\n",
       " ([16], [646]),\n",
       " ([3], [2]),\n",
       " ([0], [2646]),\n",
       " ([3], [733]),\n",
       " ([8], [289]),\n",
       " ([3], [2]),\n",
       " ([34], [225]),\n",
       " ([2], [230]),\n",
       " ([3], [2])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(zip(X_train, y_train)), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb6225a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'son', 'of'), 151),\n",
       " (('the', 'sons', 'of'), 53),\n",
       " (('the', 'king', 'of'), 50),\n",
       " (('king', 'of', 'the'), 48),\n",
       " (('o', 'thou', 'of'), 47),\n",
       " (('son', 'of', 'pandu'), 45),\n",
       " (('section', 'vaisampayana', 'said'), 42),\n",
       " (('by', 'means', 'of'), 42),\n",
       " (('of', 'the', 'matsyas'), 41),\n",
       " (('sons', 'of', 'pandu'), 38)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_to_learn = ngrams_up_to_20[1]\n",
    "ngrams_to_learn.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0073cb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'son', 'of'),\n",
       " ('the', 'sons', 'of'),\n",
       " ('the', 'king', 'of'),\n",
       " ('king', 'of', 'the'),\n",
       " ('o', 'thou', 'of'),\n",
       " ('son', 'of', 'pandu'),\n",
       " ('section', 'vaisampayana', 'said'),\n",
       " ('by', 'means', 'of'),\n",
       " ('of', 'the', 'matsyas'),\n",
       " ('sons', 'of', 'pandu')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent[0] for sent in my_filter(ngrams_to_learn.most_common(10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6b271a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[459, 271], [2, 425], [8, 1474], [656, 154], [63, 93]],\n",
       " [[271, 1], [425, 1], [1474, 1], [154, 12], [93, 28]],\n",
       " 45271,\n",
       " 45271)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2 = [[word_to_index[w] for w in sent[0][:-1]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])]\n",
    "y_train_2 = [[word_to_index[w] for w in sent[0][1:]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])]\n",
    "X_train_2, y_train_2 = fisher_yates(X_train_2, y_train_2)\n",
    "X_train_2[0:5], y_train_2[0:5], len(X_train_2), len(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "369c7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_filter(ngrams):\n",
    "    return filter(remove_periods, ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2631d3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[17, 9], [13, 93], [0, 930], [8, 1], [14, 1]],\n",
       " [[9, 223], [93, 8], [930, 626], [1, 9], [1, 0]],\n",
       " 2000,\n",
       " 2000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2 = [[word_to_index[w] for w in sent[0][:-1]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])]\n",
    "y_train_2 = [[word_to_index[w] for w in sent[0][1:]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])]\n",
    "X_train_2 = X_train_2[:2000]\n",
    "y_train_2 = y_train_2[:2000]\n",
    "X_train_2, y_train_2 = fisher_yates(X_train_2, y_train_2)\n",
    "X_train_2[0:5], y_train_2[0:5], len(X_train_2), len(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b44356ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 20], [0, 120], [0, 18], [18, 1], [13, 14]] [[20, 1], [120, 1], [18, 1], [1, 0], [14, 1]] 45271 45271\n"
     ]
    }
   ],
   "source": [
    "ngrams_to_learn = ngrams_up_to_20[1]\n",
    "X_train_2 = [[word_to_index[w] for w in sent[0][:-1]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])]\n",
    "y_train_2 = [[word_to_index[w] for w in sent[0][1:]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "               if all([w in word_to_index for w in sent[0]])]\n",
    "print(X_train_2[0:5], y_train_2[0:5], len(X_train_2), len(y_train_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5326455c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index['SENTENCE_END']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d69ad50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_eos(trigram):\n",
    "    if trigram[1] == word_to_index['SENTENCE_END']:\n",
    "          return True  \n",
    "    return False\n",
    "\n",
    "trigrams_eos = list(filter(check_eos, y_train_2))\n",
    "len(trigrams_eos), trigrams_eos[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eac556ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 18/18 [00:05<00:00,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(1, len(ngrams_up_to_20))):\n",
    "    ngrams_to_learn = ngrams_up_to_20[i]\n",
    "    X_train_2 = [[word_to_index[w] for w in sent[0][:-1]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "                   if all([w in word_to_index for w in sent[0]])]\n",
    "    y_train_2 = [[word_to_index[w] for w in sent[0][1:]] for sent in my_filter(ngrams_to_learn.most_common())\n",
    "                   if all([w in word_to_index for w in sent[0]])]\n",
    "    X_train_2 = X_train_2[:2000]\n",
    "    y_train_2 = y_train_2[:2000]\n",
    "    X_train_2, y_train_2 = fisher_yates(X_train_2, y_train_2)\n",
    "    X_train.extend(X_train_2)\n",
    "    y_train.extend(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e9e55f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81548, 81548)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d8a13176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([259, 1, 156, 452, 33, 365, 757, 5, 0, 129, 1, 48, 2], [1, 156, 452, 33, 365, 757, 5, 0, 129, 1, 48, 2, 13]), ([5, 324, 2, 1566, 1, 709, 15], [324, 2, 1566, 1, 709, 15, 86]), ([75, 674, 0, 18, 3533], [674, 0, 18, 3533, 34]), ([1278], [2]), ([0, 18, 15, 86, 306, 8, 15], [18, 15, 86, 306, 8, 15, 1957]), ([0, 722, 844, 41, 49, 672, 0, 260, 1351, 22, 530, 1618, 855, 25, 721, 1333, 1, 0, 18], [722, 844, 41, 49, 672, 0, 260, 1351, 22, 530, 1618, 855, 25, 721, 1333, 1, 0, 18, 3655]), ([452, 33, 365, 757, 5, 0, 129, 1, 48], [33, 365, 757, 5, 0, 129, 1, 48, 2]), ([5, 0, 129, 1, 48], [0, 129, 1, 48, 14]), ([1549, 1550, 3492, 1133, 48, 2454, 1551, 158, 1297, 1552, 36, 0, 1554, 1555], [1550, 3492, 1133, 48, 2454, 1551, 158, 1297, 1552, 36, 0, 1554, 1555, 1134]), ([112, 12, 594, 1391, 92, 1393, 11, 8, 514, 8, 200, 97, 66, 6, 1069], [12, 594, 1391, 92, 1393, 11, 8, 514, 8, 200, 97, 66, 6, 1069, 965])]\n"
     ]
    }
   ],
   "source": [
    "print(random.sample(list(zip(X_train, y_train)), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc0160dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2f3d8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SENTENCE_START',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'therefore',\n",
       " 'speak',\n",
       " 'to',\n",
       " 'you',\n",
       " 'something',\n",
       " 'SENTENCE_END']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e9d8db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 15, 86, 130, 721, 7, 95, 1965, 4]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[word_to_index[w] for w in sent] for sent in tokenized_sentences if all([w in word_to_index for w in sent])][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af7276cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full_sentences = [[word_to_index[w] for w in sent[:-1]] for sent in tokenized_sentences\n",
    "                         if all([w in word_to_index for w in sent])]\n",
    "y_train_full_sentences = [[word_to_index[w] for w in sent[1:]] for sent in tokenized_sentences\n",
    "                         if all([w in word_to_index for w in sent])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b8bded8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 3480, 0, 1296, 1, 1549, 1550, 1551, 158, 1297, 1552, 3481, 2443, 2444, 2445, 3482, 1903, 3483, 917, 3484, 79, 835, 3485, 3486, 80, 500, 3487, 2446, 3488, 1553, 3489, 3490, 1297, 3491, 1132, 10, 2447, 1904, 2448, 2449, 2450, 2451, 18, 2, 0, 1298, 918, 2452, 2453, 669, 669, 669, 1905, 1, 0, 110, 320, 835, 0, 1296, 1, 1549, 1550, 1551, 158, 1297, 1552, 669, 669, 669, 1132, 10, 2447, 1904, 2448, 2449, 2450, 2451, 18, 2, 0, 1298, 918, 2452, 2453, 0, 1296, 1, 1549, 1550, 3492, 1133, 48, 2454, 1551, 158, 1297, 1552, 36, 0, 1554, 1555, 1134, 10, 2443, 2444, 2445, 79, 3493, 80, 0, 1296, 48, 2454, 117, 52, 3494, 1299, 53, 3495, 49, 1906, 161, 7, 1907, 2, 3496, 0, 500, 1300, 1, 1556, 756, 2, 51, 7, 0, 451, 3497, 292, 0, 708, 1908, 24, 1135], [3, 1557, 28, 37, 282, 521, 31, 3498, 208, 6, 0, 259, 1, 156, 452, 33, 365, 757, 5, 0, 129, 1, 48, 2, 13, 3499, 282, 521, 0, 427, 614, 189, 1136, 6, 670, 453, 7, 63, 547, 2, 349, 3500, 0, 1010, 79, 917, 80, 1011, 63, 365, 1909, 253, 79, 917, 80, 3501, 3502, 67, 501, 1301, 16, 17, 3503, 69, 28, 37, 615, 13, 159, 1, 66, 282, 40, 61, 3504, 548, 0, 836, 1, 3505, 5, 0, 129, 1, 48], [3, 49, 5, 16, 350, 671, 1012, 36, 0, 837, 1, 1910, 8, 221, 1, 428, 66, 74, 1137, 7, 0, 3506, 2, 2455, 57, 0, 474, 21, 8, 78, 1302], [3, 2, 49, 2455, 475, 57, 68, 74, 2456, 7, 8, 1303, 578, 41, 78, 411, 32, 0, 3507, 1304, 2, 0, 3508, 29, 78, 672], [3, 2, 13, 191, 0, 20, 1, 0, 837, 1, 1910, 0, 260, 74, 1, 1138, 429, 45, 321, 351, 21, 12, 838, 299, 2, 112, 68, 92, 3509, 36, 134, 235, 103, 43, 548, 839, 322]] [[3480, 0, 1296, 1, 1549, 1550, 1551, 158, 1297, 1552, 3481, 2443, 2444, 2445, 3482, 1903, 3483, 917, 3484, 79, 835, 3485, 3486, 80, 500, 3487, 2446, 3488, 1553, 3489, 3490, 1297, 3491, 1132, 10, 2447, 1904, 2448, 2449, 2450, 2451, 18, 2, 0, 1298, 918, 2452, 2453, 669, 669, 669, 1905, 1, 0, 110, 320, 835, 0, 1296, 1, 1549, 1550, 1551, 158, 1297, 1552, 669, 669, 669, 1132, 10, 2447, 1904, 2448, 2449, 2450, 2451, 18, 2, 0, 1298, 918, 2452, 2453, 0, 1296, 1, 1549, 1550, 3492, 1133, 48, 2454, 1551, 158, 1297, 1552, 36, 0, 1554, 1555, 1134, 10, 2443, 2444, 2445, 79, 3493, 80, 0, 1296, 48, 2454, 117, 52, 3494, 1299, 53, 3495, 49, 1906, 161, 7, 1907, 2, 3496, 0, 500, 1300, 1, 1556, 756, 2, 51, 7, 0, 451, 3497, 292, 0, 708, 1908, 24, 1135, 4], [1557, 28, 37, 282, 521, 31, 3498, 208, 6, 0, 259, 1, 156, 452, 33, 365, 757, 5, 0, 129, 1, 48, 2, 13, 3499, 282, 521, 0, 427, 614, 189, 1136, 6, 670, 453, 7, 63, 547, 2, 349, 3500, 0, 1010, 79, 917, 80, 1011, 63, 365, 1909, 253, 79, 917, 80, 3501, 3502, 67, 501, 1301, 16, 17, 3503, 69, 28, 37, 615, 13, 159, 1, 66, 282, 40, 61, 3504, 548, 0, 836, 1, 3505, 5, 0, 129, 1, 48, 4], [49, 5, 16, 350, 671, 1012, 36, 0, 837, 1, 1910, 8, 221, 1, 428, 66, 74, 1137, 7, 0, 3506, 2, 2455, 57, 0, 474, 21, 8, 78, 1302, 4], [2, 49, 2455, 475, 57, 68, 74, 2456, 7, 8, 1303, 578, 41, 78, 411, 32, 0, 3507, 1304, 2, 0, 3508, 29, 78, 672, 4], [2, 13, 191, 0, 20, 1, 0, 837, 1, 1910, 0, 260, 74, 1, 1138, 429, 45, 321, 351, 21, 12, 838, 299, 2, 112, 68, 92, 3509, 36, 134, 235, 103, 43, 548, 839, 322, 4]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full_sentences[0:5], y_train_full_sentences[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "74841280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['SENTENCE_START', 'and', 'for', 'thee', 'all', 'my', 'doors', 'shall', 'be', 'open', 'SENTENCE_END'], [']', 'some', 'texts', 'read', '_diptasya_', 'for', '_diptayam_', 'SENTENCE_END'], ['purpose', 'such', 'as', 'creation', 'of', 'derivative', 'works', 'reports', 'performances', 'and', 'research', 'SENTENCE_END'], ['SENTENCE_START', 'let', 'every', 'preparation', 'therefore', 'for', 'battle', 'be', 'made', 'without', 'delay', 'SENTENCE_END'], ['used', 'in', 'the', 'same', 'sense', 'SENTENCE_END'], ['roar', 'also', 'of', 'many', 'elephants', 'in', 'the', 'midst', 'of', 'ranks', 'arrayed', 'for', 'battled', 'SENTENCE_END'], ['to', 'the', 'king', 'SENTENCE_END'], ['princess', 'kaikeyI', 'looking', 'on', 'then', 'I', 'almost', 'swoon', 'away', 'SENTENCE_END'], ['been', 'slain', 'by', 'the', 'gandharvas', 'SENTENCE_END'], ['hath', 'come', 'for', 'worshipping', 'the', 'illustrious', 'sons', 'of', 'pandu', 'who', 'deserve', 'to', 'be', 'worshipped', 'by', 'us', 'SENTENCE_END']]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "last_n_words = []\n",
    "for i in range(3, 20):\n",
    "    tokenized_sentences_400 = random.sample(list(tokenized_sentences), 400)\n",
    "    for s in tokenized_sentences_400:\n",
    "        last_n_words.append(s[::-1][:i][::-1])\n",
    "\n",
    "print(random.sample(last_n_words, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8a060997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6800"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(last_n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9eb3b1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eos = [[word_to_index[w] for w in sent[:-1]] for sent in last_n_words\n",
    "                         if all([w in word_to_index for w in sent])]\n",
    "y_train_eos = [[word_to_index[w] for w in sent[1:]] for sent in last_n_words\n",
    "                         if all([w in word_to_index for w in sent])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6bc82196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6800, 6800)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_eos), len(y_train_eos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b855b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.extend(X_train_eos)\n",
    "y_train.extend(y_train_eos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e1c2b66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88348, 88348)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d09e8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/X_train_siddhartha.pkl', 'wb') as file:\n",
    "    pickle.dump(X_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "911c3694",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/y_train_siddhartha.pkl', 'wb') as file:\n",
    "    pickle.dump(y_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f795331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tokenized_sentences_siddhartha.pkl', 'wb') as file:\n",
    "    pickle.dump(tokenized_sentences, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f38bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/word_to_index_siddhartha.pkl', 'wb') as file:\n",
    "    pickle.dump(word_to_index, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1991e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/index_to_word_siddhartha.pkl', 'wb') as file:\n",
    "    pickle.dump(index_to_word, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5f6790eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = np.asarray(X_train,dtype=object)\n",
    "y_train2 = np.asarray(y_train,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e4096fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88348,), (88348,))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape, y_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d39c8223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([2, 101, 342, 183, 29, 46, 1141, 6], [101, 342, 183, 29, 46, 1141, 6, 168]), ([12, 2640, 1197, 486, 108, 7, 0, 20, 1, 222, 2, 2641, 8, 838, 274, 1, 74, 1, 475], [2640, 1197, 486, 108, 7, 0, 20, 1, 222, 2, 2641, 8, 838, 274, 1, 74, 1, 475, 0]), ([3], [2]), ([0, 18, 2, 3535], [18, 2, 3535, 21]), ([1911, 228, 919, 502, 2, 430, 2462, 22], [228, 919, 502, 2, 430, 2462, 22, 134]), ([22, 8, 11, 0, 185, 945, 22, 1346, 1979], [8, 11, 0, 185, 945, 22, 1346, 1979, 2]), ([7], [1209]), ([112, 68, 92, 3509, 36, 134], [68, 92, 3509, 36, 134, 235]), ([3734, 1, 3735, 29, 78, 2575, 2576, 725, 115, 2, 218, 116, 487, 87, 46, 26, 57], [1, 3735, 29, 78, 2575, 2576, 725, 115, 2, 218, 116, 487, 87, 46, 26, 57, 0]), ([0, 438, 131, 65, 419, 1, 1034, 3640, 7, 50, 116, 1350, 11, 61, 3641, 2], [438, 131, 65, 419, 1, 1034, 3640, 7, 50, 116, 1350, 11, 61, 3641, 2, 116])]\n"
     ]
    }
   ],
   "source": [
    "print(random.sample(list(zip(X_train2, y_train2)), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5767958f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a810324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb519df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d52931a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4efa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc1f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "edc223f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6399, 100)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "vocabulary_size, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2881a4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#glove_dir = 'data/glove'\n",
    "glove_dir = \"data\"\n",
    "\n",
    "embeddings_index = {} #initialize dictionary\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'), encoding='utf8')\n",
    "try:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "except:\n",
    "    print(line)\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5f9e6ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6399"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b8f4f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulary_size, embedding_dim))\n",
    "for word, i in vocab:\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < vocabulary_size:\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5a5f28e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6399, 100)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5946be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bull', 48)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8de82608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.00619996e-01, -8.98370028e-01,  2.54619986e-01, -7.58920014e-01,\n",
       "        9.65050012e-02, -3.05970013e-01, -7.64230013e-01,  2.65679993e-02,\n",
       "       -4.19140011e-01, -5.43119982e-02,  3.83730009e-02,  8.51670027e-01,\n",
       "        5.33879995e-01,  2.73490012e-01, -1.12999998e-01,  1.20609999e-02,\n",
       "        9.45160016e-02,  2.46339999e-02,  4.66340005e-01, -7.58130014e-01,\n",
       "       -2.07120001e-01, -1.10250004e-01, -1.20290004e-01, -5.13180017e-01,\n",
       "       -9.92090032e-02, -4.33939993e-01, -3.66420001e-01,  6.38860017e-02,\n",
       "        5.58220029e-01, -1.75260007e-01,  2.27789998e-01,  1.84090003e-01,\n",
       "       -5.54630011e-02, -6.50359988e-01, -1.28410006e+00,  3.77029985e-01,\n",
       "       -5.21790028e-01, -1.59470007e-01, -5.88270009e-01, -4.60640013e-01,\n",
       "       -1.70790002e-01, -3.26260000e-01,  1.11259997e+00, -2.29320005e-01,\n",
       "       -5.94309986e-01,  2.97919989e-01,  8.04319978e-03,  1.69469997e-01,\n",
       "        1.71079993e-01, -6.59990013e-02, -6.96300030e-01, -3.22090000e-01,\n",
       "       -4.24439996e-01,  1.13610005e+00,  2.18620002e-01, -9.69969988e-01,\n",
       "       -2.19699994e-01,  1.37769997e-01,  1.09040000e-01, -3.74550015e-01,\n",
       "        7.88730025e-01,  4.28900003e-01, -3.38939995e-01,  1.04620002e-01,\n",
       "       -2.86130011e-01,  5.91480017e-01, -1.71700001e-01,  1.82960004e-01,\n",
       "        2.20950007e-01,  4.78009999e-01,  1.13770001e-01, -3.66670012e-01,\n",
       "       -6.81789994e-01, -9.45370004e-04, -3.74379992e-01, -6.66899979e-01,\n",
       "       -1.53059995e+00, -3.00420001e-02,  1.75600007e-01, -3.79660010e-01,\n",
       "        4.92570013e-01, -7.10950017e-01, -5.56529999e-01,  4.71910000e-01,\n",
       "        2.00629994e-01,  3.06690007e-01,  5.45660019e-01,  4.08230007e-01,\n",
       "       -2.48029996e-02, -9.34140027e-01, -4.78219986e-01,  1.96640000e-01,\n",
       "        3.97399992e-01,  1.51920006e-01, -7.68250003e-02, -4.25770015e-01,\n",
       "        6.94070011e-02,  2.66920000e-01,  2.75119990e-01,  9.56339985e-02])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7f2e055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def find_closest_embeddings(embedding):\n",
    "    return sorted(embeddings_index.keys(), key=lambda word: spatial.distance.euclidean(embeddings_index[word], embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6e327b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prince', 'queen', 'monarch', 'brother', 'uncle']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_embeddings(embeddings_index[\"king\"])[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fd610a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flashlight', 'twig', 'clipboard', 'shove', 'hand', 'fingers', 'clutching', 'clutched', 'tossing', 'stroking']\n"
     ]
    }
   ],
   "source": [
    "print(find_closest_embeddings(\n",
    "    embeddings_index[\"twig\"] - embeddings_index[\"branch\"] + embeddings_index[\"hand\"]\n",
    ")[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f819c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# tsne = TSNE(n_components=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "871c3d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words =  list(embeddings_index.keys())[:500]\n",
    "# vectors = [embeddings_index[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "00036a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = tsne.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c0c91b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6399, 100)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size, embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f458ce0",
   "metadata": {},
   "source": [
    "### 4. Model Architecture\n",
    "We define the architecture of our RNN model:\n",
    "\n",
    "Embedding Layer: Maps input indices to dense vectors of fixed size.\n",
    "SimpleRNN Layer: A simple recurrent layer that learns dependencies from the sequences.\n",
    "Dense Layer: Outputs the predicted word by applying a softmax over the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a58328ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:    \n",
    "    def __init__(self, word_dim, hidden_dim=100, bptt_truncate=4):\n",
    "        # Assign instance variables\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        \n",
    "        # Randomly initialize the network parameters\n",
    "        #self.U = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (hidden_dim, word_dim))\n",
    "        #self.V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (word_dim, hidden_dim))\n",
    "        self.U = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (hidden_dim, embedding_dim))\n",
    "        self.W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, hidden_dim))\n",
    "        self.V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (word_dim, hidden_dim))\n",
    "        \n",
    "        # Set GLOVE embeddings matrix\n",
    "        self.G = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7a714aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    # sometimes, may want to do this first:\n",
    "    #x = np.vectorize(round)(x)\n",
    "    \n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "57cd3758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(self, x):\n",
    "    # The total number of time steps\n",
    "    T = len(x)\n",
    "    \n",
    "    # During forward propagation we save all hidden states in s because need them later.\n",
    "    # We add one additional element for the initial hidden, which we set to 0\n",
    "    s = np.zeros((T + 1, self.hidden_dim))\n",
    "    s[-1] = np.zeros(self.hidden_dim)\n",
    "    \n",
    "    # The outputs at each time step. Again, we save them for later.\n",
    "    o = np.zeros((T, self.word_dim))\n",
    "    \n",
    "    # For each time step...\n",
    "    for t in np.arange(T):\n",
    "        # embedding of x[t]:\n",
    "        e_t = self.G[x[t]]\n",
    "                             \n",
    "        # Note that we are indxing U by x[t]. This is the same as multiplying U with a one-hot vector.\n",
    "        #s[t] = np.tanh(self.U[:,x[t]] + self.W.dot(s[t-1]))\n",
    "        s[t] = np.tanh(self.U.dot(e_t) + self.W.dot(s[t-1]))\n",
    "        o[t] = softmax(self.V.dot(s[t]))\n",
    "        \n",
    "    return [o, s]\n",
    "\n",
    "RNN.forward_propagation = forward_propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f021079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) (6399, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((6399,),\n",
       " array([0.00015627, 0.00015627, 0.00015627, ..., 0.00015627, 0.00015627,\n",
       "        0.00015627]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dim = vocabulary_size\n",
    "hidden_dim = 100\n",
    "embedding_dim = 100\n",
    "U = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (hidden_dim, embedding_dim))\n",
    "W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, hidden_dim))\n",
    "V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (word_dim, hidden_dim))\n",
    "x = np.random.randint(0, high=3000, size=word_dim)\n",
    "T = len(x)\n",
    "s = np.zeros((T + 1, hidden_dim))\n",
    "s_m1 = np.zeros(hidden_dim)\n",
    "o = np.zeros((T, word_dim))\n",
    "e_0 = embedding_matrix[x[0]]\n",
    "s_0 = np.tanh(U.dot(e_0) + W.dot(s_m1))\n",
    "print(s_0.shape, V.shape)\n",
    "o_0 = softmax(V.dot(s_0))\n",
    "o_0.shape, o_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "199cac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, x):\n",
    "    # Perform forward propagation and return index of the highest score\n",
    "    o, s = self.forward_propagation(x)\n",
    "    return np.argmax(o[-1], axis=1)\n",
    "\n",
    "RNN.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "53777307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, x):\n",
    "    # Perform forward propagation and return index of the highest score\n",
    "    o, s = self.forward_propagation(x)\n",
    "    return np.argmax(o, axis=1)\n",
    "\n",
    "RNN.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "799e8fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "SENTENCE_START\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print (\"x:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in X_train2[1000]]), X_train2[1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fcb7dcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "them yudhishthira restored to that regenerate brahmana\n",
      "[68, 74, 2456, 7, 8, 1303, 578]\n"
     ]
    }
   ],
   "source": [
    "print (\"x:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in X_train2[20000]]), X_train2[20000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "59b99be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "brilliant rings on my ears and conch-bangles on my wrists and causing\n",
      "[1936, 2487, 19, 31, 931, 2, 3562, 19, 31, 1937, 2, 2488]\n"
     ]
    }
   ],
   "source": [
    "print (\"x:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in X_train2[30000]]), X_train2[30000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "465128b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6399, [7, 0])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size, X_train2[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a996997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6399) [[0.00015685 0.00015394 0.0001592  ... 0.00015907 0.00016397 0.00015099]\n",
      " [0.00015478 0.00016109 0.00015791 ... 0.00015768 0.00015554 0.00015456]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(17)\n",
    "model = RNN(vocabulary_size)\n",
    "o, s = model.forward_propagation(X_train2[10000])\n",
    "print (o.shape, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "58e71071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2139"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(o[-1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8694fd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17,) [ 500 4074 1288  282 2685 4301 4536 5921 6094 2489  629  930 4536  484\n",
      " 6388 5126  484]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_train2[40000])\n",
    "print(predictions.shape, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4e2b9723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "most fanned saradwat how conch-bracelets speaketh grappled runnest lotus-leaves appear texts neuter grappled force forty 'indra force\n"
     ]
    }
   ],
   "source": [
    "print (\"x:\\n%s\" % (\" \".join([index_to_word[x] for x in predictions])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "93199da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_loss(self, x, y):\n",
    "    L = 0\n",
    "    # For each sentence...\n",
    "    for i in np.arange(len(y)):\n",
    "        o, s = self.forward_propagation(x[i])\n",
    "        # We only care about our prediction of the \"correct\" words\n",
    "        correct_word_predictions = o[np.arange(len(y[i])), y[i]]\n",
    "        # Add to the loss based on how off we were\n",
    "        L += -1 * np.sum(np.log(correct_word_predictions))\n",
    "    return L\n",
    "\n",
    "def calculate_loss(self, x, y):\n",
    "    # Divide the total loss by the number of training examples\n",
    "    N = np.sum((len(y_i) for y_i in y))\n",
    "    return self.calculate_total_loss(x,y)/N\n",
    "\n",
    "RNN.calculate_total_loss = calculate_total_loss\n",
    "RNN.calculate_loss = calculate_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "45779e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Loss for random predictions: 8.763897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/3w1dz5w55nj8bqyr7t76_qr00000gn/T/ipykernel_78657/1857118698.py:14: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  N = np.sum((len(y_i) for y_i in y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual loss: 8.759229\n"
     ]
    }
   ],
   "source": [
    "# Limit to 1000 examples to save time\n",
    "print (\"Expected Loss for random predictions: %f\" % np.log(vocabulary_size))\n",
    "print (\"Actual loss: %f\" % model.calculate_loss(X_train[:1000], y_train[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4ed44b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bptt(self, x, y):\n",
    "    T = len(y)\n",
    "    \n",
    "    # Perform forward propagation\n",
    "    o, s = self.forward_propagation(x)\n",
    "    \n",
    "    # We accumulate the gradients in these variables\n",
    "    dLdU = np.zeros(self.U.shape)\n",
    "    dLdV = np.zeros(self.V.shape)\n",
    "    dLdW = np.zeros(self.W.shape)\n",
    "    delta_o = o\n",
    "    delta_o[np.arange(len(y)), y] -= 1.\n",
    "    \n",
    "    # For each output backwards...\n",
    "    for t in np.arange(T)[::-1]:\n",
    "        dLdV += np.outer(delta_o[t], s[t].T)\n",
    "        \n",
    "        # Initial delta calculation\n",
    "        delta_t = self.V.T.dot(delta_o[t]) * (1 - (s[t] ** 2))\n",
    "        \n",
    "        # Backpropagation through time (for at most self.bptt_truncate steps)\n",
    "        for bptt_step in np.arange(max(0, t-self.bptt_truncate), t+1)[::-1]:\n",
    "            \n",
    "            # print \"Backpropagation step t=%d bptt step=%d \" % (t, bptt_step)\n",
    "            dLdW += np.outer(delta_t, s[bptt_step-1])              \n",
    "            #dLdU[:,x[bptt_step]] += delta_t\n",
    "            dLdU += np.outer(delta_t, self.G[x[bptt_step]]) \n",
    "            \n",
    "            # Update delta for next step\n",
    "            delta_t = self.W.T.dot(delta_t) * (1 - s[bptt_step-1] ** 2)\n",
    "            \n",
    "    return [dLdU, dLdV, dLdW]\n",
    "\n",
    "RNN.bptt = bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4e29de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check(self, x, y, h=0.001, error_threshold=0.01):\n",
    "    \n",
    "    # Calculate the gradients using backpropagation. We want to checker if these are correct.\n",
    "    bptt_gradients = model.bptt(x, y)\n",
    "    \n",
    "    # List of all parameters we want to check.\n",
    "    model_parameters = ['U', 'V', 'W']\n",
    "    \n",
    "    # Gradient check for each parameter\n",
    "    for pidx, pname in enumerate(model_parameters):\n",
    "        \n",
    "        # Get the actual parameter value from the mode, e.g. model.W\n",
    "        parameter = operator.attrgetter(pname)(self)\n",
    "        print(\"Performing gradient check for parameter %s with size %d.\" % (pname, np.prod(parameter.shape)))\n",
    "               \n",
    "        # Iterate over each element of the parameter matrix, e.g. (0,0), (0,1), ...\n",
    "        it = np.nditer(parameter, flags=['multi_index'], op_flags=['readwrite'])\n",
    "        while not it.finished:\n",
    "            ix = it.multi_index\n",
    "               \n",
    "            # Save the original value so we can reset it later\n",
    "            original_value = parameter[ix]\n",
    "               \n",
    "            # Estimate the gradient using (f(x+h) - f(x-h))/(2*h)\n",
    "            parameter[ix] = original_value + h\n",
    "            gradplus = model.calculate_total_loss([x],[y])\n",
    "            parameter[ix] = original_value - h\n",
    "            gradminus = model.calculate_total_loss([x],[y])\n",
    "            estimated_gradient = (gradplus - gradminus)/(2*h)\n",
    "               \n",
    "            # Reset parameter to original value\n",
    "            parameter[ix] = original_value\n",
    "               \n",
    "            # The gradient for this parameter calculated using backpropagation\n",
    "            backprop_gradient = bptt_gradients[pidx][ix]\n",
    "               \n",
    "            # calculate The relative error: (|x - y|/(|x| + |y|))\n",
    "            relative_error = np.abs(backprop_gradient - estimated_gradient) / (\n",
    "                                np.abs(backprop_gradient) + np.abs(estimated_gradient))\n",
    "            \n",
    "               # If the error is to large fail the gradient check\n",
    "            if relative_error > error_threshold:\n",
    "                print( \"Gradient Check ERROR: parameter=%s ix=%s\" % (pname, ix))\n",
    "                print( \"+h Loss: %f\" % gradplus)\n",
    "                print( \"-h Loss: %f\" % gradminus)\n",
    "                print( \"Estimated_gradient: %f\" % estimated_gradient)\n",
    "                print( \"Backpropagation gradient: %f\" % backprop_gradient)\n",
    "                print( \"Relative Error: %f\" % relative_error)\n",
    "                return \n",
    "            it.iternext()\n",
    "               \n",
    "        print( \"Gradient check for parameter %s passed.\" % (pname))\n",
    "\n",
    "RNN.gradient_check = gradient_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aafcc8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing gradient check for parameter U with size 1000.\n",
      "Gradient check for parameter U passed.\n",
      "Performing gradient check for parameter V with size 1000.\n",
      "Gradient check for parameter V passed.\n",
      "Performing gradient check for parameter W with size 100.\n",
      "Gradient check for parameter W passed.\n"
     ]
    }
   ],
   "source": [
    "grad_check_vocab_size = 100\n",
    "np.random.seed(10)\n",
    "model = RNN(grad_check_vocab_size, 10, bptt_truncate=1000)\n",
    "model.gradient_check([0,1,2,3], [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8f5018c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs one step of SGD.\n",
    "def numpy_sdg_step(self, x, y, learning_rate):\n",
    "    # Calculate the gradients\n",
    "    dLdU, dLdV, dLdW = self.bptt(x, y)\n",
    "    \n",
    "    # Change parameters according to gradients and learning rate\n",
    "    self.U -= learning_rate * dLdU\n",
    "    self.V -= learning_rate * dLdV\n",
    "    self.W -= learning_rate * dLdW\n",
    "\n",
    "RNN.sgd_step = numpy_sdg_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e0eb6f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer SGD Loop\n",
    "# - model: The RNN model instance\n",
    "# - X_train: The training data set\n",
    "# - y_train: The training data labels\n",
    "# - learning_rate: Initial learning rate for SGD\n",
    "# - nepoch: Number of times to iterate through the complete dataset\n",
    "# - evaluate_loss_after: Evaluate the loss after this many epochs\n",
    "\n",
    "def train_with_sgd(model, X_train, y_train, learning_rate=0.005, nepoch=100, evaluate_loss_after=5):\n",
    "    # We keep track of the losses so we can plot them later\n",
    "    losses = []\n",
    "    num_examples_seen = 0\n",
    "    \n",
    "    for epoch in range(nepoch):\n",
    "        \n",
    "        # Optionally evaluate the loss\n",
    "        if (epoch % evaluate_loss_after == 0):\n",
    "            loss = model.calculate_loss(X_train, y_train)\n",
    "            losses.append((num_examples_seen, loss))\n",
    "            time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print (\"%s: Loss after num_examples_seen=%d epoch=%d: %f\" % (time, num_examples_seen, epoch, loss))\n",
    "            \n",
    "            # Adjust the learning rate if loss increases\n",
    "            if (len(losses) > 1 and losses[-1][1] > losses[-2][1]):\n",
    "                learning_rate = learning_rate * 0.5  \n",
    "                print (\"Setting learning rate to %f\" % learning_rate)\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        # For each training example...\n",
    "        for i in range(len(y_train)):\n",
    "            \n",
    "            # One SGD step\n",
    "            model.sgd_step(X_train[i], y_train[i], learning_rate)\n",
    "            num_examples_seen += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "77b564e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6399"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b1668708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261 ms ± 38.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(17)\n",
    "model = RNN(vocabulary_size)\n",
    "%timeit model.sgd_step(X_train2[10000], y_train2[10000], 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9942857b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/3w1dz5w55nj8bqyr7t76_qr00000gn/T/ipykernel_78657/1857118698.py:14: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  N = np.sum((len(y_i) for y_i in y))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Train on a small subset of the data to see what happens\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m RNN(vocabulary_size)\n\u001b[0;32m----> 5\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_sgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_loss_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[127], line 18\u001b[0m, in \u001b[0;36mtrain_with_sgd\u001b[0;34m(model, X_train, y_train, learning_rate, nepoch, evaluate_loss_after)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nepoch):\n\u001b[1;32m     15\u001b[0m     \n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Optionally evaluate the loss\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m%\u001b[39m evaluate_loss_after \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m         losses\u001b[38;5;241m.\u001b[39mappend((num_examples_seen, loss))\n\u001b[1;32m     20\u001b[0m         time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[116], line 15\u001b[0m, in \u001b[0;36mcalculate_loss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Divide the total loss by the number of training examples\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     N \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((\u001b[38;5;28mlen\u001b[39m(y_i) \u001b[38;5;28;01mfor\u001b[39;00m y_i \u001b[38;5;129;01min\u001b[39;00m y))\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_total_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mN\n",
      "Cell \u001b[0;32mIn[116], line 5\u001b[0m, in \u001b[0;36mcalculate_total_loss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# For each sentence...\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(y)):\n\u001b[0;32m----> 5\u001b[0m     o, s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# We only care about our prediction of the \"correct\" words\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     correct_word_predictions \u001b[38;5;241m=\u001b[39m o[np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(y[i])), y[i]]\n",
      "Cell \u001b[0;32mIn[104], line 20\u001b[0m, in \u001b[0;36mforward_propagation\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     e_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG[x[t]]\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Note that we are indxing U by x[t]. This is the same as multiplying U with a one-hot vector.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#s[t] = np.tanh(self.U[:,x[t]] + self.W.dot(s[t-1]))\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     s[t] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU\u001b[38;5;241m.\u001b[39mdot(e_t) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mdot(s[t\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     21\u001b[0m     o[t] \u001b[38;5;241m=\u001b[39m softmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV\u001b[38;5;241m.\u001b[39mdot(s[t]))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [o, s]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "# Train on a small subset of the data to see what happens\n",
    "model = RNN(vocabulary_size)\n",
    "losses = train_with_sgd(model, X_train2[10000:10100], y_train2[10000:10100], nepoch=10, evaluate_loss_after=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8f85b647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "06808e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(model, senten_max_length):\n",
    "    # We start the sentence with the start token\n",
    "    new_sentence = [word_to_index[sentence_start_token]]\n",
    "    \n",
    "    # Repeat until we get an end token and keep our sentences to less than senten_max_length words for now\n",
    "    while (not new_sentence[-1] == word_to_index[sentence_end_token]) and len(new_sentence) < senten_max_length:\n",
    "        next_word_probs = model.forward_propagation(new_sentence)\n",
    "        sampled_word = word_to_index[unknown_token]\n",
    "        \n",
    "        # We don't want to sample unknown words\n",
    "        while sampled_word == word_to_index[unknown_token]:\n",
    "            \n",
    "            # correcting for abnormalities\n",
    "            #abs_v = [-i if i <0 else i for i in next_word_probs[-1][0]] \n",
    "            #nrm_v = [i/sum(abs_v) for i in abs_v] \n",
    "            #abs_v = [0 if i <0 else i for i in next_word_probs[-1][0]] \n",
    "            #abs_v = [0 if i <0 else i for i in next_word_probs[0][-1]] \n",
    "            #nrm_v = [i/sum(abs_v) for i in abs_v] \n",
    "            #samples = np.random.multinomial(1, nrm_v)\n",
    "            #sampled_word = np.argmax(samples)\n",
    "            \n",
    "            # the secret sauce of creativity\n",
    "            samples = np.random.multinomial(1, next_word_probs[0][-1])\n",
    "            \n",
    "            sampled_word = np.argmax(samples)\n",
    "            \n",
    "        new_sentence.append(sampled_word)\n",
    "\n",
    "    print(new_sentence)\n",
    "    sentence_str = [index_to_word[x] for x in new_sentence[1:-1]]\n",
    "    #print(sentence_str)\n",
    "    return sentence_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f2955ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4941, 3294, 3351, 1818, 199, 3030, 5255, 5876, 404, 3871, 127, 5880, 4060, 2493, 2101, 1889, 4103, 3970, 5128]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['eclipse',\n",
       " 'uncle',\n",
       " 'maghavat',\n",
       " 'hoisted',\n",
       " 'pierced',\n",
       " 'adhering',\n",
       " '_meghapushpa_',\n",
       " 'raining',\n",
       " 'night',\n",
       " 'swan',\n",
       " 'out',\n",
       " 'repelling',\n",
       " 'rati',\n",
       " 'enquire',\n",
       " 'influence',\n",
       " 'support',\n",
       " 'fornication',\n",
       " 'belt']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senten_max_length = 20\n",
    "generate_sentence(model, senten_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "71dd3bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 6250, 382, 2254, 5450, 2696, 3814, 2245, 6304, 6028, 5687, 4670, 3166, 4315, 5205, 517, 5970, 3450, 2083, 1891]\n",
      "corrupt kind concerning drag horse-lore arranged sending alteration praising redolent induce jumped she-elephants 'tell old enhances plain vritra\n",
      "[3, 2019, 1432, 3398, 2805, 429, 2920, 3907, 499, 4844, 5103, 3271, 4967, 1164, 1198, 2514, 4940, 2316, 2584, 1445]\n",
      "hours adopt juices lamentations soul favourites common agreement gashed 'you extol truthfulness break likest 6 obstruct _agni_ observed\n",
      "[3, 855, 2475, 2918, 1795, 3437, 6358, 438, 2853, 4852, 1842, 3776, 5719, 2885, 1638, 1701, 5905, 3572, 247, 1312]\n",
      "does vasukI fetch upraised intellectual regulating wise perils deprive chitrasena _vijaya_ highly-trained mother-in-law durga fragrance gushed horses_ covered\n",
      "[3, 2991, 2475, 1054, 1750, 1564, 2407, 3183, 4794, 1888, 4488, 4863, 2174, 2762, 2097, 242, 2903, 6051, 3155, 994]\n",
      "comes vasukI attired whither promise venerable 41 marshalling collection kaliya nakha-naki destiny treading kama lady instant council 40\n",
      "[3, 2538, 5364, 3398, 4376, 6055, 2228, 5180, 6393, 1998, 2518, 5035, 2058, 5476, 2718, 6068, 1546, 1830, 4602, 532]\n",
      "obtains buildings juices unfortunate indifferent discomfiture _swetavahana_ paper yajnasenI malicious encounterest maids befall concealment _rishi_ replacement arose peepals\n",
      "[3, 6079, 622, 3108, 1110, 100, 5308, 2638, 5263, 113, 5476, 890, 2263, 6098, 2470, 1875, 1257, 1614, 4070, 3291]\n",
      "maimed formerly wheels mean foremost painfully matter concentrating kurus befall intelligent crooked describe curries flanks sutas indulge stooping\n",
      "[3, 2826, 4816, 2730, 952, 5341, 4108, 619, 2434, 2449, 980, 3333, 1771, 2622, 5730, 3741, 579, 4007, 3666, 5219]\n",
      "fettered glorious jimuta fly negotiating confer cook defective juliet occasion yells driving _lapis avenging avoid household flung followeth\n",
      "[3, 5008, 6226, 4216, 5299, 919, 4137, 2883, 4350, 2937, 4169, 2858, 4620, 5085, 891, 5395, 1067, 864, 2472, 5107]\n",
      "_kankojwalatwacham_ profits embraceth calcutta delightful well-filtered daughters father-in-law expected thumbs desperate washed cases suddenly pandava-fire remain editions wood\n",
      "[3, 2420, 5782, 3908, 5130, 1000, 2520, 4897, 5273, 3123, 2515, 5219, 4085, 10, 877, 40, 4393, 5358, 6215, 5072]\n",
      "notice '_alas_ reality 'enjoined held offer 'desist _khandava_ simile secrets melee weal by 'thou thy sukanya lapses nonproprietary\n",
      "[3, 5920, 6282, 2335, 2426, 5340, 5145, 2537, 5490, 1773, 4220, 6187, 6331, 3702, 1586, 1590, 4264, 846, 1778, 4413]\n",
      "meaningless allow tough user eighteen climbed report _muhurtas_ deserve disgraced unprotected revenue reconquest particular class disposed carry angry\n"
     ]
    }
   ],
   "source": [
    "num_sentences = 10\n",
    "senten_min_length = 7\n",
    "senten_max_length = 20\n",
    "\n",
    "for i in range(num_sentences):\n",
    "    sent = generate_sentence(model, senten_max_length)\n",
    "    print (\" \".join(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfd388",
   "metadata": {},
   "source": [
    "### 5. Model Training\n",
    "In this section, we train the model using categorical cross-entropy loss and the Adam optimizer. The goal is to minimize the loss over multiple epochs and improve the accuracy.\n",
    "\n",
    "Training Details:\n",
    "Loss function: Categorical Cross-Entropy\n",
    "Optimizer: Adam\n",
    "Batch Size: 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "# Train on a small subset of the data to see what happens\n",
    "model = RNN(vocabulary_size)\n",
    "losses = train_with_sgd(model, X_train2, y_train2, nepoch=5, evaluate_loss_after=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bb6a547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/3w1dz5w55nj8bqyr7t76_qr00000gn/T/ipykernel_78657/1857118698.py:14: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  N = np.sum((len(y_i) for y_i in y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-19 00:23:57: Loss after num_examples_seen=0 epoch=0: 8.763614\n",
      "2024-10-19 03:42:55: Loss after num_examples_seen=88348 epoch=1: 5.576958\n",
      "2024-10-19 05:48:59: Loss after num_examples_seen=176696 epoch=2: 5.447429\n",
      "2024-10-19 09:08:09: Loss after num_examples_seen=265044 epoch=3: 5.543287\n",
      "Setting learning rate to 0.002500\n",
      "2024-10-19 10:04:14: Loss after num_examples_seen=353392 epoch=4: 5.296645\n",
      "2024-10-19 11:26:37: Loss after num_examples_seen=441740 epoch=5: 5.293215\n",
      "2024-10-19 12:21:12: Loss after num_examples_seen=530088 epoch=6: 5.382714\n",
      "Setting learning rate to 0.001250\n",
      "2024-10-19 13:49:38: Loss after num_examples_seen=618436 epoch=7: 5.237830\n",
      "2024-10-19 14:32:15: Loss after num_examples_seen=706784 epoch=8: 5.191588\n",
      "2024-10-19 15:17:30: Loss after num_examples_seen=795132 epoch=9: 5.239074\n",
      "Setting learning rate to 0.000625\n",
      "2024-10-19 16:03:59: Loss after num_examples_seen=883480 epoch=10: 5.151594\n",
      "2024-10-19 17:47:33: Loss after num_examples_seen=971828 epoch=11: 5.139855\n",
      "2024-10-19 19:20:47: Loss after num_examples_seen=1060176 epoch=12: 5.154053\n",
      "Setting learning rate to 0.000313\n",
      "2024-10-19 22:18:56: Loss after num_examples_seen=1148524 epoch=13: 4.714442\n",
      "2024-10-20 11:10:21: Loss after num_examples_seen=1236872 epoch=14: 4.624886\n",
      "2024-10-20 13:49:06: Loss after num_examples_seen=1325220 epoch=15: 4.639653\n",
      "Setting learning rate to 0.000156\n",
      "2024-10-20 15:12:57: Loss after num_examples_seen=1413568 epoch=16: 3.451147\n",
      "2024-10-20 15:47:15: Loss after num_examples_seen=1501916 epoch=17: 3.350735\n",
      "2024-10-20 16:20:32: Loss after num_examples_seen=1590264 epoch=18: 3.363465\n",
      "Setting learning rate to 0.000078\n",
      "2024-10-20 17:01:48: Loss after num_examples_seen=1678612 epoch=19: 2.591868\n",
      "2024-10-20 17:56:17: Loss after num_examples_seen=0 epoch=0: 2.568473\n",
      "2024-10-20 18:34:18: Loss after num_examples_seen=88348 epoch=1: 5.716052\n",
      "Setting learning rate to 0.002500\n",
      "2024-10-20 19:44:51: Loss after num_examples_seen=176696 epoch=2: 4.657098\n",
      "2024-10-20 20:25:45: Loss after num_examples_seen=265044 epoch=3: 5.077555\n",
      "Setting learning rate to 0.001250\n",
      "2024-10-20 21:13:19: Loss after num_examples_seen=353392 epoch=4: 4.138793\n",
      "2024-10-20 22:06:53: Loss after num_examples_seen=441740 epoch=5: 3.960176\n",
      "2024-10-20 22:49:41: Loss after num_examples_seen=530088 epoch=6: 3.930767\n",
      "2024-10-20 23:40:12: Loss after num_examples_seen=618436 epoch=7: 3.869778\n",
      "2024-10-21 00:35:53: Loss after num_examples_seen=706784 epoch=8: 3.867769\n",
      "2024-10-21 01:52:27: Loss after num_examples_seen=795132 epoch=9: 3.898632\n",
      "Setting learning rate to 0.000625\n",
      "2024-10-21 02:49:15: Loss after num_examples_seen=883480 epoch=10: 3.527783\n",
      "2024-10-21 03:33:08: Loss after num_examples_seen=971828 epoch=11: 3.414849\n",
      "2024-10-21 04:31:12: Loss after num_examples_seen=1060176 epoch=12: 3.366818\n",
      "2024-10-21 05:24:38: Loss after num_examples_seen=1148524 epoch=13: 3.340048\n",
      "2024-10-21 06:05:26: Loss after num_examples_seen=1236872 epoch=14: 3.313531\n",
      "2024-10-21 07:15:20: Loss after num_examples_seen=1325220 epoch=15: 3.299735\n",
      "2024-10-21 08:23:25: Loss after num_examples_seen=1413568 epoch=16: 3.248986\n",
      "2024-10-21 09:30:50: Loss after num_examples_seen=1501916 epoch=17: 3.222100\n",
      "2024-10-21 13:03:43: Loss after num_examples_seen=1590264 epoch=18: 3.190852\n",
      "2024-10-21 13:40:05: Loss after num_examples_seen=1678612 epoch=19: 3.189985\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      3\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m15\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_sgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_loss_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[127], line 33\u001b[0m, in \u001b[0;36mtrain_with_sgd\u001b[0;34m(model, X_train, y_train, learning_rate, nepoch, evaluate_loss_after)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# For each training example...\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_train)):\n\u001b[1;32m     31\u001b[0m     \n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# One SGD step\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msgd_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     num_examples_seen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[121], line 4\u001b[0m, in \u001b[0;36mnumpy_sdg_step\u001b[0;34m(self, x, y, learning_rate)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy_sdg_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, learning_rate):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Calculate the gradients\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     dLdU, dLdV, dLdW \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbptt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Change parameters according to gradients and learning rate\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m dLdU\n",
      "Cell \u001b[0;32mIn[118], line 30\u001b[0m, in \u001b[0;36mbptt\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     27\u001b[0m         dLdU \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(delta_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG[x[bptt_step]]) \n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Update delta for next step\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m         delta_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdot(delta_t) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m s[bptt_step\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [dLdU, dLdV, dLdW]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(5):\n",
    "    time.sleep(15*60)\n",
    "    losses = train_with_sgd(model, X_train2, y_train2, nepoch=20, evaluate_loss_after=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "86feefbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/3w1dz5w55nj8bqyr7t76_qr00000gn/T/ipykernel_55450/1857118698.py:14: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  N = np.sum((len(y_i) for y_i in y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-16 09:55:45: Loss after num_examples_seen=0 epoch=0: 5.152209\n",
      "2024-10-16 10:12:25: Loss after num_examples_seen=48950 epoch=1: 5.154802\n",
      "Setting learning rate to 0.002500\n",
      "2024-10-16 10:30:41: Loss after num_examples_seen=97900 epoch=2: 4.991009\n",
      "2024-10-16 10:48:20: Loss after num_examples_seen=146850 epoch=3: 4.963550\n",
      "2024-10-16 11:08:07: Loss after num_examples_seen=195800 epoch=4: 4.919193\n"
     ]
    }
   ],
   "source": [
    "losses = train_with_sgd(model, X_train2, y_train2, nepoch=5, evaluate_loss_after=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "db1bffed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/3w1dz5w55nj8bqyr7t76_qr00000gn/T/ipykernel_55450/1857118698.py:14: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  N = np.sum((len(y_i) for y_i in y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-16 11:24:53: Loss after num_examples_seen=0 epoch=0: 4.936287\n",
      "2024-10-16 11:39:36: Loss after num_examples_seen=48950 epoch=1: 5.093147\n",
      "Setting learning rate to 0.002500\n",
      "2024-10-16 12:35:15: Loss after num_examples_seen=97900 epoch=2: 4.892396\n",
      "2024-10-16 12:49:06: Loss after num_examples_seen=146850 epoch=3: 4.876551\n",
      "2024-10-16 13:05:37: Loss after num_examples_seen=195800 epoch=4: 4.888263\n",
      "Setting learning rate to 0.001250\n"
     ]
    }
   ],
   "source": [
    "losses = train_with_sgd(model, X_train2, y_train2, nepoch=5, evaluate_loss_after=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e6042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/3w1dz5w55nj8bqyr7t76_qr00000gn/T/ipykernel_55450/1857118698.py:14: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  N = np.sum((len(y_i) for y_i in y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-16 13:30:10: Loss after num_examples_seen=0 epoch=0: 4.777440\n",
      "2024-10-16 13:43:46: Loss after num_examples_seen=48950 epoch=1: 4.988670\n",
      "Setting learning rate to 0.002500\n",
      "2024-10-16 14:00:59: Loss after num_examples_seen=97900 epoch=2: 4.861099\n",
      "2024-10-16 14:33:38: Loss after num_examples_seen=146850 epoch=3: 4.863277\n",
      "Setting learning rate to 0.001250\n"
     ]
    }
   ],
   "source": [
    "losses = train_with_sgd(model, X_train2, y_train2, nepoch=5, evaluate_loss_after=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119393cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train_with_sgd(model, X_train2, y_train2, nepoch=5, evaluate_loss_after=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b05b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train_with_sgd(model, X_train2, y_train2, nepoch=5, evaluate_loss_after=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9761ff",
   "metadata": {},
   "source": [
    "### 6. Generating Text\n",
    "Once the model is trained, we can use it to generate text. By providing a seed (e.g., a phrase), the model predicts the next word iteratively to form a sequence.\n",
    "\n",
    "Generation Process:\n",
    "Provide a seed text.\n",
    "Generate the next word using the model’s prediction.\n",
    "Append the new word to the seed and continue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5e1faf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(model, senten_max_length):\n",
    "    prompt='''Of the god of called together all his younger brothers and said it in thus great'''\n",
    "    # We start the sentence with the start token\n",
    "    new_sentence = [word_to_index[word] for word in prompt if word in word_to_index]\n",
    "#     new_sentence = [word_to_index[sentence_start_token]]\n",
    "    \n",
    "    # Repeat until we get an end token and keep our sentences to less than senten_max_length words for now\n",
    "    while (not new_sentence[-1] == word_to_index[sentence_end_token]) and len(new_sentence) < senten_max_length:\n",
    "        next_words_probs = model.forward_propagation(new_sentence)\n",
    "        sampled_word = word_to_index[unknown_token]\n",
    "        \n",
    "        # We don't want to sample unknown words\n",
    "        while sampled_word == word_to_index[unknown_token]:\n",
    "            \n",
    "            #print(next_word_probs[0][-1])\n",
    "            samples = np.random.multinomial(1, next_words_probs[0][-1])\n",
    "            sampled_word = np.argmax(samples)\n",
    "            \n",
    "        new_sentence.append(sampled_word)\n",
    "\n",
    "    #print(new_sentence)\n",
    "    sentence_str = [index_to_word[x] for x in new_sentence[1:-1]]\n",
    "    #print(sentence_str)\n",
    "    return sentence_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7e2f6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(model, senten_max_length):\n",
    "    prompt = '''Of the god of called together all his younger brothers and said it in thus great'''\n",
    "    \n",
    "    # Convert the prompt words to their corresponding indices if they exist in word_to_index\n",
    "    new_sentence = [word_to_index[word] for word in prompt.split() if word in word_to_index]\n",
    "\n",
    "    # Ensure the sentence has a valid start by adding the start token if necessary\n",
    "    if not new_sentence:\n",
    "        new_sentence = [word_to_index[sentence_start_token]]\n",
    "\n",
    "    # Repeat until we reach the end token or exceed the maximum sentence length\n",
    "    while (new_sentence[-1] != word_to_index[sentence_end_token]) and len(new_sentence) < senten_max_length:\n",
    "        # Get the probabilities for the next word\n",
    "        next_word_probs = model.forward_propagation(new_sentence)\n",
    "        sampled_word = word_to_index[unknown_token]\n",
    "        \n",
    "        # Avoid sampling unknown words\n",
    "        while sampled_word == word_to_index[unknown_token]:\n",
    "            # Sample a word based on the probabilities\n",
    "            samples = np.random.multinomial(1, next_word_probs[0][-1])\n",
    "            sampled_word = np.argmax(samples)\n",
    "        \n",
    "        # Append the sampled word to the sentence\n",
    "        new_sentence.append(sampled_word)\n",
    "\n",
    "    # Convert the generated sentence indices back to words, excluding start and end tokens\n",
    "    sentence_str = [index_to_word[x] for x in new_sentence[1:-1]]\n",
    "    \n",
    "    return ' '.join(sentence_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0c789793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "god of called together all his younger brothers and said it in thus great are and I shall not in the hours and looking faces their long of what beautiful ye and the thou shinest ever in the\n",
      "god of called together all his younger brothers and said it in thus great o offices and is coming foremost of drupada and informed vaisyas taking and _rakshasas_ charioteers saying 'who of the and resembling thou rescuest remain\n",
      "god of called together all his younger brothers and said it in thus great I shall thou them king and o child her the their time and what o child up to the city is a younger of\n",
      "god of called together all his younger brothers and said it in thus great and whom _gandiva_ for viands entertain who thou the thou o shall perform speech just your branches and long as the with their auspicious\n",
      "god of called together all his younger brothers and said it in thus great be will to live by by means of the and red dice most tree advice symmetrical and challenged whose rain on a single car\n",
      "god of called together all his younger brothers and said it in thus great skill will apply be thine to thee do by me as the sun conceives surasena pattachchara and hearing whose on a single car all\n",
      "god of called together all his younger brothers and said it in thus great o thou great daughter of life god delicate the abounding the of distress by behaving celestial to the with the excuse course cars of\n",
      "god of called together all his younger brothers and said it in thus great o ye of earth bharata race yudhishthira of high soul then called together all should by elephants sprung from the race of the have\n",
      "god of called together all his younger brothers and said it in thus great are both profitable and men thou art the all them will and forest ordinary their producing saying 'enquire not of the for relieving prosperity\n",
      "god of called together all his younger brothers and said it in thus great be happen in respect shall then unfastened sons way me the ocean hid is the first of all _nagas_ possessed and lastly the saying\n",
      "god of called together all his younger brothers and said it in thus great be able by in the or the fastnesses that king in the and thou o foremost of the and foes and mild and foes\n",
      "god of called together all his younger brothers and said it in thus great are the for by them and yudhishthira the everything arjuna who was _gandharvas_ in a celestial we I shall o bharata what capacities ``\n",
      "god of called together all his younger brothers and said it in thus great surely be to live since lie divine undiscovered word supreme and women and is already by one who is the with their sahadeva as\n",
      "god of called together all his younger brothers and said it in thus great I shall before as the as a waiting maid as fire is there like an in the guise of the calls and the _gandiva_\n",
      "god of called together all his younger brothers and said it in thus great she or I shall say that is the to the all the plates of womanly king regains said of kuntI select some spot where\n",
      "god of called together all his younger brothers and said it in thus great o it damsel thyself the sons of pandu the whence destruction is the in one city then with bended horses beauty in the or\n",
      "god of called together all his younger brothers and said it in thus great o yudhishthira and arjuna specially and he that is disloyal attached to reside a way to be well-disposed of time yudhishthira as the humped\n",
      "god of called together all his younger brothers and said it in thus great o thou knowest by thou that possessest bangles to the king he city men and by krishna warrior the agnI in the 1e8 panchalas\n",
      "god of called together all his younger brothers and said it in thus great are ever in all hours in his fire thee him the lessons of cowherd repressers and without whom us does the that such should\n",
      "god of called together all his younger brothers and said it in thus great o both thou art behold and charitable after below people thundering symmetrical mahabharata a rider of the kuru way as clouds lion moon is\n"
     ]
    }
   ],
   "source": [
    "num_sentences = 20\n",
    "senten_min_length = 7\n",
    "senten_max_length = 40\n",
    "\n",
    "for i in range(num_sentences):\n",
    "    sent = []\n",
    "    # We want long sentences, not sentences with one or two words\n",
    "    while len(sent) < senten_min_length:\n",
    "        sent = generate_sentence(model, senten_max_length)\n",
    "    print (\"\".join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "22c7a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_with_prompt(model, prompt, senten_max_length):\n",
    "    # Start the sentence with the provided prompt\n",
    "    new_sentence = [word_to_index[word] for word in prompt if word in word_to_index]\n",
    "\n",
    "    # If no valid words in the prompt, start with the sentence start token\n",
    "    if not new_sentence:\n",
    "        new_sentence = [word_to_index[sentence_start_token]]\n",
    "\n",
    "    # Repeat until we get an end token and limit the sentence length\n",
    "    while (not new_sentence[-1] == word_to_index[sentence_end_token]) and len(new_sentence) < senten_max_length:\n",
    "        next_word_probs = model.forward_propagation(new_sentence)\n",
    "        sampled_word = word_to_index[unknown_token]\n",
    "\n",
    "        # We don't want to sample unknown words\n",
    "        while sampled_word == word_to_index[unknown_token]:\n",
    "            abs_v = [0 if i < 0 else i for i in next_word_probs[-1][0]]\n",
    "            nrm_v = [i / sum(abs_v) for i in abs_v]\n",
    "\n",
    "            samples = np.random.multinomial(1, nrm_v)\n",
    "            sampled_word = np.argmax(samples)\n",
    "\n",
    "        new_sentence.append(sampled_word)\n",
    "\n",
    "    # Convert the word indices back to words\n",
    "    sentence_str = [index_to_word[x] for x in new_sentence[1:-1]]\n",
    "\n",
    "    return sentence_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bbab4f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/3w1dz5w55nj8bqyr7t76_qr00000gn/T/ipykernel_78657/307878802.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  nrm_v = [i / sum(abs_v) for i in abs_v]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pvals < 0, pvals > 1 or pvals contains NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# We want long sentences, not sentences with one or two words\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sent) \u001b[38;5;241m<\u001b[39m senten_min_length:\n\u001b[0;32m---> 11\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_sentence_with_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msenten_max_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sent))\n",
      "Cell \u001b[0;32mIn[162], line 19\u001b[0m, in \u001b[0;36mgenerate_sentence_with_prompt\u001b[0;34m(model, prompt, senten_max_length)\u001b[0m\n\u001b[1;32m     16\u001b[0m     abs_v \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m next_word_probs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m     17\u001b[0m     nrm_v \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(abs_v) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m abs_v]\n\u001b[0;32m---> 19\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrm_v\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     sampled_word \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(samples)\n\u001b[1;32m     22\u001b[0m new_sentence\u001b[38;5;241m.\u001b[39mappend(sampled_word)\n",
      "File \u001b[0;32mmtrand.pyx:4337\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multinomial\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:391\u001b[0m, in \u001b[0;36mnumpy.random._common.check_array_constraint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:377\u001b[0m, in \u001b[0;36mnumpy.random._common._check_array_cons_bounded_0_1\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pvals < 0, pvals > 1 or pvals contains NaNs"
     ]
    }
   ],
   "source": [
    "num_sentences = 20\n",
    "senten_min_length = 7\n",
    "senten_max_length = 40\n",
    "\n",
    "prompt= '''The son of the god of Justice, called together all his younger brothers and said'''\n",
    "\n",
    "for i in range(num_sentences):\n",
    "    sent = []\n",
    "    # We want long sentences, not sentences with one or two words\n",
    "    while len(sent) < senten_min_length:\n",
    "        sent = generate_sentence_with_prompt(model,prompt, senten_max_length)\n",
    "    print (\" \".join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbca8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28731c3f",
   "metadata": {},
   "source": [
    "### 7. Conclusion\n",
    "We successfully built and trained an RNN model for text generation using trigrams. The model generates text based on the patterns it learned from the input corpus. Further improvements can be made by experimenting with different architectures and hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94637b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
